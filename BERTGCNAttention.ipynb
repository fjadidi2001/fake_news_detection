{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0xq6J1jbbL8KtNLVv+R8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/fake_news_detection/blob/main/BERTGCNAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup and Data Loading\n",
        "\n"
      ],
      "metadata": {
        "id": "K-4U7Y5EqCOl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvTEVxbhnXsW",
        "outputId": "127765c0-096d-4052-b615-0ad2811efad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Network features shape: (2282, 3)\n",
            "Label distribution: [1669  613]\n",
            "Network features saved to Google Drive\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torch-geometric transformers imbalanced-learn -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import networkx as nx\n",
        "from scipy import io as sio\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv', encoding='latin-1')\n",
        "\n",
        "# Extract network features\n",
        "network_features = df[['share_count', 'reaction_count', 'comment_count']].values  # (2282, 3)\n",
        "\n",
        "# Standardize network features\n",
        "scaler = StandardScaler()\n",
        "X_net_std = scaler.fit_transform(network_features)  # (2282, 3)\n",
        "\n",
        "# Save standardized features\n",
        "sio.savemat('network.mat', {'X_net_std': X_net_std})\n",
        "print(\"Network features shape:\", X_net_std.shape)\n",
        "\n",
        "# Prepare labels (binary classification)\n",
        "labels = df['Rating'].apply(lambda x: 0 if x == 'mostly true' else 1).values  # 0: mostly true, 1: others\n",
        "y = np.array(labels)\n",
        "print(\"Label distribution:\", np.bincount(y))  # [1669, 613]\n",
        "\n",
        "# Move files to Google Drive\n",
        "!mv /content/network.mat /content/drive/MyDrive/Projects/Hayat/\n",
        "print(\"Network features saved to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Social Branch (Graph Construction and GCN Embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "IRbmJC6fq2Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "# Load standardized network features\n",
        "X_net_std = sio.loadmat('/content/drive/MyDrive/Projects/Hayat/network.mat')['X_net_std']\n",
        "\n",
        "# Construct graph\n",
        "G = nx.Graph()\n",
        "for idx in range(len(df)):\n",
        "    G.add_node(idx, features=X_net_std[idx])\n",
        "account_groups = df.groupby('account_id').indices\n",
        "for account_id, indices in account_groups.items():\n",
        "    indices = list(indices)\n",
        "    for i in range(len(indices)):\n",
        "        for j in range(i + 1, len(indices)):\n",
        "            G.add_edge(indices[i], indices[j])\n",
        "print(\"Graph nodes:\", G.number_of_nodes(), \"Edges:\", G.number_of_edges())\n",
        "\n",
        "# Prepare GNN data\n",
        "edges = list(G.edges)\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "x = torch.tensor(X_net_std, dtype=torch.float)\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "edge_index, _ = add_self_loops(data.edge_index, num_nodes=data.num_nodes)\n",
        "data.edge_index = edge_index\n",
        "print(\"GNN Data:\", data)\n",
        "\n",
        "# Define GCN model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels=3, hidden_channels=64, out_channels=128):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Compute GCN embeddings\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gcn_model = GCN().to(device)\n",
        "data = data.to(device)\n",
        "gcn_model.eval()\n",
        "with torch.no_grad():\n",
        "    gcn_embeddings = gcn_model(data)  # (2282, 128)\n",
        "print(\"GCN Embeddings shape:\", gcn_embeddings.shape)\n",
        "\n",
        "# Save GCN model and embeddings\n",
        "torch.save(gcn_model.state_dict(), 'gcn_model.pth')\n",
        "torch.save(gcn_embeddings.cpu(), 'gcn_embeddings.pt')\n",
        "print(\"GCN model and embeddings saved\")\n",
        "\n",
        "# Move to Google Drive\n",
        "!mv /content/gcn_model.pth /content/drive/MyDrive/Projects/Hayat/\n",
        "!mv /content/gcn_embeddings.pt /content/drive/MyDrive/Projects/Hayat/\n",
        "print(\"GCN model and embeddings moved to Google Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7cKaUjSqojW",
        "outputId": "011c62f9-68b3-4f8c-91d4-0dc67e0bfe4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph nodes: 2282 Edges: 368312\n",
            "GNN Data: Data(x=[2282, 3], edge_index=[2, 370594])\n",
            "GCN Embeddings shape: torch.Size([2282, 128])\n",
            "GCN model and embeddings saved\n",
            "GCN model and embeddings moved to Google Drive\n"
          ]
        }
      ]
    }
  ]
}
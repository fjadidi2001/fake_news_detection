{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVEgSXTeWr0P9jcInVMl3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/fake_news_detection/blob/main/DansE_Mar31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "oA7Z8kvmccRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive in Colab"
      ],
      "metadata": {
        "id": "PxIpn64y8_JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Mzv5ciD71hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501a6d66-e806-4ce2-efd8-2f40a8b98510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "9J1bk_HnDc7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = '/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_path, encoding='latin-1')"
      ],
      "metadata": {
        "id": "bhyykHvM89kI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Inspection"
      ],
      "metadata": {
        "id": "TDzZ-uobD38a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(2))  # See first 2 rows\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSYdMJU3DiFH",
        "outputId": "6c85eb38-5362-49c6-bd02-01c5301fae52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     account_id       post_id    Category               Page  \\\n",
            "0  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "\n",
            "                                            Post URL Date Published Post Type  \\\n",
            "0  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "1  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "\n",
            "               Rating Debate  share_count  reaction_count  comment_count  \\\n",
            "0  no factual content    NaN          NaN           146.0           15.0   \n",
            "1         mostly true    NaN          1.0            33.0           34.0   \n",
            "\n",
            "                                        Context Post  \n",
            "0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1  Can either candidate move the needle in the de...  \n",
            "\n",
            "Missing values:\n",
            " account_id           0\n",
            "post_id              0\n",
            "Category             0\n",
            "Page                 0\n",
            "Post URL             0\n",
            "Date Published       0\n",
            "Post Type            0\n",
            "Rating               0\n",
            "Debate            1984\n",
            "share_count         70\n",
            "reaction_count       2\n",
            "comment_count        2\n",
            "Context Post         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values"
      ],
      "metadata": {
        "id": "_hVZN6j7FnqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strategy 1: Fill categorical columns\n",
        "df['Rating'] = df['Rating'].fillna('Unknown')\n",
        "df['Debate'] = df['Debate'].fillna('Not Specified')\n",
        "\n",
        "# Strategy 2: Fill numerical columns with median\n",
        "numeric_cols = ['share_count', 'reaction_count', 'comment_count']\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Alternative: Drop rows with critical missing values\n",
        "# df = df.dropna(subset=['important_column'])"
      ],
      "metadata": {
        "id": "CCesok3vEbWX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Preprocessing"
      ],
      "metadata": {
        "id": "GFWw2cFnGKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date to datetime format\n",
        "df['Date Published'] = pd.to_datetime(df['Date Published'], format='%m/%d/%Y')\n",
        "\n",
        "# Clean text columns\n",
        "df['Context Post'] = df['Context Post'].str.replace('\"', '')"
      ],
      "metadata": {
        "id": "-jLm9vpHGC-h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['account_id'] = df['account_id'].astype(str)\n",
        "df['post_id'] = df['post_id'].astype(str)"
      ],
      "metadata": {
        "id": "o2_ZzlhgGlq1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['Category', 'Page', 'Post Type']\n",
        "df[categorical_cols] = df[categorical_cols].fillna('Unknown')"
      ],
      "metadata": {
        "id": "DuV4oIehGoMR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgVsdZkBG2KU",
        "outputId": "5472e94c-4691-4b22-cb71-18f44ad414bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2282 entries, 0 to 2281\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   account_id      2282 non-null   object        \n",
            " 1   post_id         2282 non-null   object        \n",
            " 2   Category        2282 non-null   object        \n",
            " 3   Page            2282 non-null   object        \n",
            " 4   Post URL        2282 non-null   object        \n",
            " 5   Date Published  2282 non-null   datetime64[ns]\n",
            " 6   Post Type       2282 non-null   object        \n",
            " 7   Rating          2282 non-null   object        \n",
            " 8   Debate          2282 non-null   object        \n",
            " 9   share_count     2282 non-null   float64       \n",
            " 10  reaction_count  2282 non-null   float64       \n",
            " 11  comment_count   2282 non-null   float64       \n",
            " 12  Context Post    2282 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(3), object(9)\n",
            "memory usage: 231.9+ KB\n",
            "None\n",
            "account_id        0\n",
            "post_id           0\n",
            "Category          0\n",
            "Page              0\n",
            "Post URL          0\n",
            "Date Published    0\n",
            "Post Type         0\n",
            "Rating            0\n",
            "Debate            0\n",
            "share_count       0\n",
            "reaction_count    0\n",
            "comment_count     0\n",
            "Context Post      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main source"
      ],
      "metadata": {
        "id": "LVGdPq9osmqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wordembeddings"
      ],
      "metadata": {
        "id": "kzfAQRwVzfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clean up the environment\n",
        "!pip uninstall -y numpy mittens gensim scipy smart-open wrapt tensorflow tensorflow-datasets dm-tree numba\n",
        "\n",
        "# Step 2: Install compatible versions\n",
        "!pip install numpy==1.26.4 mittens==0.2 gensim==4.3.3 scipy==1.13.1 smart-open==7.1.0 wrapt==1.17.2\n",
        "\n",
        "# Step 3: Restart runtime (run this once, then comment out)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "# Step 4: After restart, run the code\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-iINw1nwrYN",
        "outputId": "b490b631-b029-49f5-d1fd-a74236705ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping mittens as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scipy 1.14.1\n",
            "Uninstalling scipy-1.14.1:\n",
            "  Successfully uninstalled scipy-1.14.1\n",
            "Found existing installation: smart-open 7.1.0\n",
            "Uninstalling smart-open-7.1.0:\n",
            "  Successfully uninstalled smart-open-7.1.0\n",
            "Found existing installation: wrapt 1.17.2\n",
            "Uninstalling wrapt-1.17.2:\n",
            "  Successfully uninstalled wrapt-1.17.2\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Found existing installation: tensorflow-datasets 4.9.8\n",
            "Uninstalling tensorflow-datasets-4.9.8:\n",
            "  Successfully uninstalled tensorflow-datasets-4.9.8\n",
            "Found existing installation: dm-tree 0.1.9\n",
            "Uninstalling dm-tree-0.1.9:\n",
            "  Successfully uninstalled dm-tree-0.1.9\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mittens==0.2\n",
            "  Downloading mittens-0.2-py3-none-any.whl.metadata (377 bytes)\n",
            "Collecting gensim==4.3.3\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open==7.1.0\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt==1.17.2\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, mittens, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "tensorflow-probability 0.25.0 requires dm-tree, which is not installed.\n",
            "umap-learn 0.5.7 requires numba>=0.51.2, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n",
            "shap 0.47.0 requires numba>=0.54, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 mittens-0.2 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import GloVe\n",
        "import mittens\n",
        "print(\"Mittens version (GloVe only):\", mittens.__version__)\n",
        "\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "9fuNa6-WuR4a",
        "outputId": "0fb0a313-26a4-42bd-8bcb-35430ccf7033"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version (GloVe only): 0.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a04323fd7025>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mittens version (GloVe only):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmittens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_tfidf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a04323fd7025>\u001b[0m in \u001b[0;36mWordEmbeddings\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mword2vecEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenization"
      ],
      "metadata": {
        "id": "Vomn4xUHzZEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages and download NLTK data\n",
        "!pip install numpy==1.26.4 gensim==4.3.3 mittens==0.2 spacy==3.7.2 stop-words==2018.7.23 -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe\n",
        "import os\n",
        "\n",
        "# Special characters dictionary\n",
        "specialchar_dic = {\n",
        "    \"’\": \"'\", \"„\": \"\\\"\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"«\": \"<<\", \"»\": \">>\",\n",
        "    \"…\": \"...\", \"—\": \"--\", \"¡\": \"!\", \"¿\": \"?\", \"©\": \" \", \"–\": \" \"\n",
        "}\n",
        "\n",
        "# Stop words function (cached globally)\n",
        "def stopWordsEN():\n",
        "    sw_stop_words = get_stop_words('en')\n",
        "    sw_nltk = stopwords.words('english')\n",
        "    sw_spacy = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
        "    sw_mallet = ['a', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', 'came', 'can', 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', 'course', 'currently', 'd', 'definitely', 'described', 'despite', 'did', 'different', 'do', 'does', 'doing', 'done', 'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'f', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'h', 'had', 'happens', 'hardly', 'has', 'have', 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'i', 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'p', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 't', 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants', 'was', 'way', 'we', 'welcome', 'well', 'went', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', 'wonder', 'would', 'x', 'y', 'yes', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', 'z', 'zero']\n",
        "    return list(set(sw_stop_words + sw_nltk + sw_mallet + sw_spacy))\n",
        "\n",
        "# Precompile regex and load Spacy model\n",
        "punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "specialchar_re = re.compile('(%s)' % '|'.join(specialchar_dic.keys()))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "cachedStopWords_en = stopWordsEN()\n",
        "\n",
        "class Tokenization:\n",
        "    def applyFE(self, text):\n",
        "        \"\"\"Combine negation with words to reduce bias.\"\"\"\n",
        "        final_text = text.replace('cannot', 'can not').replace('can\\'t', 'can not')\n",
        "        final_text = final_text.replace('won\\'t', 'will not').replace('n\\'t', ' not').replace(' not ', ' not')\n",
        "        return final_text\n",
        "\n",
        "    def removeStopWords(self, text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords_en])\n",
        "\n",
        "    def removePunctuation(self, text, punctuation=punctuation):\n",
        "        for c in punctuation:\n",
        "            text = text.replace(c, ' ')\n",
        "        return text\n",
        "\n",
        "    def replaceUTF8Char(self, text, specialchars=specialchar_dic):\n",
        "        def replace(match):\n",
        "            return specialchars[match.group(0)]\n",
        "        return specialchar_re.sub(replace, text)\n",
        "\n",
        "    def createCorpus(self, text, remove_punctuation=True, remove_stopwords=True, apply_FE=True):\n",
        "        corpus = []\n",
        "        try:\n",
        "            text = self.replaceUTF8Char(text).replace(\"\\n\", \" \")\n",
        "            doc = nlp(text)\n",
        "            processed_text = ' '.join([t.lemma_ if t.lemma_ != '-PRON-' else t.text if not t.ent_type_ else t.text for t in doc])\n",
        "            processed_text = processed_text.replace(\"\\s\\s+\", ' ')\n",
        "\n",
        "            doc = nlp(processed_text.lower())\n",
        "            rawText = not (remove_punctuation or remove_stopwords or apply_FE)\n",
        "\n",
        "            for sentence in doc.sents:\n",
        "                sent = str(sentence.text)\n",
        "                if len(sent) == 0:\n",
        "                    continue\n",
        "                if not rawText:\n",
        "                    if apply_FE:\n",
        "                        sent = self.applyFE(text=sent)\n",
        "                    if remove_punctuation:\n",
        "                        sent = self.removePunctuation(text=sent)\n",
        "                    if remove_stopwords:\n",
        "                        sent = self.removeStopWords(text=sent)\n",
        "                sent = sent.lower().split()\n",
        "                if sent:\n",
        "                    corpus.append(sent)\n",
        "        except Exception as exp:\n",
        "            print('exception=', str(exp))\n",
        "            print('text=', text)\n",
        "        return corpus\n",
        "\n",
        "    def __del__(self):\n",
        "        print(\"Destructor Tokenization\")\n",
        "\n",
        "class WordEmbeddings:\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Tokenization example\n",
        "    tkn = Tokenization()\n",
        "    text1 = \"Apple data-intensive is looking at buying U.K. startup for $1 billion. This is great! The new D.P. model is funcitonal and ready\"\n",
        "    corpus1 = tkn.createCorpus(text1)\n",
        "    print(\"Corpus 1:\", corpus1)\n",
        "\n",
        "    # Larger text example\n",
        "    text2 = \"\"\"The lion may be known as the king of the jungle, but lions do not live in jungles. They’re the rulers of the African savannahs that are covered in brown grasses and speckled with sparse trees. Lions’ coloring helps them blend in perfectly with the tall grass so they can ambush their prey as best as possible. And lions are ferocious. Although they’re one of the most powerful predators on land, lions are in danger. Hunters and poachers target lions to prove to the world their machismo.\\n\\nAnd while hunters seek to wipe lions off the face of the earth to bolster their egos, the Kevin Richardson Wildlife Sanctuary hopes to stop them and protect the big African cat at all cost.\\n\\nRichardson has earned the nickname the “Lion Whisperer” for a reason. He aims to educate the world about lions. And for those lucky enough to volunteer alongside Richardson, he encourages them to learn more about lions and help protect the wild species.\\n\\n“To raise awareness, Kevin has now set up his YouTube Channel ‘LionWhispererTV’. The channel is all about raising awareness about not only the declining numbers of lions but also how this rapid decrease is happening. By watching these videos, you are directly contributing to our scheme of land acquisition,” he writes in his bio.\\n\\nAs part of the volunteer program, Richardson hosts a “volunteer enrichment and lion enrichment” walk. As the name suggests, Richardson takes his group of volunteers out into the savannah of South Africa to hang out with two lions. There, the volunteers meet a male lion, Bobcat, and a female lioness, Gabby. Both lions look ferocious, but are truly “affectionate,” at least that’s what Richardson says. And remember, he’s the lion whisperer, so he’s got an advantage with these deadly big cats.\\n\\nAs Richardson showers the pair of lions with love, the volunteers stay locked in the truck, unwilling to put their lives in danger. And while they are in the vehicle, the lions are just feet from them – and if something goes wrong, they could wind up injured anyway.\\n\\nRichardson shared the video on his “The Lion Whisperer” YouTube channel. With more than one million hits, this video has proven to be one of his most famous.\\n\\nThe video describes the moment caught on tape as follows:\\n\\n“It’s an enrichment walk for both the volunteers and the lions as Kevin shows off his lovely lions as well as giving some amazing lion facts to the volunteers.”\\n\\nViewers like you are overwhelmed with the magnificent footage. The following are a few comments shared on the video.\\n\\n“I hope to someday volunteer there with Kevin. I believe in the work and his perspective about conservation. This video makes me want to all the more! Bobcat and Gabby are lovely lions.” “Every time I watch a one of your videos I somehow end up smiling from ear to ear!” “That was so beautiful, wish I could rub my head against a lion.”\\n\\nTake a moment to watch this video. Would you ever want to volunteer with Kevin Richardson and his lions?\"\"\"\n",
        "    corpus2 = tkn.createCorpus(text2, remove_stopwords=False)\n",
        "    print(\"Corpus 2:\", corpus2)\n",
        "\n",
        "    # Generate embeddings from Corpus 2\n",
        "    we = WordEmbeddings(corpus2)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(\"\\nDocuments shape:\", np.array(docs, dtype=object).shape)\n",
        "    print(\"Documents:\", docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec shape:\", w2v.shape)\n",
        "    print(\"Word2Vec embeddings:\", w2v[:5])  # Print first 5 for brevity\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText shape:\", w2f.shape)\n",
        "    print(\"FastText embeddings:\", w2f[:5])\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe shape:\", w2g.shape)\n",
        "    print(\"GloVe embeddings:\", w2g[:5])\n",
        "\n",
        "    print(\"\\nComparison for word 'lion' (ID varies):\")\n",
        "    lion_id = we.word2id.get('lion', -1)\n",
        "    if lion_id != -1:\n",
        "        print(\"Word2Vec:\", w2v[lion_id])\n",
        "        print(\"FastText:\", w2f[lion_id])\n",
        "        print(\"GloVe:\", w2g[lion_id])\n",
        "    else:\n",
        "        print(\"'lion' not found in vocabulary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAIG9UunzNiF",
        "outputId": "3d5d34bd-8be6-4962-8f20-b7ac71fa5e31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus 1: [['apple', 'data', 'intensive', 'buy', 'startup', '1', 'billion'], ['great'], ['model', 'funcitonal', 'ready']]\n",
            "Corpus 2: [['the', 'lion', 'may', 'be', 'know', 'as', 'the', 'king', 'of', 'the', 'jungle', 'but', 'lion', 'do', 'notlive', 'in', 'jungle'], ['they', 'be', 'the', 'ruler', 'of', 'the', 'african', 'savannah', 'that', 'be', 'cover', 'in', 'brown', 'grass', 'and', 'speckle', 'with', 'sparse', 'tree'], ['lion', 'coloring', 'help', 'they', 'blend', 'in', 'perfectly', 'with', 'the', 'tall', 'grass', 'so', 'they', 'can', 'ambush', 'their', 'prey', 'as', 'well', 'as', 'possible'], ['and', 'lion', 'be', 'ferocious'], ['although', 'they', 'be', 'one', 'of', 'the', 'most', 'powerful', 'predator', 'on', 'land', 'lion', 'be', 'in', 'danger'], ['hunter', 'and', 'poacher', 'target', 'lion', 'to', 'prove', 'to', 'the', 'world', 'their', 'machismo'], ['and', 'while', 'hunter', 'seek', 'to', 'wipe', 'lion', 'off', 'the', 'face', 'of', 'the', 'earth', 'to', 'bolster', 'their', 'ego', 'the', 'kevin', 'richardson', 'wildlife', 'sanctuary', 'hope', 'to', 'stop', 'they', 'and', 'protect', 'the', 'big', 'african', 'cat', 'at', 'all', 'cost'], ['richardson', 'have', 'earn', 'the', 'nickname', 'the', 'lion', 'whisperer', 'for', 'a', 'reason'], ['he', 'aim', 'to', 'educate', 'the', 'world', 'about', 'lion'], ['and', 'for', 'those', 'lucky', 'enough', 'to', 'volunteer', 'alongside', 'richardson', 'he', 'encourage', 'they', 'to', 'learn', 'more', 'about', 'lion', 'and', 'help', 'protect', 'the', 'wild', 'specie'], ['to', 'raise', 'awareness', 'kevin', 'have', 'now', 'set', 'up', 'his', 'youtube', 'channel', 'lionwhisperertv'], ['the', 'channel', 'be', 'all', 'about', 'raise', 'awareness', 'about', 'notonly', 'the', 'decline', 'number', 'of', 'lion', 'but', 'also', 'how', 'this', 'rapid', 'decrease', 'be', 'happen'], ['by', 'watch', 'these', 'video', 'you', 'be', 'directly', 'contribute', 'to', 'our', 'scheme', 'of', 'land', 'acquisition', 'he', 'write', 'in', 'his', 'bio'], ['as', 'part', 'of', 'the', 'volunteer', 'program', 'richardson', 'host', 'a', 'volunteer', 'enrichment', 'and', 'lion', 'enrichment', 'walk'], ['as', 'the', 'name', 'suggest', 'richardson', 'take', 'his', 'group', 'of', 'volunteer', 'out', 'into', 'the', 'savannah', 'of', 'south', 'africa', 'to', 'hang', 'out', 'with', 'two', 'lion'], ['there', 'the', 'volunteer', 'meet', 'a', 'male', 'lion', 'bobcat', 'and', 'a', 'female', 'lioness', 'gabby'], ['both', 'lion', 'look', 'ferocious', 'but', 'be', 'truly', 'affectionate', 'at', 'least', 'that', 'be', 'what', 'richardson', 'say'], ['and', 'remember', 'he', 'be', 'the', 'lion', 'whisperer', 'so', 'he', 'be', 'get', 'an', 'advantage', 'with', 'these', 'deadly', 'big', 'cat'], ['as', 'richardson', 'shower', 'the', 'pair', 'of', 'lion', 'with', 'love', 'the', 'volunteer', 'stay', 'locked', 'in', 'the', 'truck', 'unwilling', 'to', 'put', 'their', 'life', 'in', 'danger'], ['and', 'while', 'they', 'be', 'in', 'the', 'vehicle', 'the', 'lion', 'be', 'just', 'foot', 'from', 'they', 'and', 'if', 'something', 'go', 'wrong', 'they', 'could', 'wind', 'up', 'injure', 'anyway'], ['richardson', 'share', 'the', 'video', 'on', 'his', 'the', 'lion', 'whisperer', 'youtube', 'channel'], ['with', 'more', 'than', 'one', 'million', 'hit', 'this', 'video', 'have', 'prove', 'to', 'be', 'one', 'of', 'his', 'most', 'famous'], ['the', 'video', 'describe', 'the', 'moment', 'catch', 'on', 'tape', 'as', 'follow', 'it', 'be', 'an', 'enrichment', 'walk', 'for', 'both', 'the', 'volunteer', 'and', 'the', 'lion', 'as', 'kevin', 'show', 'off', 'his', 'lovely', 'lion', 'as', 'well', 'as', 'give', 'some', 'amazing', 'lion', 'fact', 'to', 'the', 'volunteer'], ['viewer', 'like', 'you', 'be', 'overwhelmed', 'with', 'the', 'magnificent', 'footage'], ['the', 'follow', 'be', 'a', 'few', 'comment', 'share', 'on', 'the', 'video'], ['i', 'hope', 'to', 'someday', 'volunteer', 'there', 'with', 'kevin'], ['i', 'believe', 'in', 'the', 'work', 'and', 'his', 'perspective', 'about', 'conservation'], ['this', 'video', 'make', 'i', 'want', 'to', 'all', 'the', 'more'], ['bobcat', 'and', 'gabby', 'be', 'lovely', 'lion'], ['every', 'time', 'i', 'watch', 'a', 'one', 'of', 'your', 'video', 'i', 'somehow', 'end', 'up', 'smile', 'from', 'ear', 'to', 'ear'], ['that', 'be', 'so', 'beautiful', 'wish', 'i', 'could', 'rub', 'my', 'head', 'against', 'a', 'lion'], ['take', 'a', 'moment', 'to', 'watch', 'this', 'video'], ['would', 'you', 'ever', 'want', 'to', 'volunteer', 'with', 'kevin', 'richardson', 'and', 'his', 'lion']]\n",
            "\n",
            "Documents shape: (33,)\n",
            "Documents: [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 3, 12, 7, 6, 13, 9, 14, 1, 2, 3, 12, 5, 7, 15, 6, 16, 1, 2, 3, 17, 18, 7, 15, 4, 3, 11, 18, 1, 4, 5, 6, 7, 19, 6, 7, 6, 1, 4, 5, 20, 3, 5, 7, 17, 18, 7, 15, 4, 3], [1, 2, 3, 10, 11, 3, 1, 2, 3, 21, 18, 4, 3, 21, 6, 16, 1, 2, 3, 9, 16, 21, 5, 22, 9, 7, 14, 9, 20, 9, 7, 7, 9, 2, 1, 2, 9, 1, 11, 3, 22, 6, 20, 3, 21, 5, 7, 11, 21, 6, 13, 7, 15, 21, 9, 14, 14, 9, 7, 19, 14, 23, 3, 22, 12, 4, 3, 13, 5, 1, 2, 14, 23, 9, 21, 14, 3, 1, 21, 3, 3], [4, 5, 6, 7, 22, 6, 4, 6, 21, 5, 7, 15, 2, 3, 4, 23, 1, 2, 3, 10, 11, 4, 3, 7, 19, 5, 7, 23, 3, 21, 16, 3, 22, 1, 4, 10, 13, 5, 1, 2, 1, 2, 3, 1, 9, 4, 4, 15, 21, 9, 14, 14, 14, 6, 1, 2, 3, 10, 22, 9, 7, 9, 8, 11, 18, 14, 2, 1, 2, 3, 5, 21, 23, 21, 3, 10, 9, 14, 13, 3, 4, 4, 9, 14, 23, 6, 14, 14, 5, 11, 4, 3], [9, 7, 19, 4, 5, 6, 7, 11, 3, 16, 3, 21, 6, 22, 5, 6, 18, 14], [9, 4, 1, 2, 6, 18, 15, 2, 1, 2, 3, 10, 11, 3, 6, 7, 3, 6, 16, 1, 2, 3, 8, 6, 14, 1, 23, 6, 13, 3, 21, 16, 18, 4, 23, 21, 3, 19, 9, 1, 6, 21, 6, 7, 4, 9, 7, 19, 4, 5, 6, 7, 11, 3, 5, 7, 19, 9, 7, 15, 3, 21], [2, 18, 7, 1, 3, 21, 9, 7, 19, 23, 6, 9, 22, 2, 3, 21, 1, 9, 21, 15, 3, 1, 4, 5, 6, 7, 1, 6, 23, 21, 6, 20, 3, 1, 6, 1, 2, 3, 13, 6, 21, 4, 19, 1, 2, 3, 5, 21, 8, 9, 22, 2, 5, 14, 8, 6], [9, 7, 19, 13, 2, 5, 4, 3, 2, 18, 7, 1, 3, 21, 14, 3, 3, 12, 1, 6, 13, 5, 23, 3, 4, 5, 6, 7, 6, 16, 16, 1, 2, 3, 16, 9, 22, 3, 6, 16, 1, 2, 3, 3, 9, 21, 1, 2, 1, 6, 11, 6, 4, 14, 1, 3, 21, 1, 2, 3, 5, 21, 3, 15, 6, 1, 2, 3, 12, 3, 20, 5, 7, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 13, 5, 4, 19, 4, 5, 16, 3, 14, 9, 7, 22, 1, 18, 9, 21, 10, 2, 6, 23, 3, 1, 6, 14, 1, 6, 23, 1, 2, 3, 10, 9, 7, 19, 23, 21, 6, 1, 3, 22, 1, 1, 2, 3, 11, 5, 15, 9, 16, 21, 5, 22, 9, 7, 22, 9, 1, 9, 1, 9, 4, 4, 22, 6, 14, 1], [21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 9, 20, 3, 3, 9, 21, 7, 1, 2, 3, 7, 5, 22, 12, 7, 9, 8, 3, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 16, 6, 21, 9, 21, 3, 9, 14, 6, 7], [2, 3, 9, 5, 8, 1, 6, 3, 19, 18, 22, 9, 1, 3, 1, 2, 3, 13, 6, 21, 4, 19, 9, 11, 6, 18, 1, 4, 5, 6, 7], [9, 7, 19, 16, 6, 21, 1, 2, 6, 14, 3, 4, 18, 22, 12, 10, 3, 7, 6, 18, 15, 2, 1, 6, 20, 6, 4, 18, 7, 1, 3, 3, 21, 9, 4, 6, 7, 15, 14, 5, 19, 3, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 3, 3, 7, 22, 6, 18, 21, 9, 15, 3, 1, 2, 3, 10, 1, 6, 4, 3, 9, 21, 7, 8, 6, 21, 3, 9, 11, 6, 18, 1, 4, 5, 6, 7, 9, 7, 19, 2, 3, 4, 23, 23, 21, 6, 1, 3, 22, 1, 1, 2, 3, 13, 5, 4, 19, 14, 23, 3, 22, 5, 3], [1, 6, 21, 9, 5, 14, 3, 9, 13, 9, 21, 3, 7, 3, 14, 14, 12, 3, 20, 5, 7, 2, 9, 20, 3, 7, 6, 13, 14, 3, 1, 18, 23, 2, 5, 14, 10, 6, 18, 1, 18, 11, 3, 22, 2, 9, 7, 7, 3, 4, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 1, 20], [1, 2, 3, 22, 2, 9, 7, 7, 3, 4, 11, 3, 9, 4, 4, 9, 11, 6, 18, 1, 21, 9, 5, 14, 3, 9, 13, 9, 21, 3, 7, 3, 14, 14, 9, 11, 6, 18, 1, 7, 6, 1, 6, 7, 4, 10, 1, 2, 3, 19, 3, 22, 4, 5, 7, 3, 7, 18, 8, 11, 3, 21, 6, 16, 4, 5, 6, 7, 11, 18, 1, 9, 4, 14, 6, 2, 6, 13, 1, 2, 5, 14, 21, 9, 23, 5, 19, 19, 3, 22, 21, 3, 9, 14, 3, 11, 3, 2, 9, 23, 23, 3, 7], [11, 10, 13, 9, 1, 22, 2, 1, 2, 3, 14, 3, 20, 5, 19, 3, 6, 10, 6, 18, 11, 3, 19, 5, 21, 3, 22, 1, 4, 10, 22, 6, 7, 1, 21, 5, 11, 18, 1, 3, 1, 6, 6, 18, 21, 14, 22, 2, 3, 8, 3, 6, 16, 4, 9, 7, 19, 9, 22, 24, 18, 5, 14, 5, 1, 5, 6, 7, 2, 3, 13, 21, 5, 1, 3, 5, 7, 2, 5, 14, 11, 5, 6], [9, 14, 23, 9, 21, 1, 6, 16, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 23, 21, 6, 15, 21, 9, 8, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 6, 14, 1, 9, 20, 6, 4, 18, 7, 1, 3, 3, 21, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 9, 7, 19, 4, 5, 6, 7, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 13, 9, 4, 12], [9, 14, 1, 2, 3, 7, 9, 8, 3, 14, 18, 15, 15, 3, 14, 1, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 1, 9, 12, 3, 2, 5, 14, 15, 21, 6, 18, 23, 6, 16, 20, 6, 4, 18, 7, 1, 3, 3, 21, 6, 18, 1, 5, 7, 1, 6, 1, 2, 3, 14, 9, 20, 9, 7, 7, 9, 2, 6, 16, 14, 6, 18, 1, 2, 9, 16, 21, 5, 22, 9, 1, 6, 2, 9, 7, 15, 6, 18, 1, 13, 5, 1, 2, 1, 13, 6, 4, 5, 6, 7], [1, 2, 3, 21, 3, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 8, 3, 3, 1, 9, 8, 9, 4, 3, 4, 5, 6, 7, 11, 6, 11, 22, 9, 1, 9, 7, 19, 9, 16, 3, 8, 9, 4, 3, 4, 5, 6, 7, 3, 14, 14, 15, 9, 11, 11, 10], [11, 6, 1, 2, 4, 5, 6, 7, 4, 6, 6, 12, 16, 3, 21, 6, 22, 5, 6, 18, 14, 11, 18, 1, 11, 3, 1, 21, 18, 4, 10, 9, 16, 16, 3, 22, 1, 5, 6, 7, 9, 1, 3, 9, 1, 4, 3, 9, 14, 1, 1, 2, 9, 1, 11, 3, 13, 2, 9, 1, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 9, 10], [9, 7, 19, 21, 3, 8, 3, 8, 11, 3, 21, 2, 3, 11, 3, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 14, 6, 2, 3, 11, 3, 15, 3, 1, 9, 7, 9, 19, 20, 9, 7, 1, 9, 15, 3, 13, 5, 1, 2, 1, 2, 3, 14, 3, 19, 3, 9, 19, 4, 10, 11, 5, 15, 22, 9, 1], [9, 14, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 2, 6, 13, 3, 21, 1, 2, 3, 23, 9, 5, 21, 6, 16, 4, 5, 6, 7, 13, 5, 1, 2, 4, 6, 20, 3, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 14, 1, 9, 10, 4, 6, 22, 12, 3, 19, 5, 7, 1, 2, 3, 1, 21, 18, 22, 12, 18, 7, 13, 5, 4, 4, 5, 7, 15, 1, 6, 23, 18, 1, 1, 2, 3, 5, 21, 4, 5, 16, 3, 5, 7, 19, 9, 7, 15, 3, 21], [9, 7, 19, 13, 2, 5, 4, 3, 1, 2, 3, 10, 11, 3, 5, 7, 1, 2, 3, 20, 3, 2, 5, 22, 4, 3, 1, 2, 3, 4, 5, 6, 7, 11, 3, 17, 18, 14, 1, 16, 6, 6, 1, 16, 21, 6, 8, 1, 2, 3, 10, 9, 7, 19, 5, 16, 14, 6, 8, 3, 1, 2, 5, 7, 15, 15, 6, 13, 21, 6, 7, 15, 1, 2, 3, 10, 22, 6, 18, 4, 19, 13, 5, 7, 19, 18, 23, 5, 7, 17, 18, 21, 3, 9, 7, 10, 13, 9, 10], [21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 2, 9, 21, 3, 1, 2, 3, 20, 5, 19, 3, 6, 6, 7, 2, 5, 14, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 10, 6, 18, 1, 18, 11, 3, 22, 2, 9, 7, 7, 3, 4], [13, 5, 1, 2, 8, 6, 21, 3, 1, 2, 9, 7, 6, 7, 3, 8, 5, 4, 4, 5, 6, 7, 2, 5, 1, 1, 2, 5, 14, 20, 5, 19, 3, 6, 2, 9, 20, 3, 23, 21, 6, 20, 3, 1, 6, 11, 3, 6, 7, 3, 6, 16, 2, 5, 14, 8, 6, 14, 1, 16, 9, 8, 6, 18, 14], [1, 2, 3, 20, 5, 19, 3, 6, 19, 3, 14, 22, 21, 5, 11, 3, 1, 2, 3, 8, 6, 8, 3, 7, 1, 22, 9, 1, 22, 2, 6, 7, 1, 9, 23, 3, 9, 14, 16, 6, 4, 4, 6, 13, 5, 1, 11, 3, 9, 7, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 13, 9, 4, 12, 16, 6, 21, 11, 6, 1, 2, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 9, 7, 19, 1, 2, 3, 4, 5, 6, 7, 9, 14, 12, 3, 20, 5, 7, 14, 2, 6, 13, 6, 16, 16, 2, 5, 14, 4, 6, 20, 3, 4, 10, 4, 5, 6, 7, 9, 14, 13, 3, 4, 4, 9, 14, 15, 5, 20, 3, 14, 6, 8, 3, 9, 8, 9, 25, 5, 7, 15, 4, 5, 6, 7, 16, 9, 22, 1, 1, 6, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21], [20, 5, 3, 13, 3, 21, 4, 5, 12, 3, 10, 6, 18, 11, 3, 6, 20, 3, 21, 13, 2, 3, 4, 8, 3, 19, 13, 5, 1, 2, 1, 2, 3, 8, 9, 15, 7, 5, 16, 5, 22, 3, 7, 1, 16, 6, 6, 1, 9, 15, 3], [1, 2, 3, 16, 6, 4, 4, 6, 13, 11, 3, 9, 16, 3, 13, 22, 6, 8, 8, 3, 7, 1, 14, 2, 9, 21, 3, 6, 7, 1, 2, 3, 20, 5, 19, 3, 6], [5, 2, 6, 23, 3, 1, 6, 14, 6, 8, 3, 19, 9, 10, 20, 6, 4, 18, 7, 1, 3, 3, 21, 1, 2, 3, 21, 3, 13, 5, 1, 2, 12, 3, 20, 5, 7], [5, 11, 3, 4, 5, 3, 20, 3, 5, 7, 1, 2, 3, 13, 6, 21, 12, 9, 7, 19, 2, 5, 14, 23, 3, 21, 14, 23, 3, 22, 1, 5, 20, 3, 9, 11, 6, 18, 1, 22, 6, 7, 14, 3, 21, 20, 9, 1, 5, 6, 7], [1, 2, 5, 14, 20, 5, 19, 3, 6, 8, 9, 12, 3, 5, 13, 9, 7, 1, 1, 6, 9, 4, 4, 1, 2, 3, 8, 6, 21, 3], [11, 6, 11, 22, 9, 1, 9, 7, 19, 15, 9, 11, 11, 10, 11, 3, 4, 6, 20, 3, 4, 10, 4, 5, 6, 7], [3, 20, 3, 21, 10, 1, 5, 8, 3, 5, 13, 9, 1, 22, 2, 9, 6, 7, 3, 6, 16, 10, 6, 18, 21, 20, 5, 19, 3, 6, 5, 14, 6, 8, 3, 2, 6, 13, 3, 7, 19, 18, 23, 14, 8, 5, 4, 3, 16, 21, 6, 8, 3, 9, 21, 1, 6, 3, 9, 21], [1, 2, 9, 1, 11, 3, 14, 6, 11, 3, 9, 18, 1, 5, 16, 18, 4, 13, 5, 14, 2, 5, 22, 6, 18, 4, 19, 21, 18, 11, 8, 10, 2, 3, 9, 19, 9, 15, 9, 5, 7, 14, 1, 9, 4, 5, 6, 7], [1, 9, 12, 3, 9, 8, 6, 8, 3, 7, 1, 1, 6, 13, 9, 1, 22, 2, 1, 2, 5, 14, 20, 5, 19, 3, 6], [13, 6, 18, 4, 19, 10, 6, 18, 3, 20, 3, 21, 13, 9, 7, 1, 1, 6, 20, 6, 4, 18, 7, 1, 3, 3, 21, 13, 5, 1, 2, 12, 3, 20, 5, 7, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 9, 7, 19, 2, 5, 14, 4, 5, 6, 7]]\n",
            "Word2Vec shape: (26, 128)\n",
            "Word2Vec embeddings: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [ 0.01426814 -0.01167079  0.17472358  0.02451202 -0.0146314  -0.22437303\n",
            "   0.02335371  0.05602231 -0.02234872 -0.01387153  0.26653907 -0.05030853\n",
            "  -0.00068698 -0.10203827 -0.00721283 -0.10466688 -0.01850976  0.12172594\n",
            "  -0.09240989  0.02927394  0.17173871  0.15838338  0.11998489  0.02099753\n",
            "  -0.08236817  0.14684002 -0.09575572  0.08313598  0.01323021 -0.07683573\n",
            "  -0.32091114  0.03759253 -0.01791698 -0.00506339 -0.03725468  0.03652476\n",
            "   0.25867468  0.15707438  0.22828494 -0.06669223 -0.07951992  0.13954708\n",
            "  -0.07149079 -0.05088308  0.10704181  0.10953268 -0.02580221 -0.0742599\n",
            "   0.00332422  0.15106489 -0.0009272   0.09217573  0.11712816  0.11890787\n",
            "   0.15584083  0.03268922  0.13046363 -0.10486653 -0.08755396 -0.02631432\n",
            "   0.12522706 -0.12577812  0.07208338 -0.0576773   0.09888031 -0.08793829\n",
            "   0.11042838  0.1055347   0.05165933 -0.01924107  0.08112093  0.05853751\n",
            "  -0.09811421 -0.07929015 -0.06172239  0.02687584  0.03930277  0.09222759\n",
            "  -0.03552807  0.19380179 -0.03264212 -0.06052406  0.07687467  0.20428325\n",
            "  -0.01435895  0.03375683  0.21907899 -0.11893818  0.09882214  0.13275041\n",
            "  -0.0781758  -0.06982379 -0.14670672 -0.00244088  0.17161368  0.0098353\n",
            "  -0.27421841 -0.23662367  0.04861191 -0.07159754 -0.27790108 -0.02046391\n",
            "   0.14918146  0.07859952  0.01451473 -0.06578263  0.08852482 -0.14673221\n",
            "  -0.06838238 -0.11625813  0.0136607  -0.03936399 -0.00687787  0.03544533\n",
            "  -0.04844701 -0.02486017 -0.03806767  0.18658037  0.03435673  0.11962222\n",
            "  -0.04799122 -0.02150991  0.05276656 -0.04505973  0.00580142 -0.16512619\n",
            "  -0.09466102  0.11376189]\n",
            " [ 0.01069803 -0.01231281  0.14518419  0.0204438  -0.01088602 -0.17598966\n",
            "   0.00833065  0.04347323 -0.00481787 -0.02158114  0.20726702 -0.04765896\n",
            "  -0.00126295 -0.08614693 -0.01786381 -0.08294852 -0.01708156  0.09440743\n",
            "  -0.06409531  0.02347251  0.13641952  0.12108126  0.0994399   0.01190965\n",
            "  -0.07184105  0.1269215  -0.07060238  0.06511528  0.00863533 -0.05984928\n",
            "  -0.2455287   0.03061523 -0.02736103  0.00465587 -0.02325613  0.03283887\n",
            "   0.20248501  0.12833275  0.18245511 -0.06108237 -0.07174747  0.11258866\n",
            "  -0.06035488 -0.0411214   0.09842044  0.07624574 -0.01116636 -0.05819609\n",
            "  -0.00789811  0.1191599  -0.00723719  0.06349182  0.08629052  0.10818785\n",
            "   0.12372454  0.01475551  0.1025928  -0.07787545 -0.07765857 -0.02814142\n",
            "   0.09423987 -0.10209151  0.06866963 -0.05695157  0.07962687 -0.05962692\n",
            "   0.07959348  0.08229937  0.04678059 -0.01064312  0.06261205  0.03586823\n",
            "  -0.08021802 -0.05837285 -0.05079154  0.02385141  0.03422551  0.07238963\n",
            "  -0.02973865  0.14886427 -0.03684855 -0.04575015  0.06676271  0.15424716\n",
            "  -0.01305245  0.01868596  0.17186469 -0.09584693  0.07460448  0.10343926\n",
            "  -0.05888079 -0.05763736 -0.11836696 -0.00461878  0.14090405  0.00590992\n",
            "  -0.21493477 -0.18017752  0.03992336 -0.05123723 -0.22765566 -0.0190749\n",
            "   0.10604523  0.06330604  0.01453854 -0.04981836  0.05683048 -0.11830492\n",
            "  -0.0630061  -0.09357455  0.00268722 -0.03938106 -0.00566507  0.02995277\n",
            "  -0.0365994  -0.01573006 -0.02281039  0.14167477  0.02888499  0.09110259\n",
            "  -0.03669268 -0.01797194  0.04051189 -0.03682881  0.00998741 -0.13692522\n",
            "  -0.07110612  0.09518564]\n",
            " [ 0.01662512 -0.00963249  0.21899961  0.03941166 -0.03072703 -0.26926529\n",
            "   0.02425867  0.07155393 -0.02495608 -0.02948857  0.31678078 -0.06390105\n",
            "   0.00110689 -0.12190038 -0.01732894 -0.13113871 -0.02391528  0.14521812\n",
            "  -0.11169282  0.0164629   0.20090546  0.18931329  0.152145    0.02390259\n",
            "  -0.09325831  0.18057568 -0.10610969  0.1039433   0.00740435 -0.08912654\n",
            "  -0.38382706  0.05039808 -0.02158199 -0.0111848  -0.04161471  0.03659898\n",
            "   0.30583656  0.18571232  0.26325518 -0.09020481 -0.10725439  0.16966991\n",
            "  -0.10136486 -0.05751793  0.13550626  0.12082892 -0.03669556 -0.08025928\n",
            "   0.00262416  0.1899344  -0.00905364  0.10441527  0.12773339  0.15158911\n",
            "   0.18488006  0.02806677  0.15369388 -0.12593539 -0.11613961 -0.02194664\n",
            "   0.13997334 -0.14460817  0.09126263 -0.08350857  0.11249023 -0.09938355\n",
            "   0.12027264  0.12313445  0.06837324 -0.02505738  0.0949908   0.07176551\n",
            "  -0.11973272 -0.10277515 -0.07172496  0.03864294  0.05971618  0.10908621\n",
            "  -0.04862962  0.2122063  -0.04931923 -0.06200745  0.10566786  0.23958744\n",
            "  -0.02528534  0.03515179  0.25992271 -0.14421873  0.10780093  0.1601916\n",
            "  -0.09545533 -0.0793061  -0.16792874 -0.00063342  0.20969054  0.01656567\n",
            "  -0.32295549 -0.27686545  0.06629122 -0.07973441 -0.33928758 -0.02968859\n",
            "   0.17868392  0.10122623  0.02260722 -0.08874979  0.09865589 -0.16671485\n",
            "  -0.08827821 -0.13865095  0.01609279 -0.0619944  -0.01124708  0.05803912\n",
            "  -0.05980857 -0.01789523 -0.03679199  0.21873464  0.03965407  0.14597574\n",
            "  -0.04985553 -0.03497259  0.07530799 -0.06502117  0.0173794  -0.2020923\n",
            "  -0.12162752  0.13692698]\n",
            " [ 0.01076326 -0.00582663  0.190841    0.02620758 -0.01386503 -0.23225605\n",
            "   0.0142345   0.0577458  -0.01106514 -0.01675737  0.28215945 -0.05389743\n",
            "   0.00610041 -0.11628971 -0.01730243 -0.11599246 -0.02437951  0.12767868\n",
            "  -0.09951808  0.02948712  0.16964984  0.15982027  0.1283766   0.02053068\n",
            "  -0.09491315  0.16460721 -0.09920134  0.08720211  0.00761104 -0.07601771\n",
            "  -0.3353788   0.04616341 -0.03143116 -0.006403   -0.02968033  0.03785565\n",
            "   0.2601153   0.16791449  0.2377865  -0.07390146 -0.09661515  0.15097788\n",
            "  -0.09031645 -0.05398095  0.12447488  0.1055982  -0.02435246 -0.07120929\n",
            "  -0.00475504  0.17156479 -0.00152224  0.09904926  0.12394615  0.12654568\n",
            "   0.15469857  0.03438149  0.13950916 -0.10022631 -0.09490686 -0.0206442\n",
            "   0.11895093 -0.12634788  0.08076153 -0.06518453  0.10718097 -0.0882149\n",
            "   0.11504623  0.10691418  0.06192927 -0.01858408  0.07665036  0.05771931\n",
            "  -0.09870957 -0.0886291  -0.06392521  0.02593266  0.05409769  0.1051613\n",
            "  -0.03947465  0.20264608 -0.04224396 -0.06474216  0.08869798  0.21492761\n",
            "  -0.02166305  0.02753776  0.23204611 -0.12199378  0.09890164  0.13602886\n",
            "  -0.08043444 -0.07655355 -0.15531817 -0.00535834  0.17577405  0.00390872\n",
            "  -0.286026   -0.24980485  0.05787139 -0.08307765 -0.30488935 -0.03579181\n",
            "   0.14829428  0.09191336  0.01830913 -0.07444263  0.08572639 -0.1610558\n",
            "  -0.07658516 -0.11851591  0.01469304 -0.04859789 -0.00412853  0.04545789\n",
            "  -0.06265733 -0.02796787 -0.04466161  0.18974166  0.04006062  0.13682947\n",
            "  -0.04815106 -0.02984632  0.06760707 -0.04937641  0.00818359 -0.17534268\n",
            "  -0.10208027  0.11513678]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.1557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText shape: (26, 128)\n",
            "FastText embeddings: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-3.52323800e-02 -3.48299444e-02  2.82304622e-02  4.07136530e-02\n",
            "  -1.04472548e-01 -2.44396105e-01 -3.75948958e-02  7.38183875e-03\n",
            "   6.85957968e-02  3.26619521e-02  1.44209370e-01 -5.93702272e-02\n",
            "   4.20250520e-02 -2.16344789e-01  1.27584010e-01 -1.24144316e-01\n",
            "  -8.72678123e-03  1.68112874e-01 -6.81267120e-03 -9.63566266e-03\n",
            "   1.10904485e-01  2.43105039e-01  7.53148645e-02  1.96272954e-02\n",
            "  -1.59128726e-01  7.75764883e-02 -6.83648139e-02  3.26289004e-03\n",
            "   4.39918712e-02 -2.07208857e-01 -2.25062117e-01 -2.87944376e-02\n",
            "   1.66184232e-01  3.92889231e-03 -7.27619380e-02  8.53168517e-02\n",
            "   2.74803579e-01 -1.39603680e-02  5.21855131e-02 -6.86397105e-02\n",
            "   1.22642312e-02 -1.11594036e-01  1.59861445e-02 -5.13485037e-02\n",
            "   1.40509784e-01  1.50717944e-01 -4.15291935e-02  4.83656712e-02\n",
            "  -7.22364336e-02  9.12505835e-02  1.39860898e-01  2.24456377e-02\n",
            "   9.30667818e-02  2.59151291e-02  5.52585162e-02 -1.02062216e-02\n",
            "   8.31423551e-02 -8.81509632e-02 -2.68845372e-02  1.06119007e-01\n",
            "   1.86198652e-02 -6.23142608e-02  1.22080911e-02  1.91566646e-02\n",
            "  -4.83184606e-02 -3.64245065e-02 -1.44400746e-02 -8.38904679e-02\n",
            "   2.46898495e-02 -4.87545468e-02  5.22756502e-02 -3.59568894e-02\n",
            "  -4.24603447e-02 -5.15601970e-02 -2.10293025e-01  5.34321740e-02\n",
            "   4.95279655e-02  3.28429967e-01 -1.11537993e-01  1.67659730e-01\n",
            "  -1.00721806e-01 -1.14052743e-02  1.31334946e-01  2.23227590e-01\n",
            "  -7.70187601e-02  9.82740670e-02  1.01069085e-01 -4.72271554e-02\n",
            "   1.40312225e-01  9.86572951e-02 -6.77364618e-02  3.77416015e-02\n",
            "  -7.81854317e-02  1.39599621e-01  2.15937197e-01 -1.08558133e-01\n",
            "  -1.38383895e-01 -1.94002345e-01  9.54547524e-02 -9.76328030e-02\n",
            "  -7.21049458e-02  4.62147444e-02  1.22757219e-01  2.27194145e-01\n",
            "  -5.08530624e-03  5.53931072e-02  7.05890730e-02 -1.72710389e-01\n",
            "   5.94581291e-02 -7.08239302e-02  4.11577597e-02 -7.16854632e-02\n",
            "   1.00968286e-01 -8.17405432e-03 -8.88271928e-02  7.74886110e-04\n",
            "  -1.35871768e-01  1.20594792e-01 -6.59490153e-02  2.58433539e-02\n",
            "  -1.07251093e-01  5.77731729e-02  7.49882758e-02 -1.04060397e-01\n",
            "   1.49280518e-01 -4.92643937e-02 -8.32262114e-02  8.13533366e-02]\n",
            " [-2.49142461e-02 -2.69111451e-02  3.08985673e-02  3.15985382e-02\n",
            "  -7.85746425e-02 -1.79293305e-01 -3.96664329e-02  1.03475321e-02\n",
            "   5.81012890e-02  1.39401900e-02  1.04118660e-01 -5.28611951e-02\n",
            "   3.22488807e-02 -1.69094697e-01  8.75598043e-02 -9.80247706e-02\n",
            "  -8.44891276e-03  1.22465715e-01 -2.94386642e-03 -7.94348400e-03\n",
            "   8.53443965e-02  1.85038835e-01  6.25933111e-02  1.05761830e-02\n",
            "  -1.23492151e-01  6.14166036e-02 -4.77214828e-02 -1.59340701e-03\n",
            "   3.48817930e-02 -1.53445393e-01 -1.68878168e-01 -2.54614949e-02\n",
            "   1.21195890e-01  1.00388248e-02 -5.06966785e-02  6.65910691e-02\n",
            "   2.11542204e-01 -1.26398690e-02  4.34512012e-02 -5.44222593e-02\n",
            "   5.44991298e-03 -7.99117684e-02  1.21237831e-02 -4.19694819e-02\n",
            "   1.14138357e-01  1.09638542e-01 -2.25588530e-02  3.56493443e-02\n",
            "  -5.67090474e-02  6.71925768e-02  1.04485109e-01  1.11787058e-02\n",
            "   6.61433265e-02  2.26159915e-02  4.13776487e-02 -1.33371809e-02\n",
            "   6.76593408e-02 -6.43638521e-02 -2.64330171e-02  7.70384967e-02\n",
            "   1.00943483e-02 -4.73505631e-02  1.09058749e-02  9.85908601e-03\n",
            "  -3.79901901e-02 -1.57056227e-02 -1.00912619e-02 -6.41863048e-02\n",
            "   2.08574347e-02 -3.17189433e-02  4.10855189e-02 -3.42999250e-02\n",
            "  -3.72842662e-02 -3.25267687e-02 -1.63568765e-01  4.18616273e-02\n",
            "   3.64649072e-02  2.56403923e-01 -8.65775421e-02  1.24862306e-01\n",
            "  -8.03344250e-02 -1.10071823e-02  9.85654891e-02  1.65249765e-01\n",
            "  -5.67353740e-02  7.08114952e-02  7.38755614e-02 -3.99260409e-02\n",
            "   1.08975433e-01  7.72978216e-02 -4.69471030e-02  2.63148695e-02\n",
            "  -5.82793802e-02  1.02737956e-01  1.62063211e-01 -8.80168825e-02\n",
            "  -1.05551228e-01 -1.48555905e-01  7.38225430e-02 -7.35366493e-02\n",
            "  -6.06050268e-02  3.55990604e-02  8.36117938e-02  1.71019465e-01\n",
            "  -2.53337040e-03  4.17100787e-02  4.75840196e-02 -1.28780261e-01\n",
            "   3.94122601e-02 -5.47841601e-02  2.76224390e-02 -5.90098202e-02\n",
            "   7.61291385e-02 -1.09804431e-02 -6.79591298e-02 -7.77780428e-04\n",
            "  -1.03193492e-01  8.51230919e-02 -4.83354069e-02  1.75367538e-02\n",
            "  -8.83279070e-02  4.37387116e-02  5.85687533e-02 -8.20807368e-02\n",
            "   1.15138829e-01 -3.60951498e-02 -5.84705956e-02  6.00235984e-02]\n",
            " [-4.65284325e-02 -3.66538391e-02  4.26087677e-02  5.00743911e-02\n",
            "  -1.25643179e-01 -2.87670285e-01 -4.82881814e-02  1.11053828e-02\n",
            "   8.54590237e-02  2.91890763e-02  1.64692074e-01 -7.37227574e-02\n",
            "   4.85347584e-02 -2.54947305e-01  1.41017944e-01 -1.52224138e-01\n",
            "  -6.13988284e-03  1.95250481e-01 -7.03924336e-03 -2.05415785e-02\n",
            "   1.31404102e-01  2.91826338e-01  9.35785621e-02  1.37404660e-02\n",
            "  -1.77830651e-01  9.04429331e-02 -7.39713311e-02  9.68066603e-03\n",
            "   4.85641845e-02 -2.41711482e-01 -2.67010868e-01 -3.88456509e-02\n",
            "   1.98047295e-01  1.03693898e-03 -8.40188861e-02  9.92229432e-02\n",
            "   3.24456781e-01 -1.92186385e-02  5.69323599e-02 -8.78925100e-02\n",
            "   8.49293545e-03 -1.31305188e-01  9.51230526e-03 -6.52611852e-02\n",
            "   1.63504541e-01  1.68117642e-01 -4.41725366e-02  6.48396462e-02\n",
            "  -8.60449225e-02  1.06023192e-01  1.59507960e-01  2.37962324e-02\n",
            "   1.08798631e-01  3.08027305e-02  6.64168373e-02 -1.71355568e-02\n",
            "   9.86371115e-02 -1.06766582e-01 -3.13782394e-02  1.28816053e-01\n",
            "   1.99728273e-02 -7.12755620e-02  1.50756016e-02  1.92695521e-02\n",
            "  -6.24293089e-02 -3.07491496e-02 -2.42310334e-02 -9.77854207e-02\n",
            "   3.71356085e-02 -5.43478951e-02  7.04184920e-02 -3.96475382e-02\n",
            "  -5.24351373e-02 -6.04662746e-02 -2.49076828e-01  6.65642321e-02\n",
            "   6.00496233e-02  3.93239081e-01 -1.33690029e-01  1.84551343e-01\n",
            "  -1.23195320e-01 -1.53479278e-02  1.56703219e-01  2.57396936e-01\n",
            "  -8.72405395e-02  1.08816594e-01  1.15357928e-01 -5.46123497e-02\n",
            "   1.59599572e-01  1.18129872e-01 -7.64348507e-02  4.37064022e-02\n",
            "  -8.04987922e-02  1.60828769e-01  2.54551321e-01 -1.32455885e-01\n",
            "  -1.58237696e-01 -2.31007561e-01  1.16853148e-01 -1.14193276e-01\n",
            "  -8.59611779e-02  5.31043261e-02  1.39466375e-01  2.70533353e-01\n",
            "  -5.75107522e-03  6.08504638e-02  7.33056366e-02 -1.99130088e-01\n",
            "   5.93274981e-02 -9.05643553e-02  4.82701994e-02 -9.08643603e-02\n",
            "   1.14543594e-01 -4.66418732e-03 -1.06788717e-01  4.59928485e-03\n",
            "  -1.60952017e-01  1.36389017e-01 -7.71313235e-02  2.63428614e-02\n",
            "  -1.28366202e-01  6.02822080e-02  9.09431055e-02 -1.23566061e-01\n",
            "   1.79128483e-01 -5.60861677e-02 -9.79298204e-02  8.92036930e-02]\n",
            " [-4.13031802e-02 -3.05674449e-02  3.12296264e-02  3.87924910e-02\n",
            "  -1.08590879e-01 -2.47271121e-01 -4.56898287e-02  9.07242298e-03\n",
            "   8.00001770e-02  3.28460857e-02  1.46915793e-01 -6.15403280e-02\n",
            "   4.07405719e-02 -2.30766699e-01  1.22389138e-01 -1.27013385e-01\n",
            "  -7.69438641e-03  1.72902659e-01 -1.00624533e-02 -8.24489165e-03\n",
            "   1.11878335e-01  2.48586148e-01  8.09872597e-02  1.59883071e-02\n",
            "  -1.66404843e-01  7.65665099e-02 -6.82032406e-02  4.46277251e-03\n",
            "   4.77180742e-02 -2.10600644e-01 -2.35447913e-01 -3.38145234e-02\n",
            "   1.61536604e-01  2.12277099e-03 -6.71671480e-02  9.04034376e-02\n",
            "   2.77064919e-01 -1.64568946e-02  5.55091053e-02 -7.26443678e-02\n",
            "   4.82468586e-03 -1.16596051e-01  9.46809538e-03 -5.92519864e-02\n",
            "   1.49925530e-01  1.44958735e-01 -3.78856286e-02  5.50831296e-02\n",
            "  -7.66891986e-02  9.53167379e-02  1.45874023e-01  2.66575329e-02\n",
            "   9.75911617e-02  2.16990486e-02  5.70396930e-02 -1.36959348e-02\n",
            "   8.39811340e-02 -9.10454765e-02 -2.66678035e-02  1.11182861e-01\n",
            "   7.97708798e-03 -6.36411607e-02  1.11409333e-02  2.26413794e-02\n",
            "  -5.09523228e-02 -3.36809456e-02 -1.81343202e-02 -8.56685638e-02\n",
            "   3.12557220e-02 -4.78790589e-02  5.44257239e-02 -4.10800353e-02\n",
            "  -4.55792770e-02 -5.10524884e-02 -2.11774901e-01  5.28454930e-02\n",
            "   6.05377294e-02  3.47838104e-01 -1.11810811e-01  1.64248437e-01\n",
            "  -1.05953261e-01 -1.34476237e-02  1.38377786e-01  2.24647909e-01\n",
            "  -8.42804611e-02  9.78736654e-02  1.01730421e-01 -5.02712429e-02\n",
            "   1.48703992e-01  9.81853083e-02 -6.87074363e-02  3.63312997e-02\n",
            "  -7.68008083e-02  1.39578640e-01  2.16679603e-01 -1.16029270e-01\n",
            "  -1.38453662e-01 -1.98014617e-01  1.04329430e-01 -1.05024830e-01\n",
            "  -7.66533762e-02  4.08310890e-02  1.20089591e-01  2.38714665e-01\n",
            "  -5.19134896e-03  5.31757958e-02  6.46219701e-02 -1.82325080e-01\n",
            "   6.04001582e-02 -7.15429485e-02  4.39241454e-02 -7.19837993e-02\n",
            "   1.03101946e-01 -9.74163041e-03 -9.18187350e-02 -2.84173788e-04\n",
            "  -1.39097512e-01  1.14466026e-01 -6.96508065e-02  2.52145212e-02\n",
            "  -1.16017230e-01  5.37935570e-02  8.28447044e-02 -1.08837947e-01\n",
            "   1.56873316e-01 -4.53081578e-02 -8.25790390e-02  7.48038292e-02]]\n",
            "GloVe shape: (26, 128)\n",
            "GloVe embeddings: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 1.66109474e-01 -5.37829329e-01  4.77579834e-01 -3.77278374e-01\n",
            "   5.51061955e-01 -2.23062216e-01  3.48056948e-01  1.03368990e-01\n",
            "   1.93460698e-01  1.01734143e-01  3.62829686e-01  2.36513193e-01\n",
            "   7.69270110e-01  5.27277114e-01  1.30552341e-01 -6.09084312e-01\n",
            "  -4.44910465e-01 -6.29890345e-01  4.81725527e-01  5.91924251e-01\n",
            "   4.91266100e-01 -3.14104006e-01  2.01377950e-02  3.00090303e-02\n",
            "  -5.79706270e-02  2.02003803e-01 -3.62677549e-01 -3.85847999e-01\n",
            "   6.11287514e-01  4.39262779e-01 -2.48481286e-01  5.99508334e-01\n",
            "  -2.58976690e-01 -5.53303639e-01 -5.90462653e-01  2.35062483e-01\n",
            "  -3.83352507e-01 -1.54362621e-01  3.19135068e-01 -4.25888113e-01\n",
            "  -6.02763358e-01 -1.50016957e-01  1.82076727e-01 -5.05232618e-01\n",
            "  -3.60749432e-01 -1.43643876e-01  2.47074854e-01 -2.70413470e-01\n",
            "  -3.71662560e-01  5.43134942e-01  2.19338669e-01  5.00256492e-01\n",
            "  -5.75013761e-01  6.77209814e-02 -2.70901760e-01  3.25411302e-01\n",
            "  -2.61920294e-01 -4.79507023e-02 -3.70687012e-01  4.39334584e-01\n",
            "  -3.88530606e-01 -3.07982603e-02 -3.62257032e-01  5.95953138e-01\n",
            "  -2.40234939e-01  5.97584908e-02 -4.09999909e-01  2.86376301e-01\n",
            "  -1.06361714e-01 -2.27128732e-01 -6.48390169e-01  3.44128044e-01\n",
            "  -3.03088889e-01  1.70027063e-01 -1.19771359e-02  1.31401908e-01\n",
            "   2.30187343e-02 -4.81989621e-01 -5.22483108e-01 -4.45878595e-01\n",
            "   3.32750722e-01 -5.54307291e-01 -1.25396422e-03  4.14717434e-01\n",
            "   4.00934680e-01  1.41517870e-01 -3.21789931e-01  5.91697755e-01\n",
            "  -4.29407419e-01  6.29056632e-01 -5.18468371e-01  1.06410679e-01\n",
            "  -4.02290949e-01  2.61743720e-01  4.21232759e-01  6.22522582e-02\n",
            "  -2.16277375e-01 -5.47471099e-01  3.64917792e-01  3.57488050e-01\n",
            "   1.62321345e-01 -6.09656966e-01 -4.92960378e-01 -1.97623734e-01\n",
            "   2.38309930e-01 -8.87901735e-02  2.88687359e-01 -1.91972705e-01\n",
            "  -4.50329563e-01  3.92434459e-01 -3.56921345e-01  1.47626247e-01\n",
            "   3.91845970e-01 -2.74735420e-01  4.39376916e-01  3.80189893e-01\n",
            "   1.14268562e-01  4.15253746e-01 -4.03953781e-01 -2.26172243e-01\n",
            "  -2.18854354e-01 -4.29341652e-01 -3.54013683e-01  2.98175182e-01\n",
            "   9.61403836e-02 -3.01283879e-01  5.09650802e-01 -1.92841229e-01]\n",
            " [ 2.12905413e-01 -5.38532725e-01  5.29542279e-01 -2.92723175e-01\n",
            "   3.55233440e-01 -4.07689170e-01  4.10369780e-01  8.06585058e-02\n",
            "   2.58578924e-01  3.90908396e-01  3.34637282e-01  5.52786119e-02\n",
            "   3.19340081e-01  5.24525586e-01  9.37370948e-02 -2.44167014e-01\n",
            "  -3.19093341e-01 -1.53679094e-01  1.93581669e-01  5.16183516e-01\n",
            "   3.34536476e-01 -2.38377535e-01 -1.41913280e-01 -6.85864225e-02\n",
            "  -3.31209758e-01  2.90125808e-01 -3.55172150e-01 -3.93029507e-01\n",
            "   4.74834269e-01  1.59177818e-01 -1.35851307e-01  2.36854836e-01\n",
            "   1.48279303e-01 -3.16713515e-01 -3.07114330e-01 -1.03567020e-01\n",
            "  -2.44608106e-01 -3.76059073e-01  6.44490154e-02 -3.29047002e-01\n",
            "  -3.20650214e-01 -2.73803288e-01 -7.79982400e-02 -2.91564519e-01\n",
            "  -5.05346855e-01 -3.89705251e-01  4.77740899e-01  3.41830125e-02\n",
            "  -2.22352111e-01  4.59625560e-01  3.70063305e-01  2.72005039e-01\n",
            "  -6.02195518e-01 -2.87777000e-01 -2.93216197e-01  2.82655930e-01\n",
            "  -3.20007700e-01  5.10138486e-02 -4.95386575e-01  4.19990498e-01\n",
            "  -1.73429757e-01  1.13476087e-01 -8.33773453e-02  4.45389303e-01\n",
            "  -4.39840947e-02 -1.69599465e-01 -3.63344207e-01  4.21851290e-01\n",
            "  -4.74790043e-01 -2.78874414e-02 -3.57668723e-01  3.09502053e-01\n",
            "  -4.15969973e-01  1.09929789e-01  8.87884255e-02  1.83177530e-01\n",
            "   2.46254568e-02 -5.13873931e-01 -5.89889109e-02 -2.09032054e-01\n",
            "   4.42219548e-01 -1.82286646e-01  9.47241155e-02  2.14548749e-01\n",
            "   3.33818171e-01  1.21367605e-01 -2.84762108e-01  5.29679851e-01\n",
            "  -2.08786753e-01  3.30822569e-01 -3.15290247e-01  1.96017151e-01\n",
            "  -3.03466034e-01  1.90859228e-01  4.24597279e-01  4.31345860e-01\n",
            "  -4.53587162e-01 -1.04084927e-01  4.04396819e-01  3.41090661e-01\n",
            "   5.35001029e-01 -2.90619850e-01 -6.02285861e-01 -7.14921652e-02\n",
            "   1.38939747e-01 -4.15879123e-01  2.24730482e-01 -1.99060556e-01\n",
            "  -2.13995937e-01  3.61343882e-01 -2.95710303e-01 -4.07603862e-02\n",
            "   4.04622347e-01 -3.04536064e-01  2.06967506e-01  1.12553913e-01\n",
            "   1.53719856e-01  2.76526952e-01 -2.80146899e-01 -4.49480682e-01\n",
            "  -5.35438359e-01 -5.51480736e-01 -8.63363692e-02  1.00988096e-01\n",
            "   3.57596712e-01 -1.63542382e-01  3.97624156e-01 -1.67622979e-01]\n",
            " [ 6.00094638e-01 -3.78200649e-01  4.90213731e-01 -3.51271808e-01\n",
            "   5.63146492e-01 -4.74274612e-01  3.89780678e-01 -8.56271115e-02\n",
            "   4.42497392e-01  2.36620279e-01  2.75406175e-01 -9.77709553e-02\n",
            "   5.02833005e-01  7.01075056e-01  2.29657225e-01 -4.83965051e-01\n",
            "  -2.05855517e-01 -5.31145996e-01  6.53925629e-01  2.90126274e-01\n",
            "   1.47635379e-01 -6.52444192e-01  2.33490703e-01 -4.74035736e-01\n",
            "  -3.74719015e-01  2.78805971e-01 -4.21831942e-01 -2.57944949e-01\n",
            "   3.48925192e-01  3.74881595e-01 -3.79040888e-01  5.37614316e-01\n",
            "  -2.99640108e-01 -4.98051489e-01 -4.47574032e-01 -1.48595491e-03\n",
            "  -2.94314359e-01 -5.76174299e-01  6.31302419e-01 -4.82982958e-01\n",
            "  -4.33973479e-01  3.17948687e-03  2.39469592e-01 -4.71468297e-01\n",
            "  -8.25650585e-02 -5.03439684e-01  1.59263076e-01 -2.72919235e-01\n",
            "  -5.41438433e-01  5.48297690e-01  1.54224305e-01  3.55136407e-01\n",
            "  -4.77310918e-01  1.27403640e-01 -5.25715387e-01  3.46918193e-01\n",
            "  -3.34857011e-01 -1.65441341e-01 -4.47408965e-01  2.21311399e-01\n",
            "  -5.70121572e-01  2.25633152e-01 -3.12749430e-01  6.56141277e-01\n",
            "  -1.53767341e-01  4.08911563e-01 -5.11296856e-01  4.79032115e-01\n",
            "  -6.12537982e-01 -2.58542827e-01 -6.25611408e-01  1.81346961e-01\n",
            "  -5.06379637e-01  2.34652579e-01 -1.95794970e-01  3.10233647e-01\n",
            "  -1.51301137e-01 -4.14833192e-01 -4.27035967e-01 -2.21044574e-01\n",
            "   4.47426557e-01 -6.31408308e-01 -2.67589486e-01  4.02501379e-01\n",
            "   3.94811482e-01  1.21334934e-01 -2.01668490e-01  4.99339631e-01\n",
            "  -3.77717341e-01  4.46409608e-01 -4.59543166e-01  5.76739334e-02\n",
            "  -2.98939557e-01  4.34427757e-01  3.82522856e-01  2.90240449e-01\n",
            "  -6.85786247e-01 -1.98881417e-01  3.42341126e-01  6.67460271e-01\n",
            "   5.78607644e-01 -1.31202261e-01 -4.64371678e-01 -1.52752856e-02\n",
            "   2.72800158e-01 -3.92636080e-01  6.06133638e-01 -3.43079947e-01\n",
            "  -5.98090151e-01  4.49891858e-01 -3.71376003e-01  1.34703822e-01\n",
            "   2.99369546e-01 -5.26244105e-01  3.79397281e-01  3.69540314e-01\n",
            "   2.31095215e-01  4.73056102e-01 -4.78084043e-01 -2.40961169e-01\n",
            "  -6.52260836e-01 -5.01456664e-01 -4.83490997e-01  1.72943347e-01\n",
            "  -5.02503229e-02 -1.86919783e-01  4.55695492e-01 -4.40305379e-01]\n",
            " [ 3.00942480e-01 -2.06538165e-01 -1.97768068e-01  7.83017356e-02\n",
            "   7.44862786e-02 -2.87233004e-01  6.03341145e-01 -1.70554091e-01\n",
            "   5.05364287e-01  2.12309712e-01  4.35663105e-01 -4.05601629e-01\n",
            "   1.91578202e-01  2.07421534e-01  2.72411025e-01 -3.31150588e-01\n",
            "  -3.09848705e-01 -3.99429432e-01  1.78542076e-01  2.37089512e-01\n",
            "   3.94355113e-01 -8.23516144e-02  5.99522252e-02 -6.02740625e-01\n",
            "  -2.60061633e-01  1.55733232e-01 -5.95748021e-01 -2.67471438e-01\n",
            "   1.50125448e-01  3.36640342e-01 -3.73250004e-01  6.08227114e-01\n",
            "  -1.74208207e-01 -1.19901995e-01 -2.86079730e-01  5.84868880e-01\n",
            "  -2.92388608e-01 -4.83416929e-01  5.57225741e-01 -5.89469275e-01\n",
            "  -2.51238459e-01  4.44872203e-01  4.00965086e-01 -2.75089759e-01\n",
            "   2.72838805e-01 -6.62019670e-01  1.10949975e-01 -3.21921895e-01\n",
            "  -4.24181593e-01  3.37009860e-01  1.68423751e-01  5.08547618e-01\n",
            "   1.02261500e-01  1.04694565e-01 -2.68418931e-01  2.01204471e-01\n",
            "  -2.53650534e-01 -2.02874505e-01 -2.00041954e-01  2.17414897e-02\n",
            "  -4.73843845e-01  6.60481176e-02  1.34768237e-01  1.97189204e-01\n",
            "  -1.91482481e-01  4.08308135e-01 -7.83504869e-02  1.97272397e-01\n",
            "  -4.16113801e-01 -1.61542161e-01 -3.00144287e-01 -5.17462363e-02\n",
            "  -1.94819083e-01  3.06140291e-01 -1.49655562e-01  5.50613033e-01\n",
            "  -8.81552888e-02 -6.38336180e-01 -1.99994544e-01 -4.29551050e-01\n",
            "  -1.24643332e-02 -3.21658434e-01 -1.75761657e-02  3.63061500e-01\n",
            "   8.73258629e-02 -3.13644067e-01 -5.03173330e-01  4.64010774e-01\n",
            "  -1.05077794e-01  2.12811892e-02  2.70932752e-03 -1.05595838e-01\n",
            "  -5.96899509e-01  6.70190756e-01  2.87625481e-01  7.85221624e-02\n",
            "  -4.63448371e-01 -5.24152046e-01  5.47332788e-01  4.05800945e-01\n",
            "   4.07015052e-01 -3.87766635e-01  4.17366585e-04 -5.55204757e-01\n",
            "   1.71494795e-01 -1.87444040e-01  3.69024979e-02 -3.79769614e-01\n",
            "  -3.35069244e-01  9.78852338e-02 -2.22936892e-01  3.72087037e-03\n",
            "   3.05527025e-01 -3.26068338e-01  3.55925266e-01  6.12831557e-01\n",
            "   3.92876310e-01  3.27044990e-01  4.20223474e-03 -2.74182554e-01\n",
            "  -4.77214528e-01 -1.06713162e-01 -4.46870537e-01 -1.02018810e-01\n",
            "  -3.29633173e-01 -4.38966076e-01  4.02116555e-01 -3.67616284e-01]]\n",
            "\n",
            "Comparison for word 'lion' (ID varies):\n",
            "'lion' not found in vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "S6BE_eCL3gmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install numpy==1.26.4 gensim==4.3.3 spacy==3.7.2 stop-words==2018.7.23 pandas scipy -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import io as sio\n",
        "import re\n",
        "import spacy\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe\n",
        "from multiprocessing import cpu_count\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define stop words (simplified for brevity; use your full list)\n",
        "def stopWordsEN():\n",
        "    sw_stop_words = get_stop_words('en')\n",
        "    sw_nltk = stopwords.words('english')\n",
        "    sw_spacy = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
        "    return list(set(sw_stop_words + sw_nltk + sw_spacy))\n",
        "\n",
        "# Tokenization setup\n",
        "specialchar_dic = {\n",
        "    \"’\": \"'\", \"„\": \"\\\"\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"«\": \"<<\", \"»\": \">>\",\n",
        "    \"…\": \"...\", \"—\": \"--\", \"¡\": \"!\", \"¿\": \"?\", \"©\": \" \", \"–\": \" \"\n",
        "}\n",
        "punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "specialchar_re = re.compile('(%s)' % '|'.join(specialchar_dic.keys()))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "cachedStopWords_en = stopWordsEN()\n",
        "\n",
        "class Tokenization:\n",
        "    def applyFE(self, text):\n",
        "        final_text = text.replace('cannot', 'can not').replace('can\\'t', 'can not')\n",
        "        final_text = final_text.replace('won\\'t', 'will not').replace('n\\'t', ' not').replace(' not ', ' not')\n",
        "        return final_text\n",
        "\n",
        "    def removeStopWords(self, text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords_en])\n",
        "\n",
        "    def removePunctuation(self, text, punctuation=punctuation):\n",
        "        for c in punctuation:\n",
        "            text = text.replace(c, ' ')\n",
        "        return text\n",
        "\n",
        "    def replaceUTF8Char(self, text, specialchars=specialchar_dic):\n",
        "        def replace(match):\n",
        "            return specialchars[match.group(0)]\n",
        "        return specialchar_re.sub(replace, text)\n",
        "\n",
        "    def createCorpus(self, text, remove_punctuation=True, remove_stopwords=True, apply_FE=True):\n",
        "        if pd.isna(text):\n",
        "            text = \"\"\n",
        "        corpus = []\n",
        "        try:\n",
        "            text = self.replaceUTF8Char(text).replace(\"\\n\", \" \")\n",
        "            doc = nlp(text)\n",
        "            processed_text = ' '.join([t.lemma_ if t.lemma_ != '-PRON-' else t.text if not t.ent_type_ else t.text for t in doc])\n",
        "            processed_text = processed_text.replace(\"\\s\\s+\", ' ')\n",
        "            doc = nlp(processed_text.lower())\n",
        "            rawText = not (remove_punctuation or remove_stopwords or apply_FE)\n",
        "            for sentence in doc.sents:\n",
        "                sent = str(sentence.text)\n",
        "                if len(sent) == 0:\n",
        "                    continue\n",
        "                if not rawText:\n",
        "                    if apply_FE:\n",
        "                        sent = self.applyFE(text=sent)\n",
        "                    if remove_punctuation:\n",
        "                        sent = self.removePunctuation(text=sent)\n",
        "                    if remove_stopwords:\n",
        "                        sent = self.removeStopWords(text=sent)\n",
        "                sent = sent.lower().split()\n",
        "                if sent:\n",
        "                    corpus.append(sent)\n",
        "        except Exception as exp:\n",
        "            print('exception=', str(exp))\n",
        "            print('text=', text)\n",
        "        return corpus\n",
        "\n",
        "class WordEmbeddings:\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=cpu_count(), sg=0):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components)\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=cpu_count(), sg=0):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "def processElement(elem):\n",
        "    idx, text = elem  # Unpack as (index, text)\n",
        "    tkn = Tokenization()\n",
        "    text = tkn.createCorpus(text, remove_stopwords=False)\n",
        "    return idx, text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    file_path = '/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv'\n",
        "    df = pd.read_csv(file_path, encoding='latin-1')\n",
        "    print(\"Dataset Head:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset Info:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Label mapping\n",
        "    label2id = {\n",
        "        'mostly true': 0,\n",
        "        'mixture of true and false': 1,\n",
        "        'no factual content': 1,\n",
        "        'mostly false': 1\n",
        "    }\n",
        "    df['Rating'] = df['Rating'].map(label2id)\n",
        "    y = df['Rating'].astype(int).to_numpy()\n",
        "    sio.savemat('labels.mat', {'y': y})\n",
        "\n",
        "    # Network features\n",
        "    network_cols = ['share_count', 'reaction_count', 'comment_count']\n",
        "    X_network = df[network_cols].fillna(0).to_numpy()\n",
        "    scaler_std = StandardScaler()\n",
        "    X_net_std = scaler_std.fit_transform(X_network)\n",
        "    X_net_std = X_net_std.reshape((X_net_std.shape[0], 1, X_net_std.shape[1]))\n",
        "    print(\"\\nX_network shape:\", X_network.shape)\n",
        "    print(\"X_net_std shape:\", X_net_std.shape)\n",
        "    sio.savemat('network.mat', {'X_net_std': X_net_std})\n",
        "\n",
        "    # Tokenization\n",
        "    print(\"\\nStart Tokenization\")\n",
        "    # Use row indices (0 to 2281) paired with Context Post\n",
        "    texts = list(enumerate(df['Context Post'].tolist()))\n",
        "    corpus = [None] * len(texts)\n",
        "    no_threads = cpu_count() - 1\n",
        "    with ProcessPoolExecutor(max_workers=no_threads) as worker:\n",
        "        for result in worker.map(processElement, texts):\n",
        "            if result:\n",
        "                corpus[result[0]] = result[1]\n",
        "\n",
        "    print(\"Corpus sample (first 5):\")\n",
        "    for idx, doc in enumerate(corpus[:5]):\n",
        "        print(idx, doc)\n",
        "\n",
        "    # Word Embeddings\n",
        "    print(\"\\nStart Document Tokenization\")\n",
        "    we = WordEmbeddings(corpus)\n",
        "    documents = we.prepareDocuments()\n",
        "    vocabulary_size = we.no_words\n",
        "    max_size = we.max_size\n",
        "    print(\"Vocabulary size:\", vocabulary_size)\n",
        "    print(\"Max Document size:\", max_size)\n",
        "\n",
        "    X_docs = []\n",
        "    for document in documents:\n",
        "        doc_size = len(document)\n",
        "        X_docs.append(document + [0] * (max_size - doc_size))\n",
        "    X_docs = np.array(X_docs)\n",
        "    sio.savemat('corpus.mat', {'X': X_docs})\n",
        "\n",
        "    print(\"Start W2V CBOW\")\n",
        "    w2v_cbow = we.word2vecEmbedding(sg=0)\n",
        "    sio.savemat('w2v_cbow.mat', {'w2v_cbow': w2v_cbow})\n",
        "\n",
        "    print(\"Start W2V SG\")\n",
        "    w2v_sg = we.word2vecEmbedding(sg=1)\n",
        "    sio.savemat('w2v_sg.mat', {'w2v_sg': w2v_sg})\n",
        "\n",
        "    print(\"Start FT CBOW\")\n",
        "    ft_cbow = we.word2FastTextEmbeddings(sg=0)\n",
        "    sio.savemat('ft_cbow.mat', {'ft_cbow': ft_cbow})\n",
        "\n",
        "    print(\"Start FT SG\")\n",
        "    ft_sg = we.word2FastTextEmbeddings(sg=1)\n",
        "    sio.savemat('ft_sg.mat', {'ft_sg': ft_sg})\n",
        "\n",
        "    print(\"Start GLOVE\")\n",
        "    glove = we.word2GloVeEmbedding()\n",
        "    sio.savemat('glove.mat', {'glove': glove})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8obA6Gw5sU6",
        "outputId": "9c7ef4fd-d9cf-457a-88ac-44e18b64ed4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset Head:\n",
            "     account_id       post_id    Category               Page  \\\n",
            "0  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "2  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "3  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "4  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "\n",
            "                                            Post URL Date Published Post Type  \\\n",
            "0  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "1  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "2  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "3  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "4  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "\n",
            "               Rating Debate  share_count  reaction_count  comment_count  \\\n",
            "0  no factual content    NaN          NaN           146.0           15.0   \n",
            "1         mostly true    NaN          1.0            33.0           34.0   \n",
            "2         mostly true    NaN         34.0            63.0           27.0   \n",
            "3         mostly true    NaN         35.0           170.0           86.0   \n",
            "4         mostly true    NaN        568.0          3188.0         2815.0   \n",
            "\n",
            "                                        Context Post  \n",
            "0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1  Can either candidate move the needle in the de...  \n",
            "2  BREAKING: Ahmad Rahami, 28, wanted in connecti...  \n",
            "3  Donald J. Trump: &quot;Do we have a choice? Lo...  \n",
            "4  WATCH LIVE: Hillary Clinton holds news confere...  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2282 entries, 0 to 2281\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   account_id      2282 non-null   float64\n",
            " 1   post_id         2282 non-null   float64\n",
            " 2   Category        2282 non-null   object \n",
            " 3   Page            2282 non-null   object \n",
            " 4   Post URL        2282 non-null   object \n",
            " 5   Date Published  2282 non-null   object \n",
            " 6   Post Type       2282 non-null   object \n",
            " 7   Rating          2282 non-null   object \n",
            " 8   Debate          298 non-null    object \n",
            " 9   share_count     2212 non-null   float64\n",
            " 10  reaction_count  2280 non-null   float64\n",
            " 11  comment_count   2280 non-null   float64\n",
            " 12  Context Post    2282 non-null   object \n",
            "dtypes: float64(5), object(8)\n",
            "memory usage: 231.9+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "account_id           0\n",
            "post_id              0\n",
            "Category             0\n",
            "Page                 0\n",
            "Post URL             0\n",
            "Date Published       0\n",
            "Post Type            0\n",
            "Rating               0\n",
            "Debate            1984\n",
            "share_count         70\n",
            "reaction_count       2\n",
            "comment_count        2\n",
            "Context Post         0\n",
            "dtype: int64\n",
            "\n",
            "X_network shape: (2282, 3)\n",
            "X_net_std shape: (2282, 1, 3)\n",
            "\n",
            "Start Tokenization\n",
            "Corpus sample (first 5):\n",
            "0 [['watch', 'quot', 'jeb', 'exclamation', 'point', 'quot', 'jeb', 'bush', 'now', 'drive', 'around', 'selina', 'meyer', 'in', 'the', 'opening', 'intro', 'to', 'the', 'emmys', 'with', 'jimmy', 'kimmel']]\n",
            "1 [['can', 'either', 'candidate', 'move', 'the', 'needle', 'in', 'the', 'debate'], ['an', 'abc', 'news', 'review', 'of', 'datum', 'since', '1960', 'suggest', 'that', 'past', 'debate', 'have', 'almost', 'never', 'directly', 'and']]\n",
            "2 [['breaking', 'ahmad', 'rahami', '28', 'want', 'in', 'connection', 'with', 'nyc', 'bombing', 'say', 'nypd']]\n",
            "3 [['donald', 'j', 'trump', 'quot', 'do', 'we', 'have', 'a', 'choice'], ['look', 'what', '039', 'go', 'on'], ['do', 'we', 'really', 'have', 'a', 'choice'], ['we', '039', 're', 'try', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', 'and']]\n",
            "4 [['watch', 'live', 'hillary', 'clinton', 'hold', 'news', 'conference', 'in', 'white', 'plains', 'ny'], ['http', 'abcn', 'ws', '2cyazvp']]\n",
            "\n",
            "Start Document Tokenization\n",
            "Vocabulary size: 4023\n",
            "Max Document size: 117\n",
            "Start W2V CBOW\n",
            "Start W2V SG\n",
            "Start FT CBOW\n",
            "Start FT SG\n",
            "Start GLOVE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 116.4637"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset Size: 2282 samples.\n",
        "\n",
        "- Network Features: X_net_std has shape (2282, 1, 3) (from share_count, reaction_count, comment_count).\n",
        "\n",
        "- Text Data: X_docs will have shape (2282, 117) (max document size is 117).\n",
        "\n",
        "- Vocabulary Size: 4023 unique words (including padding token 0).\n",
        "\n",
        "- Embeddings: Successfully generated w2v_cbow, w2v_sg, ft_cbow, ft_sg, and glove, each with 128 dimensions (default no_components).\n",
        "\n"
      ],
      "metadata": {
        "id": "2BoiXHOL7ll_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Script"
      ],
      "metadata": {
        "id": "Au4jSj444VEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlJaMAFn8tkL",
        "outputId": "61bef8c8-1c86-463a-8bf2-fa8eeefd2e47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m863.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy import io as sio\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, Concatenate, Conv1D, Flatten, MaxPooling1D, Reshape\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 2\n",
        "batch_size = 256\n",
        "epochs_n = 5\n",
        "units = 128\n",
        "filters = int(units / 2)\n",
        "no_attributes_lstm = units\n",
        "kernel_size_lstm = int(no_attributes_lstm / 2)\n",
        "no_attributes_bilstm = int(units * 2)\n",
        "kernel_size_bilstm = int(no_attributes_bilstm / 2)\n",
        "\n",
        "execution = {}\n",
        "accuracies = {}\n",
        "precisions = {}\n",
        "recalls = {}\n",
        "\n",
        "def evaluate(y_test, y_pred, modelName='LSTM', wordemb='w2v_sg', iters=0):\n",
        "    y_pred_norm = []\n",
        "    for elem in y_pred:\n",
        "        line = [0] * len(elem)\n",
        "        try:\n",
        "            elem[np.isnan(elem)] = 0\n",
        "            line[elem.tolist().index(max(elem.tolist()))] = 1\n",
        "        except:\n",
        "            print(\"Error for getting predicted class\")\n",
        "            print(elem.tolist())\n",
        "            line[random.randint(0, len(elem)-1)] = 1\n",
        "        y_pred_norm.append(line)\n",
        "    y_p = np.argmax(np.array(y_pred_norm), 1)\n",
        "    y_t = np.argmax(np.array(y_test), 1)\n",
        "    accuracy = accuracy_score(y_t, y_p)\n",
        "    accuracies[wordemb][modelName].append(accuracy)\n",
        "    precision = precision_score(y_t, y_p, average='weighted')\n",
        "    precisions[wordemb][modelName].append(precision)\n",
        "    recall = recall_score(y_t, y_p, average='weighted')\n",
        "    recalls[wordemb][modelName].append(recall)\n",
        "    print(f\"{modelName} {wordemb} Accuracy {accuracy:.4f}\")\n",
        "    print(f\"{modelName} {wordemb} Precision {precision:.4f}\")\n",
        "    print(f\"{modelName} {wordemb} Recall {recall:.4f}\")\n",
        "    return y_p, y_t\n",
        "\n",
        "# Model definitions with corrected shapes\n",
        "def modelContentNetworkLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')  # Tuple (117,)\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-00CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Reshape((no_attributes_lstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_lstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-01CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-10CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Reshape((no_attributes_lstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_lstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-11CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"LSTM-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"LSTM-CNN-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-00CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Reshape((no_attributes_bilstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_bilstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-01CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-10CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Reshape((no_attributes_bilstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_bilstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-11CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentBiLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"BiLSTM-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentBiLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"BiLSTM-CNN-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    y = sio.loadmat('labels.mat')['y'][0]\n",
        "    X_net_std = sio.loadmat('network.mat')['X_net_std']\n",
        "    X_docs = sio.loadmat('corpus.mat')['X']\n",
        "    print(\"y shape:\", y.shape)\n",
        "    print(\"X_net_std shape:\", X_net_std.shape)\n",
        "    print(\"X_docs shape:\", X_docs.shape)\n",
        "\n",
        "    # Verify vocabulary size\n",
        "    vocabulary_size = 4023\n",
        "    max_size = 117\n",
        "    print(f\"Vocabulary size: {vocabulary_size}, Max size: {max_size}\")\n",
        "\n",
        "    embedding_types = ['w2v_cbow', 'w2v_sg', 'ft_cbow', 'ft_sg', 'glove']\n",
        "    models = [\n",
        "        \"LSTM-00CNN-ContentNets\", \"LSTM-01CNN-ContentNets\", \"LSTM-10CNN-ContentNets\", \"LSTM-11CNN-ContentNets\",\n",
        "        \"LSTM-Content\", \"LSTM-CNN-Content\",\n",
        "        \"BiLSTM-00CNN-ContentNets\", \"BiLSTM-01CNN-ContentNets\", \"BiLSTM-10CNN-ContentNets\", \"BiLSTM-11CNN-ContentNets\",\n",
        "        \"BiLSTM-Content\", \"BiLSTM-CNN-Content\"\n",
        "    ]\n",
        "\n",
        "    for wordemb in embedding_types:\n",
        "        accuracies[wordemb] = {model: [] for model in models}\n",
        "        precisions[wordemb] = {model: [] for model in models}\n",
        "        recalls[wordemb] = {model: [] for model in models}\n",
        "        execution[wordemb] = {model: [] for model in models}\n",
        "\n",
        "        w2v = sio.loadmat(f'{wordemb}.mat')[wordemb]\n",
        "        print(f\"Loaded {wordemb} shape: {w2v.shape}\")\n",
        "\n",
        "        for idx in range(5):\n",
        "            X_train_docs, X_test_docs, X_train_net, X_test_net, y_train, y_test = train_test_split(\n",
        "                X_docs, X_net_std, y, test_size=0.30, shuffle=True, stratify=y)\n",
        "            X_train_docs, X_val_docs, X_train_net, X_val_net, y_train, y_val = train_test_split(\n",
        "                X_train_docs, X_train_net, y_train, test_size=0.20, shuffle=True, stratify=y_train)\n",
        "            y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "            y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "            y_val = to_categorical(y_val, num_classes=num_classes)\n",
        "\n",
        "            print(f\"\\nIteration {idx+1} - Split shapes:\")\n",
        "            print(\"X_train_docs:\", X_train_docs.shape, \"X_val_docs:\", X_val_docs.shape, \"X_test_docs:\", X_test_docs.shape)\n",
        "            print(\"X_train_net:\", X_train_net.shape, \"X_val_net:\", X_val_net.shape, \"X_test_net:\", X_test_net.shape)\n",
        "            print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "            print(f\"\\nRunning models with {wordemb} embedding:\")\n",
        "            modelContentLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentBiLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentBiLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "\n",
        "        print(f\"\\nSummary for {wordemb}:\")\n",
        "        for model in models:\n",
        "            print(f\"{model} {wordemb} ACCURACY {np.mean(accuracies[wordemb][model]):.4f} ± {np.std(accuracies[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} PRECISION {np.mean(precisions[wordemb][model]):.4f} ± {np.std(precisions[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} RECALL {np.mean(recalls[wordemb][model]):.4f} ± {np.std(recalls[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} EXECUTION TIME {np.mean(execution[wordemb][model]):.2f} ± {np.std(execution[wordemb][model]):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ9z0Kf_8qSV",
        "outputId": "7bf04fe0-d0f4-4703-de49-a88f6d151dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape: (2282,)\n",
            "X_net_std shape: (2282, 1, 3)\n",
            "X_docs shape: (2282, 117)\n",
            "Vocabulary size: 4023, Max size: 117\n",
            "Loaded w2v_cbow shape: (4023, 128)\n",
            "\n",
            "Iteration 1 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7176 - loss: 0.5778 - val_accuracy: 0.7063 - val_loss: 0.5068\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 392ms/step - accuracy: 0.7441 - loss: 0.4767 - val_accuracy: 0.7094 - val_loss: 0.4921\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 547ms/step - accuracy: 0.7487 - loss: 0.4796 - val_accuracy: 0.7188 - val_loss: 0.4883\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355ms/step - accuracy: 0.7325 - loss: 0.4754 - val_accuracy: 0.7156 - val_loss: 0.4913\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 349ms/step - accuracy: 0.7483 - loss: 0.4720 - val_accuracy: 0.7156 - val_loss: 0.4971\n",
            "LSTM-Content w2v_cbow Accuracy 0.7620\n",
            "LSTM-Content w2v_cbow Precision 0.7878\n",
            "LSTM-Content w2v_cbow Recall 0.7620\n",
            "Time taken to train: 40.27 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 563ms/step - accuracy: 0.7347 - loss: 0.5868 - val_accuracy: 0.7312 - val_loss: 0.5048\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7446 - loss: 0.4925 - val_accuracy: 0.7312 - val_loss: 0.5100\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 416ms/step - accuracy: 0.7374 - loss: 0.4854 - val_accuracy: 0.7437 - val_loss: 0.4989\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 536ms/step - accuracy: 0.7329 - loss: 0.4710 - val_accuracy: 0.7188 - val_loss: 0.5056\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.7484 - loss: 0.4649 - val_accuracy: 0.7250 - val_loss: 0.5013\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7664\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7937\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7664\n",
            "Time taken to train: 18.65 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 627ms/step - accuracy: 0.6026 - loss: 0.5929 - val_accuracy: 0.7094 - val_loss: 0.5228\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7427 - loss: 0.5012 - val_accuracy: 0.7156 - val_loss: 0.4963\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7341 - loss: 0.4832 - val_accuracy: 0.7500 - val_loss: 0.4984\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 419ms/step - accuracy: 0.7354 - loss: 0.4885 - val_accuracy: 0.7312 - val_loss: 0.4875\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 653ms/step - accuracy: 0.7325 - loss: 0.4705 - val_accuracy: 0.7750 - val_loss: 0.4827\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7460\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7163\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7460\n",
            "Time taken to train: 21.14 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5562 - loss: 0.6063 - val_accuracy: 0.7406 - val_loss: 0.5296\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.7332 - loss: 0.5093 - val_accuracy: 0.7156 - val_loss: 0.4919\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7342 - loss: 0.4893 - val_accuracy: 0.7812 - val_loss: 0.4889\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7445 - loss: 0.4557 - val_accuracy: 0.7250 - val_loss: 0.4760\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - accuracy: 0.7562 - loss: 0.4597 - val_accuracy: 0.7812 - val_loss: 0.4765\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7590\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 19.89 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 593ms/step - accuracy: 0.5726 - loss: 0.6143 - val_accuracy: 0.7406 - val_loss: 0.5201\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - accuracy: 0.7416 - loss: 0.5034 - val_accuracy: 0.7437 - val_loss: 0.5008\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step - accuracy: 0.7491 - loss: 0.4754 - val_accuracy: 0.7406 - val_loss: 0.4944\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7448 - loss: 0.4655 - val_accuracy: 0.7312 - val_loss: 0.4869\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7665 - loss: 0.4514 - val_accuracy: 0.7250 - val_loss: 0.4994\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7693\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7987\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7693\n",
            "Time taken to train: 20.80 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867ms/step - accuracy: 0.6811 - loss: 0.6103 - val_accuracy: 0.7375 - val_loss: 0.5099\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.7424 - loss: 0.4933 - val_accuracy: 0.7406 - val_loss: 0.4957\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7385 - loss: 0.4800 - val_accuracy: 0.7625 - val_loss: 0.4844\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7486 - loss: 0.4650 - val_accuracy: 0.7281 - val_loss: 0.4814\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7548 - loss: 0.4531 - val_accuracy: 0.7219 - val_loss: 0.4847\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7693\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.8011\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7693\n",
            "Time taken to train: 20.04 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6023 - loss: 0.6003 - val_accuracy: 0.7219 - val_loss: 0.5084\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 703ms/step - accuracy: 0.7449 - loss: 0.4857 - val_accuracy: 0.7031 - val_loss: 0.4904\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7392 - loss: 0.4815 - val_accuracy: 0.7125 - val_loss: 0.4913\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 678ms/step - accuracy: 0.7597 - loss: 0.4675 - val_accuracy: 0.7156 - val_loss: 0.5025\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.7637 - loss: 0.4576 - val_accuracy: 0.7188 - val_loss: 0.5011\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7679\n",
            "BiLSTM-Content w2v_cbow Precision 0.7956\n",
            "BiLSTM-Content w2v_cbow Recall 0.7679\n",
            "Time taken to train: 35.97 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7068 - loss: 0.5936 - val_accuracy: 0.7094 - val_loss: 0.5247\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7330 - loss: 0.4916 - val_accuracy: 0.7312 - val_loss: 0.5038\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7372 - loss: 0.4610 - val_accuracy: 0.7156 - val_loss: 0.4988\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687ms/step - accuracy: 0.7295 - loss: 0.4749 - val_accuracy: 0.7375 - val_loss: 0.4999\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7550 - loss: 0.4648 - val_accuracy: 0.7250 - val_loss: 0.4998\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7650\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7940\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7650\n",
            "Time taken to train: 29.12 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7090 - loss: 0.5707 - val_accuracy: 0.7250 - val_loss: 0.5001\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7470 - loss: 0.4693 - val_accuracy: 0.7281 - val_loss: 0.4836\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7584 - loss: 0.4670 - val_accuracy: 0.7688 - val_loss: 0.4926\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7429 - loss: 0.4687 - val_accuracy: 0.7219 - val_loss: 0.4977\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702ms/step - accuracy: 0.7601 - loss: 0.4618 - val_accuracy: 0.7250 - val_loss: 0.4923\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.8007\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 36.36 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.6372 - loss: 0.5973 - val_accuracy: 0.7219 - val_loss: 0.4966\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 704ms/step - accuracy: 0.7363 - loss: 0.5020 - val_accuracy: 0.7531 - val_loss: 0.4996\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7453 - loss: 0.4934 - val_accuracy: 0.7219 - val_loss: 0.4807\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7591 - loss: 0.4562 - val_accuracy: 0.7656 - val_loss: 0.4802\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7531 - loss: 0.4587 - val_accuracy: 0.7656 - val_loss: 0.4796\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7474\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7162\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7474\n",
            "Time taken to train: 37.52 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6508 - loss: 0.5916 - val_accuracy: 0.7469 - val_loss: 0.4963\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7295 - loss: 0.4864 - val_accuracy: 0.7875 - val_loss: 0.4911\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7556 - loss: 0.4522 - val_accuracy: 0.7312 - val_loss: 0.5010\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7607 - loss: 0.4513 - val_accuracy: 0.7781 - val_loss: 0.5023\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 898ms/step - accuracy: 0.7564 - loss: 0.4568 - val_accuracy: 0.7781 - val_loss: 0.4832\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7460\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7141\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7460\n",
            "Time taken to train: 32.69 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7235 - loss: 0.6058 - val_accuracy: 0.7531 - val_loss: 0.5083\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7469 - loss: 0.4981 - val_accuracy: 0.7500 - val_loss: 0.4924\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.7467 - loss: 0.4766 - val_accuracy: 0.7937 - val_loss: 0.4801\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7503 - loss: 0.4581 - val_accuracy: 0.7688 - val_loss: 0.4987\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7579 - loss: 0.4540 - val_accuracy: 0.7719 - val_loss: 0.4871\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7489\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7211\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7489\n",
            "Time taken to train: 34.16 seconds\n",
            "\n",
            "Iteration 2 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 498ms/step - accuracy: 0.6914 - loss: 0.5839 - val_accuracy: 0.7781 - val_loss: 0.4669\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - accuracy: 0.7295 - loss: 0.4934 - val_accuracy: 0.7812 - val_loss: 0.4613\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 586ms/step - accuracy: 0.7196 - loss: 0.4740 - val_accuracy: 0.7625 - val_loss: 0.4733\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7434 - loss: 0.4773 - val_accuracy: 0.7625 - val_loss: 0.4946\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7514 - loss: 0.4561 - val_accuracy: 0.7625 - val_loss: 0.4937\n",
            "LSTM-Content w2v_cbow Accuracy 0.7504\n",
            "LSTM-Content w2v_cbow Precision 0.7734\n",
            "LSTM-Content w2v_cbow Recall 0.7504\n",
            "Time taken to train: 15.60 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 633ms/step - accuracy: 0.6481 - loss: 0.6039 - val_accuracy: 0.7312 - val_loss: 0.4710\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7350 - loss: 0.4961 - val_accuracy: 0.7312 - val_loss: 0.4720\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 410ms/step - accuracy: 0.7185 - loss: 0.4857 - val_accuracy: 0.7312 - val_loss: 0.4711\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7473 - loss: 0.4623 - val_accuracy: 0.7125 - val_loss: 0.4631\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 507ms/step - accuracy: 0.7539 - loss: 0.4681 - val_accuracy: 0.7156 - val_loss: 0.4855\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7299\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.6651\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7299\n",
            "Time taken to train: 16.63 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 584ms/step - accuracy: 0.6627 - loss: 0.5935 - val_accuracy: 0.7781 - val_loss: 0.4669\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 665ms/step - accuracy: 0.7332 - loss: 0.4754 - val_accuracy: 0.7719 - val_loss: 0.4662\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step - accuracy: 0.7460 - loss: 0.4700 - val_accuracy: 0.7188 - val_loss: 0.4709\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7569 - loss: 0.4504 - val_accuracy: 0.7156 - val_loss: 0.4925\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7640 - loss: 0.4467 - val_accuracy: 0.7219 - val_loss: 0.4968\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7044\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 20.63 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 592ms/step - accuracy: 0.7087 - loss: 0.5759 - val_accuracy: 0.7281 - val_loss: 0.4652\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 684ms/step - accuracy: 0.7267 - loss: 0.4691 - val_accuracy: 0.7656 - val_loss: 0.4645\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - accuracy: 0.7413 - loss: 0.4603 - val_accuracy: 0.7125 - val_loss: 0.4869\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.7764 - loss: 0.4540 - val_accuracy: 0.7188 - val_loss: 0.4994\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 413ms/step - accuracy: 0.7653 - loss: 0.4596 - val_accuracy: 0.7156 - val_loss: 0.5052\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7121\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 20.49 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 649ms/step - accuracy: 0.6130 - loss: 0.5965 - val_accuracy: 0.7312 - val_loss: 0.4668\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378ms/step - accuracy: 0.7450 - loss: 0.4784 - val_accuracy: 0.7312 - val_loss: 0.4624\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7410 - loss: 0.4792 - val_accuracy: 0.7188 - val_loss: 0.4611\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.7607 - loss: 0.4595 - val_accuracy: 0.7188 - val_loss: 0.4745\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7694 - loss: 0.4523 - val_accuracy: 0.7219 - val_loss: 0.4824\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7061\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 18.83 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 692ms/step - accuracy: 0.5859 - loss: 0.6128 - val_accuracy: 0.7312 - val_loss: 0.4744\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 618ms/step - accuracy: 0.7358 - loss: 0.4954 - val_accuracy: 0.7344 - val_loss: 0.4588\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7415 - loss: 0.4703 - val_accuracy: 0.7219 - val_loss: 0.4661\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 427ms/step - accuracy: 0.7595 - loss: 0.4719 - val_accuracy: 0.7563 - val_loss: 0.4701\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.7776 - loss: 0.4452 - val_accuracy: 0.7250 - val_loss: 0.4877\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7474\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7187\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7474\n",
            "Time taken to train: 21.32 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5208 - loss: 0.6187 - val_accuracy: 0.7750 - val_loss: 0.4638\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687ms/step - accuracy: 0.7306 - loss: 0.4939 - val_accuracy: 0.7219 - val_loss: 0.4679\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 696ms/step - accuracy: 0.7574 - loss: 0.4698 - val_accuracy: 0.7156 - val_loss: 0.4977\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 864ms/step - accuracy: 0.7578 - loss: 0.4548 - val_accuracy: 0.7156 - val_loss: 0.5061\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 689ms/step - accuracy: 0.7393 - loss: 0.4648 - val_accuracy: 0.7625 - val_loss: 0.5006\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7504\n",
            "BiLSTM-Content w2v_cbow Precision 0.7745\n",
            "BiLSTM-Content w2v_cbow Recall 0.7504\n",
            "Time taken to train: 29.23 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 888ms/step - accuracy: 0.6965 - loss: 0.5891 - val_accuracy: 0.7312 - val_loss: 0.4635\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7216 - loss: 0.4856 - val_accuracy: 0.7219 - val_loss: 0.4662\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688ms/step - accuracy: 0.7371 - loss: 0.4590 - val_accuracy: 0.7594 - val_loss: 0.4729\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7481 - loss: 0.4653 - val_accuracy: 0.7563 - val_loss: 0.4861\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711ms/step - accuracy: 0.7451 - loss: 0.4632 - val_accuracy: 0.7156 - val_loss: 0.4894\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7285\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.6578\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7285\n",
            "Time taken to train: 30.73 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6234 - loss: 0.5890 - val_accuracy: 0.7781 - val_loss: 0.4617\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 695ms/step - accuracy: 0.7412 - loss: 0.5013 - val_accuracy: 0.7312 - val_loss: 0.4848\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7479 - loss: 0.4691 - val_accuracy: 0.7094 - val_loss: 0.4877\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7683 - loss: 0.4566 - val_accuracy: 0.7219 - val_loss: 0.4890\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 686ms/step - accuracy: 0.7739 - loss: 0.4419 - val_accuracy: 0.7188 - val_loss: 0.4914\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7072\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 40.67 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7000 - loss: 0.5738 - val_accuracy: 0.7750 - val_loss: 0.4625\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7450 - loss: 0.4669 - val_accuracy: 0.7156 - val_loss: 0.4895\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.7808 - loss: 0.4386 - val_accuracy: 0.7094 - val_loss: 0.5015\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7799 - loss: 0.4380 - val_accuracy: 0.7219 - val_loss: 0.5034\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7708 - loss: 0.4416 - val_accuracy: 0.7219 - val_loss: 0.5020\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7489\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7192\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7489\n",
            "Time taken to train: 39.62 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5414 - loss: 0.6123 - val_accuracy: 0.7312 - val_loss: 0.4641\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 728ms/step - accuracy: 0.7301 - loss: 0.4869 - val_accuracy: 0.7281 - val_loss: 0.4587\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7570 - loss: 0.4689 - val_accuracy: 0.7156 - val_loss: 0.4764\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 720ms/step - accuracy: 0.7718 - loss: 0.4493 - val_accuracy: 0.7188 - val_loss: 0.4916\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7674 - loss: 0.4582 - val_accuracy: 0.7219 - val_loss: 0.4868\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7061\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 41.26 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5366 - loss: 0.6275 - val_accuracy: 0.7344 - val_loss: 0.4763\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7553 - loss: 0.4877 - val_accuracy: 0.7281 - val_loss: 0.4637\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.7686 - loss: 0.4452 - val_accuracy: 0.7688 - val_loss: 0.4653\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 902ms/step - accuracy: 0.7640 - loss: 0.4585 - val_accuracy: 0.7250 - val_loss: 0.5053\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 715ms/step - accuracy: 0.7743 - loss: 0.4589 - val_accuracy: 0.7250 - val_loss: 0.4841\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7114\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 34.21 seconds\n",
            "\n",
            "Iteration 3 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 488ms/step - accuracy: 0.5475 - loss: 0.5990 - val_accuracy: 0.7219 - val_loss: 0.5294\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.7385 - loss: 0.4937 - val_accuracy: 0.7219 - val_loss: 0.5013\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.7555 - loss: 0.4802 - val_accuracy: 0.7312 - val_loss: 0.4851\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 482ms/step - accuracy: 0.7525 - loss: 0.4695 - val_accuracy: 0.7312 - val_loss: 0.4827\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 546ms/step - accuracy: 0.7489 - loss: 0.4668 - val_accuracy: 0.7344 - val_loss: 0.4787\n",
            "LSTM-Content w2v_cbow Accuracy 0.7401\n",
            "LSTM-Content w2v_cbow Precision 0.7723\n",
            "LSTM-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 17.31 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 632ms/step - accuracy: 0.6946 - loss: 0.5818 - val_accuracy: 0.7312 - val_loss: 0.5366\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 394ms/step - accuracy: 0.7318 - loss: 0.5265 - val_accuracy: 0.7312 - val_loss: 0.5139\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - accuracy: 0.7465 - loss: 0.4714 - val_accuracy: 0.7312 - val_loss: 0.5202\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7361 - loss: 0.4741 - val_accuracy: 0.7219 - val_loss: 0.4978\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - accuracy: 0.7551 - loss: 0.4598 - val_accuracy: 0.7312 - val_loss: 0.4916\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7328\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7613\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7328\n",
            "Time taken to train: 16.33 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 643ms/step - accuracy: 0.5833 - loss: 0.5997 - val_accuracy: 0.7406 - val_loss: 0.5368\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 423ms/step - accuracy: 0.7273 - loss: 0.4987 - val_accuracy: 0.7219 - val_loss: 0.4972\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7567 - loss: 0.4667 - val_accuracy: 0.7344 - val_loss: 0.5094\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step - accuracy: 0.7340 - loss: 0.4818 - val_accuracy: 0.7375 - val_loss: 0.4889\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7506 - loss: 0.4797 - val_accuracy: 0.7312 - val_loss: 0.4795\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7358\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7629\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7358\n",
            "Time taken to train: 21.67 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 642ms/step - accuracy: 0.7060 - loss: 0.5720 - val_accuracy: 0.7219 - val_loss: 0.5231\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - accuracy: 0.7634 - loss: 0.4684 - val_accuracy: 0.7312 - val_loss: 0.4988\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7536 - loss: 0.4791 - val_accuracy: 0.7312 - val_loss: 0.4875\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step - accuracy: 0.7308 - loss: 0.4550 - val_accuracy: 0.7375 - val_loss: 0.4757\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7758 - loss: 0.4378 - val_accuracy: 0.7375 - val_loss: 0.4754\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7431\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7812\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7431\n",
            "Time taken to train: 19.26 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 600ms/step - accuracy: 0.5476 - loss: 0.5991 - val_accuracy: 0.7281 - val_loss: 0.5487\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7317 - loss: 0.5026 - val_accuracy: 0.7406 - val_loss: 0.4999\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 490ms/step - accuracy: 0.7419 - loss: 0.4700 - val_accuracy: 0.7375 - val_loss: 0.4981\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 524ms/step - accuracy: 0.7562 - loss: 0.4501 - val_accuracy: 0.7375 - val_loss: 0.4846\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.7559 - loss: 0.4722 - val_accuracy: 0.7594 - val_loss: 0.4832\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7562\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7610\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7562\n",
            "Time taken to train: 20.96 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 645ms/step - accuracy: 0.6543 - loss: 0.5945 - val_accuracy: 0.7344 - val_loss: 0.5258\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step - accuracy: 0.7409 - loss: 0.4775 - val_accuracy: 0.7500 - val_loss: 0.4957\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 621ms/step - accuracy: 0.7422 - loss: 0.4717 - val_accuracy: 0.7375 - val_loss: 0.4787\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 416ms/step - accuracy: 0.7802 - loss: 0.4518 - val_accuracy: 0.7406 - val_loss: 0.4787\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7479 - loss: 0.4639 - val_accuracy: 0.7344 - val_loss: 0.4749\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7431\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7851\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7431\n",
            "Time taken to train: 21.29 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 991ms/step - accuracy: 0.7130 - loss: 0.5775 - val_accuracy: 0.7125 - val_loss: 0.5260\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 733ms/step - accuracy: 0.7526 - loss: 0.5028 - val_accuracy: 0.7219 - val_loss: 0.5104\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 686ms/step - accuracy: 0.7442 - loss: 0.4877 - val_accuracy: 0.7344 - val_loss: 0.4841\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.7531 - loss: 0.4653 - val_accuracy: 0.7344 - val_loss: 0.4793\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686ms/step - accuracy: 0.7579 - loss: 0.4612 - val_accuracy: 0.7344 - val_loss: 0.4808\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7416\n",
            "BiLSTM-Content w2v_cbow Precision 0.7731\n",
            "BiLSTM-Content w2v_cbow Recall 0.7416\n",
            "Time taken to train: 29.45 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.6612 - loss: 0.5799 - val_accuracy: 0.7219 - val_loss: 0.5218\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7413 - loss: 0.4777 - val_accuracy: 0.7312 - val_loss: 0.5040\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7286 - loss: 0.4464 - val_accuracy: 0.7344 - val_loss: 0.4894\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7342 - loss: 0.4555 - val_accuracy: 0.7344 - val_loss: 0.4862\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 999ms/step - accuracy: 0.7558 - loss: 0.4628 - val_accuracy: 0.7344 - val_loss: 0.4819\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7401\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7748\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 28.97 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5464 - loss: 0.6093 - val_accuracy: 0.7156 - val_loss: 0.5248\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7504 - loss: 0.4963 - val_accuracy: 0.7219 - val_loss: 0.5144\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7539 - loss: 0.4772 - val_accuracy: 0.7406 - val_loss: 0.4834\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7640 - loss: 0.4662 - val_accuracy: 0.7344 - val_loss: 0.4890\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7625 - loss: 0.4606 - val_accuracy: 0.7437 - val_loss: 0.4777\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7832\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 32.09 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7449 - loss: 0.5703 - val_accuracy: 0.7188 - val_loss: 0.5201\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 706ms/step - accuracy: 0.7559 - loss: 0.4876 - val_accuracy: 0.7531 - val_loss: 0.5066\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 917ms/step - accuracy: 0.7542 - loss: 0.4690 - val_accuracy: 0.7344 - val_loss: 0.4746\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 717ms/step - accuracy: 0.7587 - loss: 0.4623 - val_accuracy: 0.7656 - val_loss: 0.4751\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7594 - loss: 0.4523 - val_accuracy: 0.7375 - val_loss: 0.4786\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7387\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7790\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7387\n",
            "Time taken to train: 40.91 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5803 - loss: 0.5877 - val_accuracy: 0.7219 - val_loss: 0.5112\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7492 - loss: 0.4979 - val_accuracy: 0.7406 - val_loss: 0.5190\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7336 - loss: 0.4719 - val_accuracy: 0.7531 - val_loss: 0.4863\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.7643 - loss: 0.4636 - val_accuracy: 0.7594 - val_loss: 0.4795\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7336 - loss: 0.4652 - val_accuracy: 0.7656 - val_loss: 0.4850\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7679\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7544\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7679\n",
            "Time taken to train: 34.52 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6434 - loss: 0.6007 - val_accuracy: 0.7469 - val_loss: 0.5230\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7550 - loss: 0.4633 - val_accuracy: 0.7469 - val_loss: 0.4909\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687ms/step - accuracy: 0.7469 - loss: 0.4629 - val_accuracy: 0.7312 - val_loss: 0.4873\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 856ms/step - accuracy: 0.7682 - loss: 0.4437 - val_accuracy: 0.7469 - val_loss: 0.4802\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 708ms/step - accuracy: 0.7712 - loss: 0.4565 - val_accuracy: 0.7656 - val_loss: 0.4770\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7693\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7495\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7693\n",
            "Time taken to train: 34.09 seconds\n",
            "\n",
            "Iteration 4 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 480ms/step - accuracy: 0.6422 - loss: 0.5860 - val_accuracy: 0.7312 - val_loss: 0.5323\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 507ms/step - accuracy: 0.7389 - loss: 0.5183 - val_accuracy: 0.7375 - val_loss: 0.4894\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 468ms/step - accuracy: 0.7407 - loss: 0.4852 - val_accuracy: 0.7375 - val_loss: 0.4847\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.7474 - loss: 0.4979 - val_accuracy: 0.7437 - val_loss: 0.4631\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7665 - loss: 0.4532 - val_accuracy: 0.7469 - val_loss: 0.4581\n",
            "LSTM-Content w2v_cbow Accuracy 0.7255\n",
            "LSTM-Content w2v_cbow Precision 0.7685\n",
            "LSTM-Content w2v_cbow Recall 0.7255\n",
            "Time taken to train: 14.05 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 617ms/step - accuracy: 0.6550 - loss: 0.6015 - val_accuracy: 0.7312 - val_loss: 0.5033\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - accuracy: 0.7233 - loss: 0.5164 - val_accuracy: 0.7312 - val_loss: 0.4794\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 0.7450 - loss: 0.4639 - val_accuracy: 0.7531 - val_loss: 0.4651\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402ms/step - accuracy: 0.7481 - loss: 0.4824 - val_accuracy: 0.7469 - val_loss: 0.4592\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 794ms/step - accuracy: 0.7532 - loss: 0.4737 - val_accuracy: 0.7531 - val_loss: 0.4530\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7328\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7787\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7328\n",
            "Time taken to train: 18.67 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 720ms/step - accuracy: 0.6238 - loss: 0.5973 - val_accuracy: 0.7281 - val_loss: 0.5099\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.7476 - loss: 0.4923 - val_accuracy: 0.7469 - val_loss: 0.4788\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7482 - loss: 0.4835 - val_accuracy: 0.7656 - val_loss: 0.4731\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.7468 - loss: 0.4531 - val_accuracy: 0.7563 - val_loss: 0.4618\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7628 - loss: 0.4623 - val_accuracy: 0.7563 - val_loss: 0.4580\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7270\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7706\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7270\n",
            "Time taken to train: 17.53 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 638ms/step - accuracy: 0.5469 - loss: 0.6005 - val_accuracy: 0.7469 - val_loss: 0.5221\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 635ms/step - accuracy: 0.7463 - loss: 0.4860 - val_accuracy: 0.7437 - val_loss: 0.4788\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7503 - loss: 0.4735 - val_accuracy: 0.7500 - val_loss: 0.4765\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7724 - loss: 0.4456 - val_accuracy: 0.7500 - val_loss: 0.4630\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7630 - loss: 0.4639 - val_accuracy: 0.7531 - val_loss: 0.4649\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7343\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7794\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7343\n",
            "Time taken to train: 21.38 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 609ms/step - accuracy: 0.6350 - loss: 0.5997 - val_accuracy: 0.7312 - val_loss: 0.4990\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 456ms/step - accuracy: 0.7310 - loss: 0.4870 - val_accuracy: 0.7344 - val_loss: 0.4760\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378ms/step - accuracy: 0.7408 - loss: 0.4762 - val_accuracy: 0.7469 - val_loss: 0.4603\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7431 - loss: 0.4648 - val_accuracy: 0.7469 - val_loss: 0.4548\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7694 - loss: 0.4444 - val_accuracy: 0.7500 - val_loss: 0.4572\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7372\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7876\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7372\n",
            "Time taken to train: 25.60 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 950ms/step - accuracy: 0.5651 - loss: 0.6145 - val_accuracy: 0.7281 - val_loss: 0.5314\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - accuracy: 0.7395 - loss: 0.5261 - val_accuracy: 0.7469 - val_loss: 0.4947\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.7409 - loss: 0.4815 - val_accuracy: 0.7469 - val_loss: 0.4781\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7444 - loss: 0.4719 - val_accuracy: 0.7469 - val_loss: 0.4583\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7725 - loss: 0.4501 - val_accuracy: 0.7500 - val_loss: 0.4532\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7387\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7869\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7387\n",
            "Time taken to train: 19.48 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6223 - loss: 0.5956 - val_accuracy: 0.7344 - val_loss: 0.4962\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 713ms/step - accuracy: 0.7642 - loss: 0.4802 - val_accuracy: 0.7344 - val_loss: 0.4749\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7525 - loss: 0.4685 - val_accuracy: 0.7563 - val_loss: 0.4581\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7648 - loss: 0.4583 - val_accuracy: 0.7500 - val_loss: 0.4595\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 685ms/step - accuracy: 0.7587 - loss: 0.4620 - val_accuracy: 0.7437 - val_loss: 0.4598\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7285\n",
            "BiLSTM-Content w2v_cbow Precision 0.7726\n",
            "BiLSTM-Content w2v_cbow Recall 0.7285\n",
            "Time taken to train: 34.39 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7429 - loss: 0.5804 - val_accuracy: 0.7344 - val_loss: 0.5130\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 781ms/step - accuracy: 0.7535 - loss: 0.5001 - val_accuracy: 0.7344 - val_loss: 0.4770\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7536 - loss: 0.4811 - val_accuracy: 0.7500 - val_loss: 0.4576\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 678ms/step - accuracy: 0.7596 - loss: 0.4678 - val_accuracy: 0.7500 - val_loss: 0.4537\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7777 - loss: 0.4560 - val_accuracy: 0.7469 - val_loss: 0.4532\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7299\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7746\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7299\n",
            "Time taken to train: 34.64 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.6732 - loss: 0.5942 - val_accuracy: 0.7344 - val_loss: 0.4944\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7492 - loss: 0.4857 - val_accuracy: 0.7469 - val_loss: 0.4824\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 728ms/step - accuracy: 0.7602 - loss: 0.4652 - val_accuracy: 0.7594 - val_loss: 0.4632\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 707ms/step - accuracy: 0.7645 - loss: 0.4662 - val_accuracy: 0.7531 - val_loss: 0.4654\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 706ms/step - accuracy: 0.7755 - loss: 0.4611 - val_accuracy: 0.7500 - val_loss: 0.4548\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7358\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7828\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7358\n",
            "Time taken to train: 35.83 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6538 - loss: 0.5983 - val_accuracy: 0.7406 - val_loss: 0.4949\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729ms/step - accuracy: 0.7485 - loss: 0.5010 - val_accuracy: 0.7469 - val_loss: 0.4823\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 685ms/step - accuracy: 0.7608 - loss: 0.4757 - val_accuracy: 0.7469 - val_loss: 0.4603\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 772ms/step - accuracy: 0.7685 - loss: 0.4546 - val_accuracy: 0.7500 - val_loss: 0.4646\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 704ms/step - accuracy: 0.7672 - loss: 0.4643 - val_accuracy: 0.7500 - val_loss: 0.4574\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7372\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7849\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7372\n",
            "Time taken to train: 37.09 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6826 - loss: 0.5661 - val_accuracy: 0.7406 - val_loss: 0.4972\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7388 - loss: 0.4885 - val_accuracy: 0.7469 - val_loss: 0.4873\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - accuracy: 0.7583 - loss: 0.4780 - val_accuracy: 0.7531 - val_loss: 0.4639\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 726ms/step - accuracy: 0.7521 - loss: 0.4614 - val_accuracy: 0.7469 - val_loss: 0.4647\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7596 - loss: 0.4599 - val_accuracy: 0.7531 - val_loss: 0.4541\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7650\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7433\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7650\n",
            "Time taken to train: 33.05 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.6527 - loss: 0.6027 - val_accuracy: 0.7406 - val_loss: 0.4982\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 721ms/step - accuracy: 0.7431 - loss: 0.5005 - val_accuracy: 0.7437 - val_loss: 0.4730\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7327 - loss: 0.4718 - val_accuracy: 0.7500 - val_loss: 0.4630\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.7761 - loss: 0.4379 - val_accuracy: 0.7437 - val_loss: 0.4555\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7656 - loss: 0.4381 - val_accuracy: 0.7531 - val_loss: 0.4544\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7679\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7473\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7679\n",
            "Time taken to train: 45.53 seconds\n",
            "\n",
            "Iteration 5 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 521ms/step - accuracy: 0.7059 - loss: 0.5770 - val_accuracy: 0.7344 - val_loss: 0.5199\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 621ms/step - accuracy: 0.7532 - loss: 0.4745 - val_accuracy: 0.7344 - val_loss: 0.4887\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7442 - loss: 0.4736 - val_accuracy: 0.7375 - val_loss: 0.4985\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 413ms/step - accuracy: 0.7551 - loss: 0.4665 - val_accuracy: 0.7469 - val_loss: 0.4740\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7395 - loss: 0.4804 - val_accuracy: 0.7375 - val_loss: 0.4921\n",
            "LSTM-Content w2v_cbow Accuracy 0.7401\n",
            "LSTM-Content w2v_cbow Precision 0.7735\n",
            "LSTM-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 15.10 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 531ms/step - accuracy: 0.5965 - loss: 0.6009 - val_accuracy: 0.7312 - val_loss: 0.5640\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.7331 - loss: 0.5021 - val_accuracy: 0.7312 - val_loss: 0.4894\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.7375 - loss: 0.4748 - val_accuracy: 0.7312 - val_loss: 0.4936\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7364 - loss: 0.4708 - val_accuracy: 0.7469 - val_loss: 0.4714\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 498ms/step - accuracy: 0.7441 - loss: 0.4726 - val_accuracy: 0.7375 - val_loss: 0.4975\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7401\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7269\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 16.98 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 901ms/step - accuracy: 0.7303 - loss: 0.5508 - val_accuracy: 0.7594 - val_loss: 0.5193\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7484 - loss: 0.4833 - val_accuracy: 0.7344 - val_loss: 0.4833\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.7360 - loss: 0.4880 - val_accuracy: 0.7375 - val_loss: 0.4852\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7285 - loss: 0.4725 - val_accuracy: 0.7469 - val_loss: 0.4711\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 604ms/step - accuracy: 0.7536 - loss: 0.4554 - val_accuracy: 0.7437 - val_loss: 0.4724\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7807\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 23.06 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 981ms/step - accuracy: 0.7287 - loss: 0.5561 - val_accuracy: 0.7344 - val_loss: 0.5048\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.7497 - loss: 0.4981 - val_accuracy: 0.7406 - val_loss: 0.4837\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7592 - loss: 0.4652 - val_accuracy: 0.7406 - val_loss: 0.4846\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7545 - loss: 0.4602 - val_accuracy: 0.7500 - val_loss: 0.4671\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7593 - loss: 0.4658 - val_accuracy: 0.7688 - val_loss: 0.4756\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7021\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 17.81 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 627ms/step - accuracy: 0.5448 - loss: 0.6119 - val_accuracy: 0.7375 - val_loss: 0.5316\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 414ms/step - accuracy: 0.7318 - loss: 0.4931 - val_accuracy: 0.7406 - val_loss: 0.4876\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 410ms/step - accuracy: 0.7307 - loss: 0.4743 - val_accuracy: 0.7344 - val_loss: 0.4910\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7582 - loss: 0.4599 - val_accuracy: 0.7750 - val_loss: 0.4664\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.7684 - loss: 0.4672 - val_accuracy: 0.7437 - val_loss: 0.4775\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7820\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 19.48 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 698ms/step - accuracy: 0.6752 - loss: 0.6004 - val_accuracy: 0.7406 - val_loss: 0.5402\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 549ms/step - accuracy: 0.7350 - loss: 0.5001 - val_accuracy: 0.7406 - val_loss: 0.4846\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376ms/step - accuracy: 0.7523 - loss: 0.4733 - val_accuracy: 0.7594 - val_loss: 0.4784\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 413ms/step - accuracy: 0.7464 - loss: 0.4437 - val_accuracy: 0.7469 - val_loss: 0.4648\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 407ms/step - accuracy: 0.7517 - loss: 0.4668 - val_accuracy: 0.7437 - val_loss: 0.4779\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7489\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7893\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7489\n",
            "Time taken to train: 21.26 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6146 - loss: 0.5888 - val_accuracy: 0.7344 - val_loss: 0.5087\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7480 - loss: 0.4766 - val_accuracy: 0.7344 - val_loss: 0.4921\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7655 - loss: 0.4645 - val_accuracy: 0.7375 - val_loss: 0.4715\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7511 - loss: 0.4848 - val_accuracy: 0.7406 - val_loss: 0.5080\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686ms/step - accuracy: 0.7717 - loss: 0.4706 - val_accuracy: 0.7406 - val_loss: 0.4786\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7460\n",
            "BiLSTM-Content w2v_cbow Precision 0.7840\n",
            "BiLSTM-Content w2v_cbow Recall 0.7460\n",
            "Time taken to train: 30.49 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 900ms/step - accuracy: 0.6400 - loss: 0.5910 - val_accuracy: 0.7312 - val_loss: 0.4985\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7382 - loss: 0.4822 - val_accuracy: 0.7312 - val_loss: 0.4911\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7464 - loss: 0.4607 - val_accuracy: 0.7406 - val_loss: 0.4793\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 680ms/step - accuracy: 0.7628 - loss: 0.4599 - val_accuracy: 0.7531 - val_loss: 0.4794\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7474 - loss: 0.4756 - val_accuracy: 0.7406 - val_loss: 0.5083\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7401\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7269\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 29.81 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5844 - loss: 0.5865 - val_accuracy: 0.7437 - val_loss: 0.5137\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7438 - loss: 0.4904 - val_accuracy: 0.7531 - val_loss: 0.5070\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 748ms/step - accuracy: 0.7472 - loss: 0.4658 - val_accuracy: 0.7469 - val_loss: 0.4707\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7737 - loss: 0.4732 - val_accuracy: 0.7781 - val_loss: 0.4884\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7601 - loss: 0.4623 - val_accuracy: 0.7437 - val_loss: 0.4659\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7474\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7847\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7474\n",
            "Time taken to train: 33.03 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6406 - loss: 0.5867 - val_accuracy: 0.7406 - val_loss: 0.5079\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 727ms/step - accuracy: 0.7481 - loss: 0.4904 - val_accuracy: 0.7406 - val_loss: 0.4935\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 723ms/step - accuracy: 0.7529 - loss: 0.4567 - val_accuracy: 0.7437 - val_loss: 0.4646\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 753ms/step - accuracy: 0.7634 - loss: 0.4567 - val_accuracy: 0.7781 - val_loss: 0.4754\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 718ms/step - accuracy: 0.7709 - loss: 0.4455 - val_accuracy: 0.7812 - val_loss: 0.4736\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7533\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7363\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7533\n",
            "Time taken to train: 34.89 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5287 - loss: 0.6118 - val_accuracy: 0.7375 - val_loss: 0.5075\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7455 - loss: 0.4973 - val_accuracy: 0.7375 - val_loss: 0.5155\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 733ms/step - accuracy: 0.7523 - loss: 0.4664 - val_accuracy: 0.7406 - val_loss: 0.4755\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 805ms/step - accuracy: 0.7623 - loss: 0.4522 - val_accuracy: 0.7437 - val_loss: 0.4765\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7759 - loss: 0.4428 - val_accuracy: 0.7812 - val_loss: 0.4721\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7372\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.6994\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7372\n",
            "Time taken to train: 36.79 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5578 - loss: 0.6007 - val_accuracy: 0.7312 - val_loss: 0.5156\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 766ms/step - accuracy: 0.7498 - loss: 0.4557 - val_accuracy: 0.7563 - val_loss: 0.4721\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 811ms/step - accuracy: 0.7498 - loss: 0.4598 - val_accuracy: 0.7812 - val_loss: 0.4698\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7704 - loss: 0.4469 - val_accuracy: 0.7906 - val_loss: 0.4771\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 740ms/step - accuracy: 0.7695 - loss: 0.4589 - val_accuracy: 0.7812 - val_loss: 0.4802\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7489\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7188\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7489\n",
            "Time taken to train: 31.76 seconds\n",
            "\n",
            "Summary for w2v_cbow:\n",
            "LSTM-00CNN-ContentNets w2v_cbow ACCURACY 0.7387 ± 0.0068\n",
            "LSTM-00CNN-ContentNets w2v_cbow PRECISION 0.7470 ± 0.0307\n",
            "LSTM-00CNN-ContentNets w2v_cbow RECALL 0.7387 ± 0.0068\n",
            "LSTM-00CNN-ContentNets w2v_cbow EXECUTION TIME 20.81 ± 1.83\n",
            "LSTM-01CNN-ContentNets w2v_cbow ACCURACY 0.7466 ± 0.0126\n",
            "LSTM-01CNN-ContentNets w2v_cbow PRECISION 0.7468 ± 0.0335\n",
            "LSTM-01CNN-ContentNets w2v_cbow RECALL 0.7466 ± 0.0126\n",
            "LSTM-01CNN-ContentNets w2v_cbow EXECUTION TIME 19.77 ± 1.20\n",
            "LSTM-10CNN-ContentNets w2v_cbow ACCURACY 0.7495 ± 0.0118\n",
            "LSTM-10CNN-ContentNets w2v_cbow PRECISION 0.7671 ± 0.0329\n",
            "LSTM-10CNN-ContentNets w2v_cbow RECALL 0.7495 ± 0.0118\n",
            "LSTM-10CNN-ContentNets w2v_cbow EXECUTION TIME 21.14 ± 2.37\n",
            "LSTM-11CNN-ContentNets w2v_cbow ACCURACY 0.7495 ± 0.0106\n",
            "LSTM-11CNN-ContentNets w2v_cbow PRECISION 0.7762 ± 0.0293\n",
            "LSTM-11CNN-ContentNets w2v_cbow RECALL 0.7495 ± 0.0106\n",
            "LSTM-11CNN-ContentNets w2v_cbow EXECUTION TIME 20.68 ± 0.77\n",
            "LSTM-Content w2v_cbow ACCURACY 0.7436 ± 0.0121\n",
            "LSTM-Content w2v_cbow PRECISION 0.7751 ± 0.0066\n",
            "LSTM-Content w2v_cbow RECALL 0.7436 ± 0.0121\n",
            "LSTM-Content w2v_cbow EXECUTION TIME 20.47 ± 9.96\n",
            "LSTM-CNN-Content w2v_cbow ACCURACY 0.7404 ± 0.0134\n",
            "LSTM-CNN-Content w2v_cbow PRECISION 0.7451 ± 0.0458\n",
            "LSTM-CNN-Content w2v_cbow RECALL 0.7404 ± 0.0134\n",
            "LSTM-CNN-Content w2v_cbow EXECUTION TIME 17.45 ± 1.01\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow ACCURACY 0.7477 ± 0.0122\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow PRECISION 0.7717 ± 0.0330\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow RECALL 0.7477 ± 0.0122\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow EXECUTION TIME 35.60 ± 3.01\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow ACCURACY 0.7451 ± 0.0062\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow PRECISION 0.7471 ± 0.0293\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow RECALL 0.7451 ± 0.0062\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow EXECUTION TIME 38.01 ± 2.09\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow ACCURACY 0.7512 ± 0.0127\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow PRECISION 0.7234 ± 0.0215\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow RECALL 0.7512 ± 0.0127\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow EXECUTION TIME 35.66 ± 3.15\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow ACCURACY 0.7559 ± 0.0105\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow PRECISION 0.7296 ± 0.0157\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow RECALL 0.7559 ± 0.0105\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow EXECUTION TIME 35.95 ± 4.88\n",
            "BiLSTM-Content w2v_cbow ACCURACY 0.7469 ± 0.0128\n",
            "BiLSTM-Content w2v_cbow PRECISION 0.7800 ± 0.0089\n",
            "BiLSTM-Content w2v_cbow RECALL 0.7469 ± 0.0128\n",
            "BiLSTM-Content w2v_cbow EXECUTION TIME 31.90 ± 2.75\n",
            "BiLSTM-CNN-Content w2v_cbow ACCURACY 0.7407 ± 0.0131\n",
            "BiLSTM-CNN-Content w2v_cbow PRECISION 0.7456 ± 0.0492\n",
            "BiLSTM-CNN-Content w2v_cbow RECALL 0.7407 ± 0.0131\n",
            "BiLSTM-CNN-Content w2v_cbow EXECUTION TIME 30.66 ± 2.09\n",
            "Loaded w2v_sg shape: (4023, 128)\n",
            "\n",
            "Iteration 1 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 754ms/step - accuracy: 0.5969 - loss: 0.6089 - val_accuracy: 0.7312 - val_loss: 0.5900\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7284 - loss: 0.5058 - val_accuracy: 0.7437 - val_loss: 0.4935\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.7388 - loss: 0.4846 - val_accuracy: 0.7344 - val_loss: 0.4873\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7368 - loss: 0.4784 - val_accuracy: 0.7312 - val_loss: 0.4897\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 690ms/step - accuracy: 0.7311 - loss: 0.4759 - val_accuracy: 0.7500 - val_loss: 0.4744\n",
            "LSTM-Content w2v_sg Accuracy 0.7518\n",
            "LSTM-Content w2v_sg Precision 0.7731\n",
            "LSTM-Content w2v_sg Recall 0.7518\n",
            "Time taken to train: 20.89 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 553ms/step - accuracy: 0.5362 - loss: 0.6290 - val_accuracy: 0.7312 - val_loss: 0.5928\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 632ms/step - accuracy: 0.7244 - loss: 0.5203 - val_accuracy: 0.7312 - val_loss: 0.4980\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7351 - loss: 0.4902 - val_accuracy: 0.7312 - val_loss: 0.4992\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7206 - loss: 0.4866 - val_accuracy: 0.7531 - val_loss: 0.4747\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7391 - loss: 0.4727 - val_accuracy: 0.7531 - val_loss: 0.4785\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7518\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7731\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7518\n",
            "Time taken to train: 15.84 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 601ms/step - accuracy: 0.6980 - loss: 0.6024 - val_accuracy: 0.7312 - val_loss: 0.5585\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 422ms/step - accuracy: 0.7392 - loss: 0.4996 - val_accuracy: 0.7469 - val_loss: 0.4876\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 497ms/step - accuracy: 0.7521 - loss: 0.4769 - val_accuracy: 0.7406 - val_loss: 0.4859\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7318 - loss: 0.4726 - val_accuracy: 0.7437 - val_loss: 0.4789\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7566 - loss: 0.4711 - val_accuracy: 0.7594 - val_loss: 0.4675\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7577\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7326\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7577\n",
            "Time taken to train: 20.31 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 636ms/step - accuracy: 0.6421 - loss: 0.6007 - val_accuracy: 0.7312 - val_loss: 0.5808\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 424ms/step - accuracy: 0.7349 - loss: 0.5026 - val_accuracy: 0.7594 - val_loss: 0.4924\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - accuracy: 0.7495 - loss: 0.4743 - val_accuracy: 0.7406 - val_loss: 0.4906\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 538ms/step - accuracy: 0.7267 - loss: 0.4811 - val_accuracy: 0.7656 - val_loss: 0.4716\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7608 - loss: 0.4567 - val_accuracy: 0.7594 - val_loss: 0.4637\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7547\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7838\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7547\n",
            "Time taken to train: 21.09 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 635ms/step - accuracy: 0.5516 - loss: 0.6249 - val_accuracy: 0.7312 - val_loss: 0.6645\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419ms/step - accuracy: 0.7364 - loss: 0.5396 - val_accuracy: 0.7406 - val_loss: 0.5095\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.7521 - loss: 0.4931 - val_accuracy: 0.7344 - val_loss: 0.5025\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 700ms/step - accuracy: 0.7281 - loss: 0.4817 - val_accuracy: 0.7469 - val_loss: 0.4770\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7517 - loss: 0.4608 - val_accuracy: 0.7656 - val_loss: 0.4648\n",
            "LSTM-10CNN-ContentNets w2v_sg Accuracy 0.7591\n",
            "LSTM-10CNN-ContentNets w2v_sg Precision 0.7353\n",
            "LSTM-10CNN-ContentNets w2v_sg Recall 0.7591\n",
            "Time taken to train: 21.79 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 607ms/step - accuracy: 0.5721 - loss: 0.6406 - val_accuracy: 0.7312 - val_loss: 0.6006\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7063 - loss: 0.5517 - val_accuracy: 0.7406 - val_loss: 0.4997\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7406 - loss: 0.4916 - val_accuracy: 0.7469 - val_loss: 0.4945\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7482 - loss: 0.4725 - val_accuracy: 0.7625 - val_loss: 0.4686\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736ms/step - accuracy: 0.7590 - loss: 0.4576 - val_accuracy: 0.7875 - val_loss: 0.4667\n",
            "LSTM-11CNN-ContentNets w2v_sg Accuracy 0.7518\n",
            "LSTM-11CNN-ContentNets w2v_sg Precision 0.7326\n",
            "LSTM-11CNN-ContentNets w2v_sg Recall 0.7518\n",
            "Time taken to train: 20.40 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6594 - loss: 0.5925 - val_accuracy: 0.7312 - val_loss: 0.5662\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 688ms/step - accuracy: 0.7296 - loss: 0.4814 - val_accuracy: 0.7500 - val_loss: 0.4823\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.7297 - loss: 0.4891 - val_accuracy: 0.7312 - val_loss: 0.4939\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7370 - loss: 0.4664 - val_accuracy: 0.7531 - val_loss: 0.4684\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693ms/step - accuracy: 0.7409 - loss: 0.4700 - val_accuracy: 0.7437 - val_loss: 0.4842\n",
            "BiLSTM-Content w2v_sg Accuracy 0.7387\n",
            "BiLSTM-Content w2v_sg Precision 0.7558\n",
            "BiLSTM-Content w2v_sg Recall 0.7387\n",
            "Time taken to train: 31.28 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7251 - loss: 0.5832 - val_accuracy: 0.7312 - val_loss: 0.5215\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7263 - loss: 0.5052 - val_accuracy: 0.7312 - val_loss: 0.4851\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 706ms/step - accuracy: 0.7477 - loss: 0.4716 - val_accuracy: 0.7344 - val_loss: 0.4934\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7340 - loss: 0.4735 - val_accuracy: 0.7625 - val_loss: 0.4749\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7335 - loss: 0.4699 - val_accuracy: 0.7312 - val_loss: 0.4853\n",
            "BiLSTM-CNN-Content w2v_sg Accuracy 0.7358\n",
            "BiLSTM-CNN-Content w2v_sg Precision 0.7302\n",
            "BiLSTM-CNN-Content w2v_sg Recall 0.7358\n",
            "Time taken to train: 28.06 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6621 - loss: 0.5916 - val_accuracy: 0.7344 - val_loss: 0.5519\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7412 - loss: 0.5161 - val_accuracy: 0.7625 - val_loss: 0.4812\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7504 - loss: 0.4704 - val_accuracy: 0.7406 - val_loss: 0.4967\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7378 - loss: 0.4719 - val_accuracy: 0.7594 - val_loss: 0.4646\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 715ms/step - accuracy: 0.7585 - loss: 0.4599 - val_accuracy: 0.7594 - val_loss: 0.4766\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Accuracy 0.7547\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Precision 0.7425\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Recall 0.7547\n",
            "Time taken to train: 35.51 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.7227 - loss: 0.5942 - val_accuracy: 0.7312 - val_loss: 0.5885\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736ms/step - accuracy: 0.7522 - loss: 0.4920 - val_accuracy: 0.7594 - val_loss: 0.4985\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 968ms/step - accuracy: 0.7408 - loss: 0.4882 - val_accuracy: 0.7375 - val_loss: 0.5008\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736ms/step - accuracy: 0.7381 - loss: 0.4716 - val_accuracy: 0.7625 - val_loss: 0.4680\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 802ms/step - accuracy: 0.7510 - loss: 0.4549 - val_accuracy: 0.7625 - val_loss: 0.4561\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Accuracy 0.7533\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Precision 0.7866\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Recall 0.7533\n",
            "Time taken to train: 41.64 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6644 - loss: 0.6009 - val_accuracy: 0.7312 - val_loss: 0.5382\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 727ms/step - accuracy: 0.7429 - loss: 0.4847 - val_accuracy: 0.7375 - val_loss: 0.4775\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7301 - loss: 0.4732 - val_accuracy: 0.7656 - val_loss: 0.4647\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7636 - loss: 0.4488 - val_accuracy: 0.7594 - val_loss: 0.4602\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7537 - loss: 0.4550 - val_accuracy: 0.7594 - val_loss: 0.4573\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Accuracy 0.7562\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Precision 0.7893\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Recall 0.7562\n",
            "Time taken to train: 40.43 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6527 - loss: 0.6160 - val_accuracy: 0.7344 - val_loss: 0.5483\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 745ms/step - accuracy: 0.7320 - loss: 0.4926 - val_accuracy: 0.7500 - val_loss: 0.4811\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7436 - loss: 0.4807 - val_accuracy: 0.7594 - val_loss: 0.4716\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.7414 - loss: 0.4610 - val_accuracy: 0.7594 - val_loss: 0.4708\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7545 - loss: 0.4702 - val_accuracy: 0.7625 - val_loss: 0.4536\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Accuracy 0.7591\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Precision 0.7349\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Recall 0.7591\n",
            "Time taken to train: 39.60 seconds\n",
            "\n",
            "Iteration 2 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 523ms/step - accuracy: 0.5862 - loss: 0.6052 - val_accuracy: 0.7312 - val_loss: 0.5460\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.7432 - loss: 0.4875 - val_accuracy: 0.7281 - val_loss: 0.5031\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.7431 - loss: 0.4930 - val_accuracy: 0.7281 - val_loss: 0.4932\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - accuracy: 0.7624 - loss: 0.4733 - val_accuracy: 0.7344 - val_loss: 0.4989\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 512ms/step - accuracy: 0.7789 - loss: 0.4418 - val_accuracy: 0.7312 - val_loss: 0.4901\n",
            "LSTM-Content w2v_sg Accuracy 0.7212\n",
            "LSTM-Content w2v_sg Precision 0.7651\n",
            "LSTM-Content w2v_sg Recall 0.7212\n",
            "Time taken to train: 17.25 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 686ms/step - accuracy: 0.6200 - loss: 0.6059 - val_accuracy: 0.7312 - val_loss: 0.5501\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 373ms/step - accuracy: 0.7265 - loss: 0.4977 - val_accuracy: 0.7312 - val_loss: 0.4964\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7245 - loss: 0.4707 - val_accuracy: 0.7312 - val_loss: 0.5026\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7453 - loss: 0.4590 - val_accuracy: 0.7375 - val_loss: 0.4891\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7748 - loss: 0.4507 - val_accuracy: 0.7312 - val_loss: 0.4924\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7212\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7625\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7212\n",
            "Time taken to train: 16.49 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 591ms/step - accuracy: 0.6676 - loss: 0.6000 - val_accuracy: 0.7312 - val_loss: 0.5448\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7354 - loss: 0.4919 - val_accuracy: 0.7281 - val_loss: 0.5010\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 777ms/step - accuracy: 0.7749 - loss: 0.4567 - val_accuracy: 0.7625 - val_loss: 0.4904\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412ms/step - accuracy: 0.7645 - loss: 0.4446 - val_accuracy: 0.7375 - val_loss: 0.4783\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7663 - loss: 0.4632 - val_accuracy: 0.7312 - val_loss: 0.4744\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7226\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7620\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7226\n",
            "Time taken to train: 19.54 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 592ms/step - accuracy: 0.6007 - loss: 0.6063 - val_accuracy: 0.7312 - val_loss: 0.5637\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7249 - loss: 0.5164 - val_accuracy: 0.7437 - val_loss: 0.4901\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600ms/step - accuracy: 0.7799 - loss: 0.4567 - val_accuracy: 0.7437 - val_loss: 0.4748\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.7726 - loss: 0.4520 - val_accuracy: 0.7563 - val_loss: 0.4656\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.7756 - loss: 0.4450 - val_accuracy: 0.7437 - val_loss: 0.4580\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7255\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7698\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7255\n",
            "Time taken to train: 21.13 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 599ms/step - accuracy: 0.6496 - loss: 0.6057 - val_accuracy: 0.7312 - val_loss: 0.5569\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 736ms/step - accuracy: 0.7396 - loss: 0.4856 - val_accuracy: 0.7406 - val_loss: 0.4993\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.7359 - loss: 0.4713 - val_accuracy: 0.7375 - val_loss: 0.4840\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7434 - loss: 0.4436 - val_accuracy: 0.7375 - val_loss: 0.4801\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7883 - loss: 0.4266 - val_accuracy: 0.7406 - val_loss: 0.4730\n",
            "LSTM-10CNN-ContentNets w2v_sg Accuracy 0.7226\n",
            "LSTM-10CNN-ContentNets w2v_sg Precision 0.7620\n",
            "LSTM-10CNN-ContentNets w2v_sg Recall 0.7226\n",
            "Time taken to train: 19.63 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 646ms/step - accuracy: 0.6372 - loss: 0.6233 - val_accuracy: 0.7312 - val_loss: 0.5304\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7373 - loss: 0.4687 - val_accuracy: 0.7531 - val_loss: 0.4923\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7675 - loss: 0.4553 - val_accuracy: 0.7500 - val_loss: 0.4706\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7588 - loss: 0.4452 - val_accuracy: 0.7344 - val_loss: 0.4622\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.7759 - loss: 0.4375 - val_accuracy: 0.7375 - val_loss: 0.4590\n",
            "LSTM-11CNN-ContentNets w2v_sg Accuracy 0.7285\n",
            "LSTM-11CNN-ContentNets w2v_sg Precision 0.7779\n",
            "LSTM-11CNN-ContentNets w2v_sg Recall 0.7285\n",
            "Time taken to train: 21.89 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 889ms/step - accuracy: 0.7207 - loss: 0.5863 - val_accuracy: 0.7312 - val_loss: 0.5438\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 885ms/step - accuracy: 0.7650 - loss: 0.4737 - val_accuracy: 0.7281 - val_loss: 0.5000\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675ms/step - accuracy: 0.7465 - loss: 0.4681 - val_accuracy: 0.7344 - val_loss: 0.4959\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7547 - loss: 0.4674 - val_accuracy: 0.7344 - val_loss: 0.4857\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7721 - loss: 0.4493 - val_accuracy: 0.7312 - val_loss: 0.4928\n",
            "BiLSTM-Content w2v_sg Accuracy 0.7212\n",
            "BiLSTM-Content w2v_sg Precision 0.7587\n",
            "BiLSTM-Content w2v_sg Recall 0.7212\n",
            "Time taken to train: 28.92 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 964ms/step - accuracy: 0.5381 - loss: 0.5963 - val_accuracy: 0.7312 - val_loss: 0.5173\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 678ms/step - accuracy: 0.7398 - loss: 0.4662 - val_accuracy: 0.7312 - val_loss: 0.4856\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7325 - loss: 0.4703 - val_accuracy: 0.7312 - val_loss: 0.4854\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686ms/step - accuracy: 0.7879 - loss: 0.4227 - val_accuracy: 0.7312 - val_loss: 0.4985\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7799 - loss: 0.4425 - val_accuracy: 0.7344 - val_loss: 0.5069\n",
            "BiLSTM-CNN-Content w2v_sg Accuracy 0.7255\n",
            "BiLSTM-CNN-Content w2v_sg Precision 0.6568\n",
            "BiLSTM-CNN-Content w2v_sg Recall 0.7255\n",
            "Time taken to train: 27.95 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5255 - loss: 0.6050 - val_accuracy: 0.7344 - val_loss: 0.5332\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 888ms/step - accuracy: 0.7355 - loss: 0.4848 - val_accuracy: 0.7250 - val_loss: 0.4948\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 727ms/step - accuracy: 0.7554 - loss: 0.4537 - val_accuracy: 0.7406 - val_loss: 0.4896\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7524 - loss: 0.4416 - val_accuracy: 0.7375 - val_loss: 0.4793\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7802 - loss: 0.4320 - val_accuracy: 0.7531 - val_loss: 0.4698\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Accuracy 0.7650\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Precision 0.7565\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Recall 0.7650\n",
            "Time taken to train: 38.86 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5974 - loss: 0.5846 - val_accuracy: 0.7344 - val_loss: 0.5334\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7537 - loss: 0.4572 - val_accuracy: 0.7344 - val_loss: 0.4896\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 704ms/step - accuracy: 0.7665 - loss: 0.4509 - val_accuracy: 0.7688 - val_loss: 0.4667\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7759 - loss: 0.4443 - val_accuracy: 0.7375 - val_loss: 0.4639\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7806 - loss: 0.4249 - val_accuracy: 0.7375 - val_loss: 0.4607\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Accuracy 0.7270\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Precision 0.7719\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Recall 0.7270\n",
            "Time taken to train: 36.29 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.5662 - loss: 0.6067 - val_accuracy: 0.7344 - val_loss: 0.5496\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 903ms/step - accuracy: 0.7494 - loss: 0.4731 - val_accuracy: 0.7500 - val_loss: 0.4882\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736ms/step - accuracy: 0.7613 - loss: 0.4584 - val_accuracy: 0.7594 - val_loss: 0.4712\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7714 - loss: 0.4312 - val_accuracy: 0.7312 - val_loss: 0.4912\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7655 - loss: 0.4608 - val_accuracy: 0.7594 - val_loss: 0.4726\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Accuracy 0.7401\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Precision 0.7023\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Recall 0.7401\n",
            "Time taken to train: 42.90 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5553 - loss: 0.6283 - val_accuracy: 0.7312 - val_loss: 0.5665\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 719ms/step - accuracy: 0.7335 - loss: 0.5125 - val_accuracy: 0.7688 - val_loss: 0.4910\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7561 - loss: 0.4665 - val_accuracy: 0.7531 - val_loss: 0.4597\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 733ms/step - accuracy: 0.7681 - loss: 0.4496 - val_accuracy: 0.7437 - val_loss: 0.4559\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7683 - loss: 0.4457 - val_accuracy: 0.7406 - val_loss: 0.4542\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Accuracy 0.7285\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Precision 0.7779\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Recall 0.7285\n",
            "Time taken to train: 38.98 seconds\n",
            "\n",
            "Iteration 3 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 712ms/step - accuracy: 0.5560 - loss: 0.6212 - val_accuracy: 0.7312 - val_loss: 0.4778\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7205 - loss: 0.5159 - val_accuracy: 0.7281 - val_loss: 0.4783\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7323 - loss: 0.5009 - val_accuracy: 0.7312 - val_loss: 0.4425\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7178 - loss: 0.4916 - val_accuracy: 0.7406 - val_loss: 0.4402\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7411 - loss: 0.4857 - val_accuracy: 0.7688 - val_loss: 0.4388\n",
            "LSTM-Content w2v_sg Accuracy 0.7358\n",
            "LSTM-Content w2v_sg Precision 0.7562\n",
            "LSTM-Content w2v_sg Recall 0.7358\n",
            "Time taken to train: 15.17 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 560ms/step - accuracy: 0.6304 - loss: 0.6103 - val_accuracy: 0.7312 - val_loss: 0.4830\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7362 - loss: 0.5057 - val_accuracy: 0.7312 - val_loss: 0.4884\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7357 - loss: 0.4985 - val_accuracy: 0.7312 - val_loss: 0.4433\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 603ms/step - accuracy: 0.7322 - loss: 0.4882 - val_accuracy: 0.7406 - val_loss: 0.4513\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7539 - loss: 0.4674 - val_accuracy: 0.7406 - val_loss: 0.4362\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7401\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7179\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7401\n",
            "Time taken to train: 16.12 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 931ms/step - accuracy: 0.6203 - loss: 0.6071 - val_accuracy: 0.7312 - val_loss: 0.4766\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.7397 - loss: 0.5189 - val_accuracy: 0.7531 - val_loss: 0.4739\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step - accuracy: 0.7462 - loss: 0.4910 - val_accuracy: 0.7406 - val_loss: 0.4368\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.7400 - loss: 0.4877 - val_accuracy: 0.7563 - val_loss: 0.4406\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7472 - loss: 0.4691 - val_accuracy: 0.7563 - val_loss: 0.4318\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7504\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7224\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7504\n",
            "Time taken to train: 18.35 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 600ms/step - accuracy: 0.5666 - loss: 0.6149 - val_accuracy: 0.7312 - val_loss: 0.4845\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 488ms/step - accuracy: 0.7356 - loss: 0.5324 - val_accuracy: 0.7688 - val_loss: 0.4752\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 529ms/step - accuracy: 0.7488 - loss: 0.4921 - val_accuracy: 0.7437 - val_loss: 0.4335\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.7485 - loss: 0.4721 - val_accuracy: 0.7781 - val_loss: 0.4275\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7360 - loss: 0.4845 - val_accuracy: 0.7812 - val_loss: 0.4257\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7504\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7850\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7504\n",
            "Time taken to train: 18.28 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 605ms/step - accuracy: 0.5519 - loss: 0.6332 - val_accuracy: 0.7312 - val_loss: 0.4799\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7451 - loss: 0.5090 - val_accuracy: 0.7344 - val_loss: 0.4826\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 640ms/step - accuracy: 0.7323 - loss: 0.5028 - val_accuracy: 0.7406 - val_loss: 0.4371\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 423ms/step - accuracy: 0.7403 - loss: 0.4856 - val_accuracy: 0.7719 - val_loss: 0.4384\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.7461 - loss: 0.4810 - val_accuracy: 0.7719 - val_loss: 0.4254\n",
            "LSTM-10CNN-ContentNets w2v_sg Accuracy 0.7460\n",
            "LSTM-10CNN-ContentNets w2v_sg Precision 0.7720\n",
            "LSTM-10CNN-ContentNets w2v_sg Recall 0.7460\n",
            "Time taken to train: 23.61 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 655ms/step - accuracy: 0.7295 - loss: 0.6071 - val_accuracy: 0.7281 - val_loss: 0.4736\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 437ms/step - accuracy: 0.7185 - loss: 0.5793 - val_accuracy: 0.7469 - val_loss: 0.4783\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 633ms/step - accuracy: 0.7489 - loss: 0.4969 - val_accuracy: 0.7406 - val_loss: 0.4365\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379ms/step - accuracy: 0.7426 - loss: 0.4769 - val_accuracy: 0.7875 - val_loss: 0.4328\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.7408 - loss: 0.4609 - val_accuracy: 0.7688 - val_loss: 0.4174\n",
            "LSTM-11CNN-ContentNets w2v_sg Accuracy 0.7577\n",
            "LSTM-11CNN-ContentNets w2v_sg Precision 0.7337\n",
            "LSTM-11CNN-ContentNets w2v_sg Recall 0.7577\n",
            "Time taken to train: 23.37 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 976ms/step - accuracy: 0.6755 - loss: 0.5928 - val_accuracy: 0.7312 - val_loss: 0.4643\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 710ms/step - accuracy: 0.7649 - loss: 0.4964 - val_accuracy: 0.7719 - val_loss: 0.4669\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 687ms/step - accuracy: 0.7327 - loss: 0.4913 - val_accuracy: 0.7375 - val_loss: 0.4413\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7385 - loss: 0.4685 - val_accuracy: 0.7688 - val_loss: 0.4505\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 690ms/step - accuracy: 0.7407 - loss: 0.4835 - val_accuracy: 0.7625 - val_loss: 0.4360\n",
            "BiLSTM-Content w2v_sg Accuracy 0.7343\n",
            "BiLSTM-Content w2v_sg Precision 0.7532\n",
            "BiLSTM-Content w2v_sg Recall 0.7343\n",
            "Time taken to train: 30.77 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 887ms/step - accuracy: 0.6526 - loss: 0.6171 - val_accuracy: 0.7312 - val_loss: 0.4728\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 881ms/step - accuracy: 0.7232 - loss: 0.5171 - val_accuracy: 0.7281 - val_loss: 0.4728\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 668ms/step - accuracy: 0.7302 - loss: 0.4976 - val_accuracy: 0.7375 - val_loss: 0.4396\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.7481 - loss: 0.4885 - val_accuracy: 0.7688 - val_loss: 0.4507\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7490 - loss: 0.4795 - val_accuracy: 0.7406 - val_loss: 0.4378\n",
            "BiLSTM-CNN-Content w2v_sg Accuracy 0.7401\n",
            "BiLSTM-CNN-Content w2v_sg Precision 0.7219\n",
            "BiLSTM-CNN-Content w2v_sg Recall 0.7401\n",
            "Time taken to train: 30.78 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6661 - loss: 0.5928 - val_accuracy: 0.7281 - val_loss: 0.4573\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 700ms/step - accuracy: 0.7042 - loss: 0.5354 - val_accuracy: 0.7437 - val_loss: 0.4458\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7412 - loss: 0.4792 - val_accuracy: 0.7437 - val_loss: 0.4308\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 827ms/step - accuracy: 0.7587 - loss: 0.4413 - val_accuracy: 0.7719 - val_loss: 0.4516\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702ms/step - accuracy: 0.7492 - loss: 0.4758 - val_accuracy: 0.7656 - val_loss: 0.4233\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Accuracy 0.7533\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Precision 0.7287\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Recall 0.7533\n",
            "Time taken to train: 33.57 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7105 - loss: 0.5810 - val_accuracy: 0.7344 - val_loss: 0.4502\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 719ms/step - accuracy: 0.7558 - loss: 0.4947 - val_accuracy: 0.7688 - val_loss: 0.4388\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7427 - loss: 0.4732 - val_accuracy: 0.7656 - val_loss: 0.4207\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 717ms/step - accuracy: 0.7539 - loss: 0.4526 - val_accuracy: 0.8000 - val_loss: 0.4251\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7472 - loss: 0.4580 - val_accuracy: 0.7719 - val_loss: 0.4236\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Accuracy 0.7562\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Precision 0.7314\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Recall 0.7562\n",
            "Time taken to train: 34.08 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6296 - loss: 0.6171 - val_accuracy: 0.7281 - val_loss: 0.4724\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7421 - loss: 0.4968 - val_accuracy: 0.7375 - val_loss: 0.4540\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 715ms/step - accuracy: 0.7442 - loss: 0.4771 - val_accuracy: 0.7719 - val_loss: 0.4312\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7626 - loss: 0.4546 - val_accuracy: 0.7625 - val_loss: 0.4234\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 990ms/step - accuracy: 0.7615 - loss: 0.4477 - val_accuracy: 0.7688 - val_loss: 0.4410\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Accuracy 0.7460\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Precision 0.7139\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Recall 0.7460\n",
            "Time taken to train: 35.99 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7270 - loss: 0.6168 - val_accuracy: 0.7312 - val_loss: 0.4701\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 723ms/step - accuracy: 0.7417 - loss: 0.4836 - val_accuracy: 0.7750 - val_loss: 0.4583\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 873ms/step - accuracy: 0.7569 - loss: 0.4749 - val_accuracy: 0.7594 - val_loss: 0.4205\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 738ms/step - accuracy: 0.7404 - loss: 0.4734 - val_accuracy: 0.7688 - val_loss: 0.4140\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7599 - loss: 0.4678 - val_accuracy: 0.7750 - val_loss: 0.4244\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Accuracy 0.7606\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Precision 0.7370\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Recall 0.7606\n",
            "Time taken to train: 38.38 seconds\n",
            "\n",
            "Iteration 4 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 488ms/step - accuracy: 0.7136 - loss: 0.5870 - val_accuracy: 0.7312 - val_loss: 0.5799\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7410 - loss: 0.4930 - val_accuracy: 0.7406 - val_loss: 0.4984\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 597ms/step - accuracy: 0.7412 - loss: 0.4928 - val_accuracy: 0.7469 - val_loss: 0.4987\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7242 - loss: 0.4847 - val_accuracy: 0.7500 - val_loss: 0.4856\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.7371 - loss: 0.4646 - val_accuracy: 0.7469 - val_loss: 0.4721\n",
            "LSTM-Content w2v_sg Accuracy 0.7489\n",
            "LSTM-Content w2v_sg Precision 0.7748\n",
            "LSTM-Content w2v_sg Recall 0.7489\n",
            "Time taken to train: 16.81 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 606ms/step - accuracy: 0.5423 - loss: 0.6322 - val_accuracy: 0.7312 - val_loss: 0.6009\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7346 - loss: 0.5343 - val_accuracy: 0.7344 - val_loss: 0.5053\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 442ms/step - accuracy: 0.7344 - loss: 0.4757 - val_accuracy: 0.7344 - val_loss: 0.4962\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7475 - loss: 0.4696 - val_accuracy: 0.7469 - val_loss: 0.4883\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7638 - loss: 0.4681 - val_accuracy: 0.7437 - val_loss: 0.4897\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7504\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7779\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7504\n",
            "Time taken to train: 15.43 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 586ms/step - accuracy: 0.5419 - loss: 0.6174 - val_accuracy: 0.7312 - val_loss: 0.5775\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 569ms/step - accuracy: 0.7373 - loss: 0.5366 - val_accuracy: 0.7312 - val_loss: 0.4999\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - accuracy: 0.7332 - loss: 0.4822 - val_accuracy: 0.7281 - val_loss: 0.4920\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7545 - loss: 0.4656 - val_accuracy: 0.7500 - val_loss: 0.4873\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - accuracy: 0.7408 - loss: 0.4610 - val_accuracy: 0.7531 - val_loss: 0.4691\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7533\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7830\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7533\n",
            "Time taken to train: 18.43 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 984ms/step - accuracy: 0.6272 - loss: 0.6065 - val_accuracy: 0.7312 - val_loss: 0.5602\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.7338 - loss: 0.5217 - val_accuracy: 0.7625 - val_loss: 0.4970\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - accuracy: 0.7457 - loss: 0.4829 - val_accuracy: 0.7563 - val_loss: 0.4925\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 444ms/step - accuracy: 0.7507 - loss: 0.4593 - val_accuracy: 0.7437 - val_loss: 0.4745\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 840ms/step - accuracy: 0.7650 - loss: 0.4625 - val_accuracy: 0.7437 - val_loss: 0.4717\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7518\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7870\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7518\n",
            "Time taken to train: 22.64 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 993ms/step - accuracy: 0.6544 - loss: 0.6162 - val_accuracy: 0.7312 - val_loss: 0.5507\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.7349 - loss: 0.4963 - val_accuracy: 0.7406 - val_loss: 0.5051\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 439ms/step - accuracy: 0.7307 - loss: 0.4854 - val_accuracy: 0.7312 - val_loss: 0.5028\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - accuracy: 0.7439 - loss: 0.4706 - val_accuracy: 0.7594 - val_loss: 0.4804\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step - accuracy: 0.7396 - loss: 0.4598 - val_accuracy: 0.7500 - val_loss: 0.4859\n",
            "LSTM-10CNN-ContentNets w2v_sg Accuracy 0.7518\n",
            "LSTM-10CNN-ContentNets w2v_sg Precision 0.7822\n",
            "LSTM-10CNN-ContentNets w2v_sg Recall 0.7518\n",
            "Time taken to train: 20.13 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5898 - loss: 0.6300 - val_accuracy: 0.7312 - val_loss: 0.5665\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 0.7159 - loss: 0.5185 - val_accuracy: 0.7406 - val_loss: 0.5013\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.7539 - loss: 0.4818 - val_accuracy: 0.7437 - val_loss: 0.4963\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7485 - loss: 0.4685 - val_accuracy: 0.7688 - val_loss: 0.4723\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 518ms/step - accuracy: 0.7548 - loss: 0.4590 - val_accuracy: 0.7406 - val_loss: 0.4789\n",
            "LSTM-11CNN-ContentNets w2v_sg Accuracy 0.7650\n",
            "LSTM-11CNN-ContentNets w2v_sg Precision 0.7435\n",
            "LSTM-11CNN-ContentNets w2v_sg Recall 0.7650\n",
            "Time taken to train: 20.63 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6973 - loss: 0.5805 - val_accuracy: 0.7312 - val_loss: 0.5420\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7473 - loss: 0.4998 - val_accuracy: 0.7469 - val_loss: 0.4905\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7053 - loss: 0.4863 - val_accuracy: 0.7500 - val_loss: 0.4981\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 818ms/step - accuracy: 0.7357 - loss: 0.4611 - val_accuracy: 0.7406 - val_loss: 0.4744\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7358 - loss: 0.4698 - val_accuracy: 0.7469 - val_loss: 0.4828\n",
            "BiLSTM-Content w2v_sg Accuracy 0.7460\n",
            "BiLSTM-Content w2v_sg Precision 0.7687\n",
            "BiLSTM-Content w2v_sg Recall 0.7460\n",
            "Time taken to train: 26.41 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 912ms/step - accuracy: 0.5975 - loss: 0.6037 - val_accuracy: 0.7312 - val_loss: 0.5210\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 704ms/step - accuracy: 0.7176 - loss: 0.4769 - val_accuracy: 0.7312 - val_loss: 0.4815\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 767ms/step - accuracy: 0.7202 - loss: 0.4764 - val_accuracy: 0.7469 - val_loss: 0.4832\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7471 - loss: 0.4691 - val_accuracy: 0.7469 - val_loss: 0.4723\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7351 - loss: 0.4609 - val_accuracy: 0.7344 - val_loss: 0.4845\n",
            "BiLSTM-CNN-Content w2v_sg Accuracy 0.7460\n",
            "BiLSTM-CNN-Content w2v_sg Precision 0.7665\n",
            "BiLSTM-CNN-Content w2v_sg Recall 0.7460\n",
            "Time taken to train: 31.24 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5312 - loss: 0.6067 - val_accuracy: 0.7312 - val_loss: 0.5630\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7373 - loss: 0.5058 - val_accuracy: 0.7531 - val_loss: 0.4929\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 716ms/step - accuracy: 0.7386 - loss: 0.4766 - val_accuracy: 0.7469 - val_loss: 0.5116\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7289 - loss: 0.4796 - val_accuracy: 0.7594 - val_loss: 0.4689\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7474 - loss: 0.4632 - val_accuracy: 0.7594 - val_loss: 0.4667\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Accuracy 0.7664\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Precision 0.7503\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Recall 0.7664\n",
            "Time taken to train: 34.45 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7358 - loss: 0.5848 - val_accuracy: 0.7312 - val_loss: 0.5367\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721ms/step - accuracy: 0.7467 - loss: 0.4767 - val_accuracy: 0.7469 - val_loss: 0.4887\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 794ms/step - accuracy: 0.7379 - loss: 0.4723 - val_accuracy: 0.7563 - val_loss: 0.5023\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 838ms/step - accuracy: 0.7487 - loss: 0.4542 - val_accuracy: 0.7594 - val_loss: 0.4688\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7579 - loss: 0.4700 - val_accuracy: 0.7375 - val_loss: 0.4777\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Accuracy 0.7606\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Precision 0.7398\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Recall 0.7606\n",
            "Time taken to train: 31.99 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6926 - loss: 0.6032 - val_accuracy: 0.7437 - val_loss: 0.5080\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787ms/step - accuracy: 0.7339 - loss: 0.4920 - val_accuracy: 0.7375 - val_loss: 0.4978\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 813ms/step - accuracy: 0.7488 - loss: 0.4612 - val_accuracy: 0.7594 - val_loss: 0.4688\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 705ms/step - accuracy: 0.7576 - loss: 0.4627 - val_accuracy: 0.7500 - val_loss: 0.4805\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7574 - loss: 0.4700 - val_accuracy: 0.7563 - val_loss: 0.4637\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Accuracy 0.7679\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Precision 0.7481\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Recall 0.7679\n",
            "Time taken to train: 35.55 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6982 - loss: 0.6046 - val_accuracy: 0.7344 - val_loss: 0.6499\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7485 - loss: 0.4942 - val_accuracy: 0.7625 - val_loss: 0.5179\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 718ms/step - accuracy: 0.7421 - loss: 0.4975 - val_accuracy: 0.7437 - val_loss: 0.4891\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7558 - loss: 0.4488 - val_accuracy: 0.7469 - val_loss: 0.4910\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7447 - loss: 0.4381 - val_accuracy: 0.7500 - val_loss: 0.4784\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Accuracy 0.7591\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Precision 0.7996\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Recall 0.7591\n",
            "Time taken to train: 35.62 seconds\n",
            "\n",
            "Iteration 5 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 781ms/step - accuracy: 0.6836 - loss: 0.6039 - val_accuracy: 0.7312 - val_loss: 0.5022\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7417 - loss: 0.5261 - val_accuracy: 0.7563 - val_loss: 0.4834\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7477 - loss: 0.4944 - val_accuracy: 0.7312 - val_loss: 0.4509\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - accuracy: 0.7360 - loss: 0.4964 - val_accuracy: 0.7312 - val_loss: 0.4460\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7337 - loss: 0.4713 - val_accuracy: 0.7656 - val_loss: 0.4486\n",
            "LSTM-Content w2v_sg Accuracy 0.7504\n",
            "LSTM-Content w2v_sg Precision 0.7712\n",
            "LSTM-Content w2v_sg Recall 0.7504\n",
            "Time taken to train: 16.29 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 503ms/step - accuracy: 0.7096 - loss: 0.6073 - val_accuracy: 0.7312 - val_loss: 0.4789\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7492 - loss: 0.4683 - val_accuracy: 0.7344 - val_loss: 0.4870\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7175 - loss: 0.4967 - val_accuracy: 0.7406 - val_loss: 0.4501\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 607ms/step - accuracy: 0.7371 - loss: 0.4742 - val_accuracy: 0.7344 - val_loss: 0.4518\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.7431 - loss: 0.4715 - val_accuracy: 0.7625 - val_loss: 0.4453\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7489\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7725\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7489\n",
            "Time taken to train: 14.76 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 921ms/step - accuracy: 0.6125 - loss: 0.6160 - val_accuracy: 0.7312 - val_loss: 0.4797\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7363 - loss: 0.5082 - val_accuracy: 0.7625 - val_loss: 0.4685\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.7372 - loss: 0.4882 - val_accuracy: 0.7375 - val_loss: 0.4479\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7372 - loss: 0.4862 - val_accuracy: 0.7469 - val_loss: 0.4482\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 410ms/step - accuracy: 0.7518 - loss: 0.4697 - val_accuracy: 0.7531 - val_loss: 0.4422\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7401\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7026\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7401\n",
            "Time taken to train: 19.88 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 899ms/step - accuracy: 0.5714 - loss: 0.6160 - val_accuracy: 0.7312 - val_loss: 0.4868\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7349 - loss: 0.5059 - val_accuracy: 0.7656 - val_loss: 0.4705\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.7633 - loss: 0.4921 - val_accuracy: 0.7406 - val_loss: 0.4447\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7504 - loss: 0.4693 - val_accuracy: 0.7500 - val_loss: 0.4422\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7531 - loss: 0.4567 - val_accuracy: 0.7719 - val_loss: 0.4394\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7547\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7826\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7547\n",
            "Time taken to train: 19.42 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 698ms/step - accuracy: 0.5395 - loss: 0.6258 - val_accuracy: 0.7312 - val_loss: 0.4809\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7296 - loss: 0.5206 - val_accuracy: 0.7344 - val_loss: 0.4707\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7489 - loss: 0.4735 - val_accuracy: 0.7344 - val_loss: 0.4472\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7525 - loss: 0.4585 - val_accuracy: 0.7500 - val_loss: 0.4515\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7519 - loss: 0.4670 - val_accuracy: 0.7531 - val_loss: 0.4436\n",
            "LSTM-10CNN-ContentNets w2v_sg Accuracy 0.7518\n",
            "LSTM-10CNN-ContentNets w2v_sg Precision 0.7255\n",
            "LSTM-10CNN-ContentNets w2v_sg Recall 0.7518\n",
            "Time taken to train: 18.92 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 650ms/step - accuracy: 0.5754 - loss: 0.6245 - val_accuracy: 0.7312 - val_loss: 0.5049\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 545ms/step - accuracy: 0.7298 - loss: 0.5164 - val_accuracy: 0.7437 - val_loss: 0.4880\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 416ms/step - accuracy: 0.7471 - loss: 0.5055 - val_accuracy: 0.7437 - val_loss: 0.4506\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7466 - loss: 0.4767 - val_accuracy: 0.7563 - val_loss: 0.4467\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7581 - loss: 0.4702 - val_accuracy: 0.7500 - val_loss: 0.4387\n",
            "LSTM-11CNN-ContentNets w2v_sg Accuracy 0.7518\n",
            "LSTM-11CNN-ContentNets w2v_sg Precision 0.7255\n",
            "LSTM-11CNN-ContentNets w2v_sg Recall 0.7518\n",
            "Time taken to train: 20.86 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 908ms/step - accuracy: 0.5938 - loss: 0.5931 - val_accuracy: 0.7312 - val_loss: 0.4952\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 963ms/step - accuracy: 0.7320 - loss: 0.5428 - val_accuracy: 0.7719 - val_loss: 0.4732\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7245 - loss: 0.4981 - val_accuracy: 0.7281 - val_loss: 0.4557\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7414 - loss: 0.4680 - val_accuracy: 0.7656 - val_loss: 0.4593\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.7242 - loss: 0.4924 - val_accuracy: 0.7406 - val_loss: 0.4455\n",
            "BiLSTM-Content w2v_sg Accuracy 0.7416\n",
            "BiLSTM-Content w2v_sg Precision 0.7797\n",
            "BiLSTM-Content w2v_sg Recall 0.7416\n",
            "Time taken to train: 28.60 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 894ms/step - accuracy: 0.6037 - loss: 0.6037 - val_accuracy: 0.7312 - val_loss: 0.4666\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.7358 - loss: 0.4974 - val_accuracy: 0.7312 - val_loss: 0.4510\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930ms/step - accuracy: 0.7356 - loss: 0.4783 - val_accuracy: 0.7719 - val_loss: 0.4686\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 700ms/step - accuracy: 0.7545 - loss: 0.4744 - val_accuracy: 0.7688 - val_loss: 0.4450\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.7432 - loss: 0.4777 - val_accuracy: 0.7375 - val_loss: 0.4509\n",
            "BiLSTM-CNN-Content w2v_sg Accuracy 0.7460\n",
            "BiLSTM-CNN-Content w2v_sg Precision 0.7741\n",
            "BiLSTM-CNN-Content w2v_sg Recall 0.7460\n",
            "Time taken to train: 31.59 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5644 - loss: 0.6133 - val_accuracy: 0.7312 - val_loss: 0.4680\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7582 - loss: 0.4671 - val_accuracy: 0.7719 - val_loss: 0.4661\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7641 - loss: 0.4843 - val_accuracy: 0.7500 - val_loss: 0.4443\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 717ms/step - accuracy: 0.7357 - loss: 0.4917 - val_accuracy: 0.7406 - val_loss: 0.4493\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7497 - loss: 0.4694 - val_accuracy: 0.7375 - val_loss: 0.4413\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Accuracy 0.7533\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Precision 0.7261\n",
            "BiLSTM-00CNN-ContentNets w2v_sg Recall 0.7533\n",
            "Time taken to train: 33.81 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.6649 - loss: 0.5880 - val_accuracy: 0.7344 - val_loss: 0.4697\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 734ms/step - accuracy: 0.7472 - loss: 0.5096 - val_accuracy: 0.7437 - val_loss: 0.4542\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 770ms/step - accuracy: 0.7724 - loss: 0.4687 - val_accuracy: 0.7469 - val_loss: 0.4384\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7537 - loss: 0.4564 - val_accuracy: 0.7688 - val_loss: 0.4456\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.7698 - loss: 0.4485 - val_accuracy: 0.7469 - val_loss: 0.4428\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Accuracy 0.7504\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Precision 0.7274\n",
            "BiLSTM-01CNN-ContentNets w2v_sg Recall 0.7504\n",
            "Time taken to train: 48.68 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7204 - loss: 0.6105 - val_accuracy: 0.7312 - val_loss: 0.4711\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7426 - loss: 0.4989 - val_accuracy: 0.7344 - val_loss: 0.4587\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729ms/step - accuracy: 0.7408 - loss: 0.4690 - val_accuracy: 0.7500 - val_loss: 0.4536\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7493 - loss: 0.4676 - val_accuracy: 0.7594 - val_loss: 0.4398\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.7832 - loss: 0.4454 - val_accuracy: 0.7500 - val_loss: 0.4572\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Accuracy 0.7547\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Precision 0.7284\n",
            "BiLSTM-10CNN-ContentNets w2v_sg Recall 0.7547\n",
            "Time taken to train: 37.27 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6541 - loss: 0.6244 - val_accuracy: 0.7312 - val_loss: 0.4757\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 744ms/step - accuracy: 0.7480 - loss: 0.4782 - val_accuracy: 0.7500 - val_loss: 0.4768\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7502 - loss: 0.4843 - val_accuracy: 0.7469 - val_loss: 0.4451\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 739ms/step - accuracy: 0.7484 - loss: 0.4684 - val_accuracy: 0.7500 - val_loss: 0.4504\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.7582 - loss: 0.4742 - val_accuracy: 0.7531 - val_loss: 0.4357\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Accuracy 0.7562\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Precision 0.7311\n",
            "BiLSTM-11CNN-ContentNets w2v_sg Recall 0.7562\n",
            "Time taken to train: 36.05 seconds\n",
            "\n",
            "Summary for w2v_sg:\n",
            "LSTM-00CNN-ContentNets w2v_sg ACCURACY 0.7448 ± 0.0125\n",
            "LSTM-00CNN-ContentNets w2v_sg PRECISION 0.7405 ± 0.0286\n",
            "LSTM-00CNN-ContentNets w2v_sg RECALL 0.7448 ± 0.0125\n",
            "LSTM-00CNN-ContentNets w2v_sg EXECUTION TIME 19.30 ± 0.78\n",
            "LSTM-01CNN-ContentNets w2v_sg ACCURACY 0.7474 ± 0.0111\n",
            "LSTM-01CNN-ContentNets w2v_sg PRECISION 0.7817 ± 0.0061\n",
            "LSTM-01CNN-ContentNets w2v_sg RECALL 0.7474 ± 0.0111\n",
            "LSTM-01CNN-ContentNets w2v_sg EXECUTION TIME 20.51 ± 1.51\n",
            "LSTM-10CNN-ContentNets w2v_sg ACCURACY 0.7463 ± 0.0125\n",
            "LSTM-10CNN-ContentNets w2v_sg PRECISION 0.7554 ± 0.0216\n",
            "LSTM-10CNN-ContentNets w2v_sg RECALL 0.7463 ± 0.0125\n",
            "LSTM-10CNN-ContentNets w2v_sg EXECUTION TIME 20.81 ± 1.69\n",
            "LSTM-11CNN-ContentNets w2v_sg ACCURACY 0.7509 ± 0.0122\n",
            "LSTM-11CNN-ContentNets w2v_sg PRECISION 0.7426 ± 0.0186\n",
            "LSTM-11CNN-ContentNets w2v_sg RECALL 0.7509 ± 0.0122\n",
            "LSTM-11CNN-ContentNets w2v_sg EXECUTION TIME 21.43 ± 1.09\n",
            "LSTM-Content w2v_sg ACCURACY 0.7416 ± 0.0117\n",
            "LSTM-Content w2v_sg PRECISION 0.7681 ± 0.0068\n",
            "LSTM-Content w2v_sg RECALL 0.7416 ± 0.0117\n",
            "LSTM-Content w2v_sg EXECUTION TIME 17.28 ± 1.93\n",
            "LSTM-CNN-Content w2v_sg ACCURACY 0.7425 ± 0.0114\n",
            "LSTM-CNN-Content w2v_sg PRECISION 0.7608 ± 0.0220\n",
            "LSTM-CNN-Content w2v_sg RECALL 0.7425 ± 0.0114\n",
            "LSTM-CNN-Content w2v_sg EXECUTION TIME 15.73 ± 0.59\n",
            "BiLSTM-00CNN-ContentNets w2v_sg ACCURACY 0.7585 ± 0.0059\n",
            "BiLSTM-00CNN-ContentNets w2v_sg PRECISION 0.7408 ± 0.0119\n",
            "BiLSTM-00CNN-ContentNets w2v_sg RECALL 0.7585 ± 0.0059\n",
            "BiLSTM-00CNN-ContentNets w2v_sg EXECUTION TIME 35.24 ± 1.93\n",
            "BiLSTM-01CNN-ContentNets w2v_sg ACCURACY 0.7495 ± 0.0117\n",
            "BiLSTM-01CNN-ContentNets w2v_sg PRECISION 0.7514 ± 0.0235\n",
            "BiLSTM-01CNN-ContentNets w2v_sg RECALL 0.7495 ± 0.0117\n",
            "BiLSTM-01CNN-ContentNets w2v_sg EXECUTION TIME 38.53 ± 6.00\n",
            "BiLSTM-10CNN-ContentNets w2v_sg ACCURACY 0.7530 ± 0.0095\n",
            "BiLSTM-10CNN-ContentNets w2v_sg PRECISION 0.7364 ± 0.0306\n",
            "BiLSTM-10CNN-ContentNets w2v_sg RECALL 0.7530 ± 0.0095\n",
            "BiLSTM-10CNN-ContentNets w2v_sg EXECUTION TIME 38.43 ± 2.81\n",
            "BiLSTM-11CNN-ContentNets w2v_sg ACCURACY 0.7527 ± 0.0122\n",
            "BiLSTM-11CNN-ContentNets w2v_sg PRECISION 0.7561 ± 0.0276\n",
            "BiLSTM-11CNN-ContentNets w2v_sg RECALL 0.7527 ± 0.0122\n",
            "BiLSTM-11CNN-ContentNets w2v_sg EXECUTION TIME 37.73 ± 1.60\n",
            "BiLSTM-Content w2v_sg ACCURACY 0.7364 ± 0.0085\n",
            "BiLSTM-Content w2v_sg PRECISION 0.7632 ± 0.0098\n",
            "BiLSTM-Content w2v_sg RECALL 0.7364 ± 0.0085\n",
            "BiLSTM-Content w2v_sg EXECUTION TIME 29.20 ± 1.73\n",
            "BiLSTM-CNN-Content w2v_sg ACCURACY 0.7387 ± 0.0076\n",
            "BiLSTM-CNN-Content w2v_sg PRECISION 0.7299 ± 0.0417\n",
            "BiLSTM-CNN-Content w2v_sg RECALL 0.7387 ± 0.0076\n",
            "BiLSTM-CNN-Content w2v_sg EXECUTION TIME 29.92 ± 1.59\n",
            "Loaded ft_cbow shape: (4023, 128)\n",
            "\n",
            "Iteration 1 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with ft_cbow embedding:\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711ms/step - accuracy: 0.6428 - loss: 0.5872 - val_accuracy: 0.7312 - val_loss: 0.5260\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379ms/step - accuracy: 0.7345 - loss: 0.5016 - val_accuracy: 0.7594 - val_loss: 0.4851\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.7498 - loss: 0.4785 - val_accuracy: 0.7594 - val_loss: 0.4972\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.7353 - loss: 0.4865 - val_accuracy: 0.7594 - val_loss: 0.4780\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 574ms/step - accuracy: 0.7354 - loss: 0.4674 - val_accuracy: 0.7594 - val_loss: 0.4797\n",
            "LSTM-Content ft_cbow Accuracy 0.7460\n",
            "LSTM-Content ft_cbow Precision 0.7542\n",
            "LSTM-Content ft_cbow Recall 0.7460\n",
            "Time taken to train: 18.53 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 519ms/step - accuracy: 0.6289 - loss: 0.5956 - val_accuracy: 0.7312 - val_loss: 0.5066\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7332 - loss: 0.4903 - val_accuracy: 0.7312 - val_loss: 0.4881\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 610ms/step - accuracy: 0.7361 - loss: 0.4727 - val_accuracy: 0.7312 - val_loss: 0.4752\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7287 - loss: 0.4667 - val_accuracy: 0.7312 - val_loss: 0.4743\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 413ms/step - accuracy: 0.7362 - loss: 0.4604 - val_accuracy: 0.7312 - val_loss: 0.4711\n",
            "LSTM-CNN-Content ft_cbow Accuracy 0.7299\n",
            "LSTM-CNN-Content ft_cbow Precision 0.6592\n",
            "LSTM-CNN-Content ft_cbow Recall 0.7299\n",
            "Time taken to train: 15.46 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 604ms/step - accuracy: 0.6105 - loss: 0.5936 - val_accuracy: 0.7625 - val_loss: 0.5229\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.7267 - loss: 0.5110 - val_accuracy: 0.7625 - val_loss: 0.4824\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 429ms/step - accuracy: 0.7521 - loss: 0.4653 - val_accuracy: 0.7375 - val_loss: 0.5077\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 812ms/step - accuracy: 0.7546 - loss: 0.4726 - val_accuracy: 0.7688 - val_loss: 0.4762\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7529 - loss: 0.4716 - val_accuracy: 0.7500 - val_loss: 0.4758\n",
            "LSTM-00CNN-ContentNets ft_cbow Accuracy 0.7533\n",
            "LSTM-00CNN-ContentNets ft_cbow Precision 0.7260\n",
            "LSTM-00CNN-ContentNets ft_cbow Recall 0.7533\n",
            "Time taken to train: 22.79 seconds\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 665ms/step - accuracy: 0.7263 - loss: 0.5691 - val_accuracy: 0.7656 - val_loss: 0.4949\n",
            "Epoch 2/5\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - accuracy: 0.7734 - loss: 0.4831"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWF6lpFj88_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
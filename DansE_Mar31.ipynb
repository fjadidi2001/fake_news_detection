{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNkvxGR59hlIGq54UvcbPEs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/fake_news_detection/blob/main/DansE_Mar31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "oA7Z8kvmccRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive in Colab"
      ],
      "metadata": {
        "id": "PxIpn64y8_JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Mzv5ciD71hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5890cb91-2cb3-42e4-8182-665ee200a863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "9J1bk_HnDc7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = '/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_path, encoding='latin-1')"
      ],
      "metadata": {
        "id": "bhyykHvM89kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Inspection"
      ],
      "metadata": {
        "id": "TDzZ-uobD38a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(2))  # See first 2 rows\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSYdMJU3DiFH",
        "outputId": "c3497beb-abff-43fd-c4dd-7eccce71a1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     account_id       post_id    Category               Page  \\\n",
            "0  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "\n",
            "                                            Post URL Date Published Post Type  \\\n",
            "0  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "1  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "\n",
            "               Rating Debate  share_count  reaction_count  comment_count  \\\n",
            "0  no factual content    NaN          NaN           146.0           15.0   \n",
            "1         mostly true    NaN          1.0            33.0           34.0   \n",
            "\n",
            "                                        Context Post  \n",
            "0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1  Can either candidate move the needle in the de...  \n",
            "\n",
            "Missing values:\n",
            " account_id           0\n",
            "post_id              0\n",
            "Category             0\n",
            "Page                 0\n",
            "Post URL             0\n",
            "Date Published       0\n",
            "Post Type            0\n",
            "Rating               0\n",
            "Debate            1984\n",
            "share_count         70\n",
            "reaction_count       2\n",
            "comment_count        2\n",
            "Context Post         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values"
      ],
      "metadata": {
        "id": "_hVZN6j7FnqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strategy 1: Fill categorical columns\n",
        "df['Rating'] = df['Rating'].fillna('Unknown')\n",
        "df['Debate'] = df['Debate'].fillna('Not Specified')\n",
        "\n",
        "# Strategy 2: Fill numerical columns with median\n",
        "numeric_cols = ['share_count', 'reaction_count', 'comment_count']\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Alternative: Drop rows with critical missing values\n",
        "# df = df.dropna(subset=['important_column'])"
      ],
      "metadata": {
        "id": "CCesok3vEbWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Preprocessing"
      ],
      "metadata": {
        "id": "GFWw2cFnGKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date to datetime format\n",
        "df['Date Published'] = pd.to_datetime(df['Date Published'], format='%m/%d/%Y')\n",
        "\n",
        "# Clean text columns\n",
        "df['Context Post'] = df['Context Post'].str.replace('\"', '')"
      ],
      "metadata": {
        "id": "-jLm9vpHGC-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['account_id'] = df['account_id'].astype(str)\n",
        "df['post_id'] = df['post_id'].astype(str)"
      ],
      "metadata": {
        "id": "o2_ZzlhgGlq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['Category', 'Page', 'Post Type']\n",
        "df[categorical_cols] = df[categorical_cols].fillna('Unknown')"
      ],
      "metadata": {
        "id": "DuV4oIehGoMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgVsdZkBG2KU",
        "outputId": "5d16b487-68eb-47d9-fcff-c88889ad8418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2282 entries, 0 to 2281\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   account_id      2282 non-null   object        \n",
            " 1   post_id         2282 non-null   object        \n",
            " 2   Category        2282 non-null   object        \n",
            " 3   Page            2282 non-null   object        \n",
            " 4   Post URL        2282 non-null   object        \n",
            " 5   Date Published  2282 non-null   datetime64[ns]\n",
            " 6   Post Type       2282 non-null   object        \n",
            " 7   Rating          2282 non-null   object        \n",
            " 8   Debate          2282 non-null   object        \n",
            " 9   share_count     2282 non-null   float64       \n",
            " 10  reaction_count  2282 non-null   float64       \n",
            " 11  comment_count   2282 non-null   float64       \n",
            " 12  Context Post    2282 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(3), object(9)\n",
            "memory usage: 231.9+ KB\n",
            "None\n",
            "account_id        0\n",
            "post_id           0\n",
            "Category          0\n",
            "Page              0\n",
            "Post URL          0\n",
            "Date Published    0\n",
            "Post Type         0\n",
            "Rating            0\n",
            "Debate            0\n",
            "share_count       0\n",
            "reaction_count    0\n",
            "comment_count     0\n",
            "Context Post      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processElement(elem):\n",
        "    id_line = elem[0]\n",
        "    text = elem[1]\n",
        "    # Use 'Context Post' instead of 'content' if needed\n",
        "    text = tkn.createCorpus(text, remove_stopwords=False)\n",
        "    return id_line, text"
      ],
      "metadata": {
        "id": "hGiF99i4JzJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main source"
      ],
      "metadata": {
        "id": "LVGdPq9osmqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Download and save to Drive (run once)\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip -O /content/drive/MyDrive/glove.6B.zip\n",
        "!unzip /content/drive/MyDrive/glove.6B.zip -d /content/drive/MyDrive/glove\n",
        "\n",
        "# Load from Drive in future sessions\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/glove/glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(embeddings_index)} word vectors.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K5rbfZArlgD",
        "outputId": "b4013e1c-35b5-4486-c05b-3c22230a7495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/glove.6B.zip\n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.50d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.100d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.200d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.300d.txt  \n",
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wordembeddings"
      ],
      "metadata": {
        "id": "kzfAQRwVzfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clean up the environment\n",
        "!pip uninstall -y numpy mittens gensim scipy smart-open wrapt tensorflow tensorflow-datasets dm-tree numba\n",
        "\n",
        "# Step 2: Install compatible versions\n",
        "!pip install numpy==1.26.4 mittens==0.2 gensim==4.3.3 scipy==1.13.1 smart-open==7.1.0 wrapt==1.17.2\n",
        "\n",
        "# Step 3: Restart runtime (run this once, then comment out)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "# Step 4: After restart, run the code\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-iINw1nwrYN",
        "outputId": "d1acb732-f0b4-4cfb-a026-a2af9beaa851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping mittens as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scipy 1.14.1\n",
            "Uninstalling scipy-1.14.1:\n",
            "  Successfully uninstalled scipy-1.14.1\n",
            "Found existing installation: smart-open 7.1.0\n",
            "Uninstalling smart-open-7.1.0:\n",
            "  Successfully uninstalled smart-open-7.1.0\n",
            "Found existing installation: wrapt 1.17.2\n",
            "Uninstalling wrapt-1.17.2:\n",
            "  Successfully uninstalled wrapt-1.17.2\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Found existing installation: tensorflow-datasets 4.9.8\n",
            "Uninstalling tensorflow-datasets-4.9.8:\n",
            "  Successfully uninstalled tensorflow-datasets-4.9.8\n",
            "Found existing installation: dm-tree 0.1.9\n",
            "Uninstalling dm-tree-0.1.9:\n",
            "  Successfully uninstalled dm-tree-0.1.9\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mittens==0.2\n",
            "  Downloading mittens-0.2-py3-none-any.whl.metadata (377 bytes)\n",
            "Collecting gensim==4.3.3\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open==7.1.0\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt==1.17.2\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, mittens, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "tensorflow-probability 0.25.0 requires dm-tree, which is not installed.\n",
            "umap-learn 0.5.7 requires numba>=0.51.2, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n",
            "shap 0.47.0 requires numba>=0.54, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 mittens-0.2 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)\n",
        "import osfit(cooccurrence, vocab=None, initial_embedding_dict=None)\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "    def word2MittensEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2mittens = np.empty(shape=(self.no_words, no_components))\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        model = Mittens(n=no_components, max_iter=epochs, mittens=learning_rate)\n",
        "        embeddings = model.fit(cooc_matrix, vocab=vocab)\n",
        "        self.word2mittens[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2mittens[idx] = embeddings[idx - 1]\n",
        "        return self.word2mittens\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    w2m = we.word2MittensEmbedding()\n",
        "    print(\"Mittens:\", w2m.shape)\n",
        "    print(w2m)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])\n",
        "    print(\"Mittens:\", w2m[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tJ-FKOOovXUR",
        "outputId": "2e02fed7-7d80-488e-b76e-531ea717c3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version: 0.2\n",
            "(3, 15)\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14]]\n",
            "Word2Vec: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.21626532e-05  3.19088437e-03 -7.12745590e-03 ...  9.92520479e-04\n",
            "   7.14840600e-03  2.83964048e-03]\n",
            " [-3.82514030e-04  1.51936125e-04  3.97204095e-03 ...  2.31946167e-03\n",
            "  -3.84517061e-03  3.48054501e-03]\n",
            " ...\n",
            " [-1.44330040e-03 -3.37802432e-03 -5.04739862e-03 ...  4.78180777e-03\n",
            "   3.40414606e-03  2.03621481e-03]\n",
            " [ 5.68562094e-03 -4.50939965e-03  6.46589976e-03 ...  4.88198549e-03\n",
            "  -7.37946481e-03  7.49228429e-03]\n",
            " [-1.35904271e-03  5.24326880e-03  7.78503902e-03 ... -6.09789602e-03\n",
            "  -7.12639559e-03 -4.63685114e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04 ...  4.79545008e-04\n",
            "   1.65466184e-03 -2.04305412e-04]\n",
            " [-1.36351539e-03  1.12285069e-03 -1.62398699e-03 ...  1.27794396e-03\n",
            "  -4.78518370e-04  1.83548301e-03]\n",
            " ...\n",
            " [-2.22318270e-03  2.95931986e-05 -4.96662979e-04 ...  1.28600537e-03\n",
            "   9.15645447e-04 -2.91286968e-04]\n",
            " [-3.23804357e-04  9.54689051e-04 -1.18813978e-03 ...  6.51234936e-04\n",
            "   2.29042576e-04  1.05157425e-03]\n",
            " [-4.99513757e-04  2.49632495e-03  2.18920293e-03 ...  4.68000828e-04\n",
            "  -1.34677067e-03 -1.70546729e-04]]\n",
            "GloVe: (15, 128)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.35759968 -0.41002173 -0.11296739 ... -0.13695379 -0.08978107\n",
            "  -0.02064198]\n",
            " [ 0.03458208 -0.26300714  0.31167143 ... -0.42121385  0.17037075\n",
            "   0.06615572]\n",
            " ...\n",
            " [ 0.00209569  0.26936345  0.07195031 ...  0.01113254  0.02607798\n",
            "   0.16050002]\n",
            " [ 0.00497766  0.02229993  0.00638193 ...  0.05898192 -0.15140509\n",
            "  -0.05942085]\n",
            " [ 0.08744059  0.12552654  0.06976608 ... -0.14350026 -0.07537804\n",
            "   0.00438942]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Mittens' object has no attribute 'has_embedding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a5e2d75135b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mw2m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2MittensEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mittens:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a5e2d75135b9>\u001b[0m in \u001b[0;36mword2MittensEmbedding\u001b[0;34m(self, window_size, no_components, epochs, workers, learning_rate)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMittens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmittens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2mittens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/mittens_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, vocab, initial_embedding_dict, fixed_initialization)\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_coincidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         return self._fit(X, weights, log_coincidence,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                          \u001b[0minitial_embedding_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_embedding_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/np_mittens.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, coincidence, weights, log_coincidence, vocab, initial_embedding_dict, fixed_initialization)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             gradients, error = self._get_gradients_and_error(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 pred, log_coincidence, weights)\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/np_mittens.py\u001b[0m in \u001b[0;36m_get_gradients_and_error\u001b[0;34m(self, predictions, log_coincidence, weights)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmittens\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcurr_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mwgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmittens\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Mittens' object has no attribute 'has_embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)\n",
        "\n",
        "# Minimal test for Mittens\n",
        "vocab = ['hello', 'world']\n",
        "cooc_matrix = np.array([[0, 1], [1, 0]])  # Simple co-occurrence matrix\n",
        "mittens_model = Mittens(n=10, max_iter=10)\n",
        "try:\n",
        "    embeddings = mittens_model.fit(cooc_matrix, vocab=vocab)\n",
        "    print(\"Mittens test successful:\", embeddings.shape)\n",
        "except Exception as e:\n",
        "    print(\"Mittens test failed:\", str(e))\n",
        "\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "    def word2MittensEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2mittens = np.empty(shape=(self.no_words, no_components))\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        model = Mittens(n=no_components, max_iter=epochs, mittens=learning_rate)\n",
        "        try:\n",
        "            embeddings = model.fit(cooc_matrix, vocab=vocab)  # Explicitly test this\n",
        "            self.word2mittens[0] = np.zeros(no_components)\n",
        "            for word, idx in self.word2id.items():\n",
        "                self.word2mittens[idx] = embeddings[idx - 1]\n",
        "        except AttributeError as e:\n",
        "            print(f\"Error in Mittens.fit: {e}\")\n",
        "            embeddings = np.zeros((len(vocab), no_components))  # Fallback\n",
        "            self.word2mittens[0] = np.zeros(no_components)\n",
        "            for i, word in enumerate(vocab, 1):\n",
        "                self.word2mittens[i] = embeddings[i - 1]\n",
        "        return self.word2mittens\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    w2m = we.word2MittensEmbedding()\n",
        "    print(\"Mittens:\", w2m.shape)\n",
        "    print(w2m)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])\n",
        "    print(\"Mittens:\", w2m[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzniUIiExhUt",
        "outputId": "976c519e-ad97-46f8-df34-92413a655258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version: 0.2\n",
            "Mittens test failed: 'Mittens' object has no attribute 'has_embedding'\n",
            "(3, 15)\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14]]\n",
            "Word2Vec: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.21626532e-05  3.19088437e-03 -7.12745590e-03 ...  9.92520479e-04\n",
            "   7.14840600e-03  2.83964048e-03]\n",
            " [-3.82514030e-04  1.51936125e-04  3.97204095e-03 ...  2.31946167e-03\n",
            "  -3.84517061e-03  3.48054501e-03]\n",
            " ...\n",
            " [-1.44330040e-03 -3.37802432e-03 -5.04739862e-03 ...  4.78180777e-03\n",
            "   3.40414606e-03  2.03621481e-03]\n",
            " [ 5.68562094e-03 -4.50939965e-03  6.46589976e-03 ...  4.88198549e-03\n",
            "  -7.37946481e-03  7.49228429e-03]\n",
            " [-1.35904271e-03  5.24326880e-03  7.78503902e-03 ... -6.09789602e-03\n",
            "  -7.12639559e-03 -4.63685114e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04 ...  4.79545008e-04\n",
            "   1.65466184e-03 -2.04305412e-04]\n",
            " [-1.36351539e-03  1.12285069e-03 -1.62398699e-03 ...  1.27794396e-03\n",
            "  -4.78518370e-04  1.83548301e-03]\n",
            " ...\n",
            " [-2.22318270e-03  2.95931986e-05 -4.96662979e-04 ...  1.28600537e-03\n",
            "   9.15645447e-04 -2.91286968e-04]\n",
            " [-3.23804357e-04  9.54689051e-04 -1.18813978e-03 ...  6.51234936e-04\n",
            "   2.29042576e-04  1.05157425e-03]\n",
            " [-4.99513757e-04  2.49632495e-03  2.18920293e-03 ...  4.68000828e-04\n",
            "  -1.34677067e-03 -1.70546729e-04]]\n",
            "GloVe: (15, 128)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.24156722  0.19728762  0.28115077 ...  0.25290197 -0.28166244\n",
            "   0.03103951]\n",
            " [-0.20704135 -0.10191444  0.2596386  ...  0.16890988  0.03980409\n",
            "   0.13393758]\n",
            " ...\n",
            " [-0.10637504 -0.02374604 -0.0016289  ...  0.03591276  0.28356568\n",
            "   0.06366436]\n",
            " [-0.05972623  0.04286632  0.09204827 ...  0.1193088   0.33685324\n",
            "  -0.31354328]\n",
            " [-0.12742595 -0.09153549  0.28084373 ... -0.32305798  0.05837046\n",
            "  -0.34258802]]\n",
            "Error in Mittens.fit: 'Mittens' object has no attribute 'has_embedding'\n",
            "Mittens: (15, 128)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "\n",
            "Comparison for word ID 1:\n",
            "Word2Vec: [-6.21626532e-05  3.19088437e-03 -7.12745590e-03  6.01633405e-03\n",
            "  4.82634921e-03  3.97735788e-03  5.58952475e-03  6.64290274e-03\n",
            "  6.49750407e-04 -1.30172889e-03  4.28103493e-04 -7.31625035e-03\n",
            "  6.59953337e-03 -5.00487117e-03  6.55153207e-03 -3.32944584e-03\n",
            "  5.09716512e-04 -7.12373713e-03 -7.48809706e-03 -6.06476609e-03\n",
            " -6.01806538e-03  2.62050075e-04 -5.66331577e-03 -3.86920548e-03\n",
            " -4.16113203e-03 -3.37171252e-03  5.41871926e-03  3.72564164e-03\n",
            "  6.80003501e-03  5.55603579e-03 -4.45879949e-03  5.70788607e-03\n",
            " -7.26995803e-03 -2.01427122e-03 -6.02612738e-03  3.31634958e-03\n",
            "  1.43352617e-03  5.52080385e-03  2.32943310e-03 -5.44838468e-03\n",
            "  5.98756177e-03 -4.64449916e-03  7.02972896e-03  2.28456082e-03\n",
            " -3.11649730e-03 -3.70101258e-03 -3.46256793e-03 -4.79195034e-03\n",
            "  7.32414331e-03 -2.00591167e-03  6.06871955e-03 -7.54190609e-03\n",
            "  1.68094877e-03 -9.79775796e-04  5.90900565e-03 -7.03375321e-03\n",
            "  5.83272101e-03 -3.95497913e-03 -4.70296340e-03 -4.40138392e-03\n",
            " -2.66821543e-03 -2.65624467e-03 -2.50413013e-03 -5.86187281e-03\n",
            "  6.00978325e-04 -4.53708722e-04 -1.28188857e-03  2.92269792e-03\n",
            " -5.91868116e-03 -2.48495163e-03  4.01353044e-03  6.70103775e-03\n",
            " -7.66575430e-03  5.61965723e-03  4.15526563e-03 -3.09771299e-03\n",
            "  6.73769321e-03 -7.15261744e-03  5.66246081e-03  4.26008087e-03\n",
            "  9.85841965e-04 -4.10628133e-03 -3.25019588e-03 -2.61222548e-03\n",
            "  1.28108205e-03  1.24865468e-03  5.82506089e-03  7.80742289e-03\n",
            "  6.93350285e-03 -3.08938394e-03  7.56247900e-03 -5.23670344e-04\n",
            "  3.73711600e-03  1.97167136e-03 -4.63132892e-04  2.85691721e-03\n",
            " -4.20561666e-03 -4.55231313e-03 -5.94439125e-03  1.47928542e-03\n",
            "  5.05184289e-03  6.73822535e-04  9.28732043e-04  2.46044085e-03\n",
            "  6.36986131e-03 -6.00371370e-03  1.73082878e-03 -5.86407073e-03\n",
            "  2.87816045e-03  7.43294507e-03  5.87216392e-03  5.02722338e-03\n",
            "  6.27435837e-03  5.13774622e-03  5.31336619e-03  6.73875213e-03\n",
            " -3.89733445e-03  7.20354123e-03  3.95858521e-03 -1.59854104e-03\n",
            "  6.62540551e-03  3.92472045e-03  7.54022226e-03  2.18087039e-03\n",
            "  7.74372742e-03  9.92520479e-04  7.14840600e-03  2.83964048e-03]\n",
            "FastText: [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04  1.07396161e-03\n",
            "  7.47827522e-04  2.43436918e-03  1.25494599e-03  8.32708203e-04\n",
            "  1.39498618e-04 -1.04375544e-03  1.66534202e-03  5.92023076e-04\n",
            " -1.01467571e-03  4.17726085e-04  1.15030364e-03 -8.53901089e-04\n",
            "  3.93663533e-04  1.66030577e-03  8.04261887e-04 -1.37844379e-03\n",
            " -1.00217399e-03 -1.71076367e-03 -6.08318776e-04 -3.13780096e-04\n",
            "  7.09959713e-04  6.52309740e-04 -1.03251881e-03  6.82479527e-04\n",
            "  1.76711939e-04 -1.86265504e-03  6.39586418e-04  1.27322774e-03\n",
            " -2.63598538e-03  1.30318059e-03  1.28268311e-03  7.31006585e-05\n",
            " -8.57610779e-04 -1.77271932e-03  4.76834684e-05  7.52914173e-04\n",
            "  6.25460816e-04 -3.61822196e-04 -2.49825674e-03  6.06271380e-04\n",
            "  2.61506008e-04 -1.91198278e-03 -7.39933399e-04 -4.00340045e-03\n",
            "  3.98896955e-04 -6.40470942e-04 -9.73124232e-04 -4.94266103e-04\n",
            "  9.33958218e-04  3.16818740e-04 -1.39790284e-03  8.03306350e-04\n",
            "  4.68277285e-04 -7.05544895e-04  8.22283386e-04 -1.07828462e-04\n",
            "  3.76482669e-04  2.11784281e-04 -4.11284942e-04  9.16630845e-04\n",
            " -3.64862324e-04 -6.43940584e-04 -1.22504728e-03 -4.09014639e-04\n",
            "  2.33947922e-05 -4.68008395e-04 -1.46471866e-04  1.28898071e-03\n",
            " -1.87438796e-03 -1.11290443e-04 -2.82968773e-04  1.62297476e-03\n",
            " -3.61244201e-05 -1.74025889e-03  2.76980782e-03 -8.65978887e-04\n",
            "  1.14296249e-03 -1.82072268e-04 -1.75701268e-03  7.34397385e-04\n",
            " -1.71435822e-03  3.74486670e-04 -2.81040557e-05 -2.88294628e-04\n",
            "  2.09705951e-03 -7.59013637e-04  1.51762320e-03 -4.17047850e-04\n",
            "  4.31056396e-04 -4.13735892e-04 -1.18768564e-03 -2.78128078e-03\n",
            " -3.55213997e-04 -2.31009349e-03  5.31876693e-04  1.93082809e-03\n",
            "  2.91791657e-04  5.18289220e-04 -7.66348530e-05 -5.61056775e-04\n",
            "  2.11288570e-03  1.20306201e-03  1.37995798e-04  7.44218880e-04\n",
            "  6.21078652e-04  2.57000350e-03  2.15380220e-03  1.53649191e-03\n",
            " -5.03137708e-04 -5.04195632e-04  1.45434562e-04  1.80694833e-03\n",
            "  3.40078317e-04 -9.81442863e-04 -7.77254521e-04 -1.38233358e-04\n",
            " -6.73915958e-04 -6.80455332e-06 -7.82594958e-04  1.34958001e-03\n",
            " -1.20654621e-03  4.79545008e-04  1.65466184e-03 -2.04305412e-04]\n",
            "GloVe: [-0.24156722  0.19728762  0.28115077 -0.01267708 -0.15987858  0.21574398\n",
            " -0.1480353  -0.17230529  0.18451083  0.30139633 -0.01786616 -0.10788706\n",
            " -0.02538971 -0.17632268  0.17546725  0.23223604 -0.04676747 -0.32730955\n",
            " -0.17357518  0.28444662  0.22395164 -0.15287594  0.02411032  0.16742667\n",
            " -0.30741247 -0.08741171 -0.17499335 -0.23875255 -0.10647899 -0.43408586\n",
            "  0.03226503 -0.02690753 -0.03439709 -0.06679865 -0.41822772  0.00441864\n",
            " -0.33425292  0.33217133 -0.02931358 -0.3106526   0.13540257  0.08195526\n",
            " -0.28979497 -0.00119301 -0.14958068 -0.11357246 -0.33342334  0.1647589\n",
            "  0.00192798  0.12798077  0.35912439  0.47988574  0.29816269  0.02062277\n",
            "  0.341725   -0.09348523  0.00970518  0.09629346 -0.13512328  0.03271592\n",
            " -0.22528884  0.12753717 -0.00965846  0.05195969 -0.09110937 -0.03771555\n",
            "  0.11739977 -0.04516209 -0.02465634 -0.05721831 -0.11449855 -0.16619301\n",
            "  0.05787712  0.03165011 -0.10521808 -0.23580368 -0.32708301  0.56562534\n",
            "  0.05927055  0.00094551  0.31607433 -0.35772211 -0.27208042 -0.19823527\n",
            "  0.04679147  0.07974814  0.15175472 -0.03920601  0.17394178  0.27804593\n",
            " -0.00697557 -0.43042942  0.23622731 -0.13813303 -0.2330843  -0.25773563\n",
            "  0.29068773 -0.32492003  0.02964249 -0.24167678  0.12750401 -0.00378335\n",
            " -0.28357644  0.20254182 -0.03352816  0.08491384  0.15584422  0.15268531\n",
            " -0.26024194  0.17879857 -0.18562622 -0.24850885 -0.13399434  0.43196456\n",
            "  0.26941041  0.27321471  0.08527431  0.17110002  0.12516943 -0.36612575\n",
            " -0.07978609 -0.01374283  0.14129145  0.29812763  0.42890394  0.25290197\n",
            " -0.28166244  0.03103951]\n",
            "Mittens: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)\n",
        "\n",
        "from scipy.sparse import csr_matrix  # Add sparse matrix support\n",
        "\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "    def word2MittensEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2mittens = np.empty(shape=(self.no_words, no_components))\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        # Convert to sparse matrix\n",
        "        cooc_matrix_sparse = csr_matrix(cooc_matrix)\n",
        "        model = Mittens(n=no_components, max_iter=epochs, mittens=learning_rate)\n",
        "        try:\n",
        "            embeddings = model.fit(cooc_matrix_sparse, vocab=vocab)\n",
        "            self.word2mittens[0] = np.zeros(no_components)\n",
        "            for word, idx in self.word2id.items():\n",
        "                self.word2mittens[idx] = embeddings[idx - 1]\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Mittens.fit: {e}\")\n",
        "            embeddings = np.zeros((len(vocab), no_components))  # Fallback\n",
        "            self.word2mittens[0] = np.zeros(no_components)\n",
        "            for i, word in enumerate(vocab, 1):\n",
        "                self.word2mittens[i] = embeddings[i - 1]\n",
        "        return self.word2mittens\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    w2m = we.word2MittensEmbedding()\n",
        "    print(\"Mittens:\", w2m.shape)\n",
        "    print(w2m)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])\n",
        "    print(\"Mittens:\", w2m[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHvZNe7qyhTU",
        "outputId": "9a141780-d10a-4947-c293-d2fb5d271c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version: 0.2\n",
            "(3, 15)\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14]]\n",
            "Word2Vec: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.21626532e-05  3.19088437e-03 -7.12745590e-03 ...  9.92520479e-04\n",
            "   7.14840600e-03  2.83964048e-03]\n",
            " [-3.82514030e-04  1.51936125e-04  3.97204095e-03 ...  2.31946167e-03\n",
            "  -3.84517061e-03  3.48054501e-03]\n",
            " ...\n",
            " [-1.44330040e-03 -3.37802432e-03 -5.04739862e-03 ...  4.78180777e-03\n",
            "   3.40414606e-03  2.03621481e-03]\n",
            " [ 5.68562094e-03 -4.50939965e-03  6.46589976e-03 ...  4.88198549e-03\n",
            "  -7.37946481e-03  7.49228429e-03]\n",
            " [-1.35904271e-03  5.24326880e-03  7.78503902e-03 ... -6.09789602e-03\n",
            "  -7.12639559e-03 -4.63685114e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.0001"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04 ...  4.79545008e-04\n",
            "   1.65466184e-03 -2.04305412e-04]\n",
            " [-1.36351539e-03  1.12285069e-03 -1.62398699e-03 ...  1.27794396e-03\n",
            "  -4.78518370e-04  1.83548301e-03]\n",
            " ...\n",
            " [-2.22318270e-03  2.95931986e-05 -4.96662979e-04 ...  1.28600537e-03\n",
            "   9.15645447e-04 -2.91286968e-04]\n",
            " [-3.23804357e-04  9.54689051e-04 -1.18813978e-03 ...  6.51234936e-04\n",
            "   2.29042576e-04  1.05157425e-03]\n",
            " [-4.99513757e-04  2.49632495e-03  2.18920293e-03 ...  4.68000828e-04\n",
            "  -1.34677067e-03 -1.70546729e-04]]\n",
            "GloVe: (15, 128)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.24973279 -0.47211752 -0.3471582  ... -0.01941465  0.43606771\n",
            "  -0.0892403 ]\n",
            " [-0.2158313  -0.12271662 -0.21352648 ... -0.07537541  0.31608701\n",
            "   0.02839591]\n",
            " ...\n",
            " [ 0.16518111  0.128661   -0.0561627  ... -0.03275083  0.00815867\n",
            "  -0.02345717]\n",
            " [-0.09888651 -0.27747496  0.19922241 ... -0.0432742   0.0807169\n",
            "   0.25686838]\n",
            " [ 0.07700253 -0.14335636  0.38736752 ...  0.15984586  0.09920613\n",
            "   0.03748307]]\n",
            "Error in Mittens.fit: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().\n",
            "Mittens: (15, 128)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "\n",
            "Comparison for word ID 1:\n",
            "Word2Vec: [-6.21626532e-05  3.19088437e-03 -7.12745590e-03  6.01633405e-03\n",
            "  4.82634921e-03  3.97735788e-03  5.58952475e-03  6.64290274e-03\n",
            "  6.49750407e-04 -1.30172889e-03  4.28103493e-04 -7.31625035e-03\n",
            "  6.59953337e-03 -5.00487117e-03  6.55153207e-03 -3.32944584e-03\n",
            "  5.09716512e-04 -7.12373713e-03 -7.48809706e-03 -6.06476609e-03\n",
            " -6.01806538e-03  2.62050075e-04 -5.66331577e-03 -3.86920548e-03\n",
            " -4.16113203e-03 -3.37171252e-03  5.41871926e-03  3.72564164e-03\n",
            "  6.80003501e-03  5.55603579e-03 -4.45879949e-03  5.70788607e-03\n",
            " -7.26995803e-03 -2.01427122e-03 -6.02612738e-03  3.31634958e-03\n",
            "  1.43352617e-03  5.52080385e-03  2.32943310e-03 -5.44838468e-03\n",
            "  5.98756177e-03 -4.64449916e-03  7.02972896e-03  2.28456082e-03\n",
            " -3.11649730e-03 -3.70101258e-03 -3.46256793e-03 -4.79195034e-03\n",
            "  7.32414331e-03 -2.00591167e-03  6.06871955e-03 -7.54190609e-03\n",
            "  1.68094877e-03 -9.79775796e-04  5.90900565e-03 -7.03375321e-03\n",
            "  5.83272101e-03 -3.95497913e-03 -4.70296340e-03 -4.40138392e-03\n",
            " -2.66821543e-03 -2.65624467e-03 -2.50413013e-03 -5.86187281e-03\n",
            "  6.00978325e-04 -4.53708722e-04 -1.28188857e-03  2.92269792e-03\n",
            " -5.91868116e-03 -2.48495163e-03  4.01353044e-03  6.70103775e-03\n",
            " -7.66575430e-03  5.61965723e-03  4.15526563e-03 -3.09771299e-03\n",
            "  6.73769321e-03 -7.15261744e-03  5.66246081e-03  4.26008087e-03\n",
            "  9.85841965e-04 -4.10628133e-03 -3.25019588e-03 -2.61222548e-03\n",
            "  1.28108205e-03  1.24865468e-03  5.82506089e-03  7.80742289e-03\n",
            "  6.93350285e-03 -3.08938394e-03  7.56247900e-03 -5.23670344e-04\n",
            "  3.73711600e-03  1.97167136e-03 -4.63132892e-04  2.85691721e-03\n",
            " -4.20561666e-03 -4.55231313e-03 -5.94439125e-03  1.47928542e-03\n",
            "  5.05184289e-03  6.73822535e-04  9.28732043e-04  2.46044085e-03\n",
            "  6.36986131e-03 -6.00371370e-03  1.73082878e-03 -5.86407073e-03\n",
            "  2.87816045e-03  7.43294507e-03  5.87216392e-03  5.02722338e-03\n",
            "  6.27435837e-03  5.13774622e-03  5.31336619e-03  6.73875213e-03\n",
            " -3.89733445e-03  7.20354123e-03  3.95858521e-03 -1.59854104e-03\n",
            "  6.62540551e-03  3.92472045e-03  7.54022226e-03  2.18087039e-03\n",
            "  7.74372742e-03  9.92520479e-04  7.14840600e-03  2.83964048e-03]\n",
            "FastText: [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04  1.07396161e-03\n",
            "  7.47827522e-04  2.43436918e-03  1.25494599e-03  8.32708203e-04\n",
            "  1.39498618e-04 -1.04375544e-03  1.66534202e-03  5.92023076e-04\n",
            " -1.01467571e-03  4.17726085e-04  1.15030364e-03 -8.53901089e-04\n",
            "  3.93663533e-04  1.66030577e-03  8.04261887e-04 -1.37844379e-03\n",
            " -1.00217399e-03 -1.71076367e-03 -6.08318776e-04 -3.13780096e-04\n",
            "  7.09959713e-04  6.52309740e-04 -1.03251881e-03  6.82479527e-04\n",
            "  1.76711939e-04 -1.86265504e-03  6.39586418e-04  1.27322774e-03\n",
            " -2.63598538e-03  1.30318059e-03  1.28268311e-03  7.31006585e-05\n",
            " -8.57610779e-04 -1.77271932e-03  4.76834684e-05  7.52914173e-04\n",
            "  6.25460816e-04 -3.61822196e-04 -2.49825674e-03  6.06271380e-04\n",
            "  2.61506008e-04 -1.91198278e-03 -7.39933399e-04 -4.00340045e-03\n",
            "  3.98896955e-04 -6.40470942e-04 -9.73124232e-04 -4.94266103e-04\n",
            "  9.33958218e-04  3.16818740e-04 -1.39790284e-03  8.03306350e-04\n",
            "  4.68277285e-04 -7.05544895e-04  8.22283386e-04 -1.07828462e-04\n",
            "  3.76482669e-04  2.11784281e-04 -4.11284942e-04  9.16630845e-04\n",
            " -3.64862324e-04 -6.43940584e-04 -1.22504728e-03 -4.09014639e-04\n",
            "  2.33947922e-05 -4.68008395e-04 -1.46471866e-04  1.28898071e-03\n",
            " -1.87438796e-03 -1.11290443e-04 -2.82968773e-04  1.62297476e-03\n",
            " -3.61244201e-05 -1.74025889e-03  2.76980782e-03 -8.65978887e-04\n",
            "  1.14296249e-03 -1.82072268e-04 -1.75701268e-03  7.34397385e-04\n",
            " -1.71435822e-03  3.74486670e-04 -2.81040557e-05 -2.88294628e-04\n",
            "  2.09705951e-03 -7.59013637e-04  1.51762320e-03 -4.17047850e-04\n",
            "  4.31056396e-04 -4.13735892e-04 -1.18768564e-03 -2.78128078e-03\n",
            " -3.55213997e-04 -2.31009349e-03  5.31876693e-04  1.93082809e-03\n",
            "  2.91791657e-04  5.18289220e-04 -7.66348530e-05 -5.61056775e-04\n",
            "  2.11288570e-03  1.20306201e-03  1.37995798e-04  7.44218880e-04\n",
            "  6.21078652e-04  2.57000350e-03  2.15380220e-03  1.53649191e-03\n",
            " -5.03137708e-04 -5.04195632e-04  1.45434562e-04  1.80694833e-03\n",
            "  3.40078317e-04 -9.81442863e-04 -7.77254521e-04 -1.38233358e-04\n",
            " -6.73915958e-04 -6.80455332e-06 -7.82594958e-04  1.34958001e-03\n",
            " -1.20654621e-03  4.79545008e-04  1.65466184e-03 -2.04305412e-04]\n",
            "GloVe: [-0.24973279 -0.47211752 -0.3471582   0.09206807 -0.13866986  0.15487264\n",
            "  0.10668666 -0.1446956  -0.37882732 -0.31554635 -0.12138892  0.0336272\n",
            " -0.00930984  0.03009921 -0.13521719 -0.08467253 -0.19571198 -0.13949303\n",
            " -0.35111745  0.027482    0.11905168  0.18794745  0.11306527  0.12954\n",
            "  0.05691607  0.13720159  0.22953001  0.10246665  0.20592919 -0.21759341\n",
            " -0.23108193  0.21138186 -0.26241941  0.04116371 -0.21286277 -0.11801152\n",
            "  0.31120586 -0.29845012 -0.05790725 -0.18902083  0.22907882 -0.12611849\n",
            "  0.40500281 -0.22766443  0.04437517 -0.03016994 -0.00181209  0.24601004\n",
            " -0.1288323   0.14103511  0.25497694 -0.09054451  0.16266434  0.11801647\n",
            " -0.16773795 -0.12649524  0.21566807  0.01240493  0.01311322  0.2398281\n",
            "  0.24605117 -0.48681179  0.17264584  0.11088587 -0.30783911  0.25423832\n",
            "  0.05147336 -0.12579411  0.15714605 -0.10685451  0.31093266 -0.17077477\n",
            " -0.03805187 -0.31860494 -0.23026643 -0.17669139  0.26581533 -0.40427327\n",
            "  0.03385626  0.34479212 -0.06676299  0.09452871 -0.0890423  -0.02015828\n",
            " -0.25413745 -0.20022885  0.31813517 -0.0295259  -0.39070183 -0.29587508\n",
            " -0.04877057  0.56845457 -0.27300501  0.20099248  0.56908743  0.04327456\n",
            " -0.28636521  0.52484852  0.06302865 -0.00368409  0.30760488 -0.1834542\n",
            "  0.0405381  -0.01405919 -0.37281245  0.10027112  0.00985007 -0.19940571\n",
            " -0.19570702  0.02242911 -0.33625058 -0.22106823  0.44265247 -0.15831874\n",
            " -0.50237319  0.218131    0.34700928 -0.14113709  0.17201621  0.20608975\n",
            " -0.35104507 -0.23447789 -0.19862362  0.01224652 -0.30237286 -0.01941465\n",
            "  0.43606771 -0.0892403 ]\n",
            "Mittens: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### slimmed-down version without Mittens\n",
        "\n"
      ],
      "metadata": {
        "id": "UlYgCEY3y8LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import GloVe\n",
        "import mittens\n",
        "print(\"Mittens version (GloVe only):\", mittens.__version__)\n",
        "\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fuNa6-WuR4a",
        "outputId": "96a23ddc-0209-42e2-8fd2-ec5579559d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version (GloVe only): 0.2\n",
            "(3, 15)\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14]]\n",
            "Word2Vec: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.21626532e-05  3.19088437e-03 -7.12745590e-03 ...  9.92520479e-04\n",
            "   7.14840600e-03  2.83964048e-03]\n",
            " [-3.82514030e-04  1.51936125e-04  3.97204095e-03 ...  2.31946167e-03\n",
            "  -3.84517061e-03  3.48054501e-03]\n",
            " ...\n",
            " [-1.44330040e-03 -3.37802432e-03 -5.04739862e-03 ...  4.78180777e-03\n",
            "   3.40414606e-03  2.03621481e-03]\n",
            " [ 5.68562094e-03 -4.50939965e-03  6.46589976e-03 ...  4.88198549e-03\n",
            "  -7.37946481e-03  7.49228429e-03]\n",
            " [-1.35904271e-03  5.24326880e-03  7.78503902e-03 ... -6.09789602e-03\n",
            "  -7.12639559e-03 -4.63685114e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04 ...  4.79545008e-04\n",
            "   1.65466184e-03 -2.04305412e-04]\n",
            " [-1.36351539e-03  1.12285069e-03 -1.62398699e-03 ...  1.27794396e-03\n",
            "  -4.78518370e-04  1.83548301e-03]\n",
            " ...\n",
            " [-2.22318270e-03  2.95931986e-05 -4.96662979e-04 ...  1.28600537e-03\n",
            "   9.15645447e-04 -2.91286968e-04]\n",
            " [-3.23804357e-04  9.54689051e-04 -1.18813978e-03 ...  6.51234936e-04\n",
            "   2.29042576e-04  1.05157425e-03]\n",
            " [-4.99513757e-04  2.49632495e-03  2.18920293e-03 ...  4.68000828e-04\n",
            "  -1.34677067e-03 -1.70546729e-04]]\n",
            "GloVe: (15, 128)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.14491981 -0.09447325  0.12144629 ... -0.2624261  -0.18998113\n",
            "  -0.09980709]\n",
            " [ 0.32938427 -0.05994402  0.05077884 ...  0.01185149  0.20612515\n",
            "   0.28760553]\n",
            " ...\n",
            " [-0.01241104 -0.08506157  0.29257517 ... -0.17227083 -0.19028408\n",
            "  -0.19335479]\n",
            " [ 0.37489702 -0.22289123  0.05223132 ... -0.01077101 -0.10361216\n",
            "   0.00802199]\n",
            " [ 0.04938111  0.12498871  0.37583299 ...  0.16933881  0.26277163\n",
            "  -0.23265269]]\n",
            "\n",
            "\n",
            "Comparison for word ID 1:\n",
            "Word2Vec: [-6.21626532e-05  3.19088437e-03 -7.12745590e-03  6.01633405e-03\n",
            "  4.82634921e-03  3.97735788e-03  5.58952475e-03  6.64290274e-03\n",
            "  6.49750407e-04 -1.30172889e-03  4.28103493e-04 -7.31625035e-03\n",
            "  6.59953337e-03 -5.00487117e-03  6.55153207e-03 -3.32944584e-03\n",
            "  5.09716512e-04 -7.12373713e-03 -7.48809706e-03 -6.06476609e-03\n",
            " -6.01806538e-03  2.62050075e-04 -5.66331577e-03 -3.86920548e-03\n",
            " -4.16113203e-03 -3.37171252e-03  5.41871926e-03  3.72564164e-03\n",
            "  6.80003501e-03  5.55603579e-03 -4.45879949e-03  5.70788607e-03\n",
            " -7.26995803e-03 -2.01427122e-03 -6.02612738e-03  3.31634958e-03\n",
            "  1.43352617e-03  5.52080385e-03  2.32943310e-03 -5.44838468e-03\n",
            "  5.98756177e-03 -4.64449916e-03  7.02972896e-03  2.28456082e-03\n",
            " -3.11649730e-03 -3.70101258e-03 -3.46256793e-03 -4.79195034e-03\n",
            "  7.32414331e-03 -2.00591167e-03  6.06871955e-03 -7.54190609e-03\n",
            "  1.68094877e-03 -9.79775796e-04  5.90900565e-03 -7.03375321e-03\n",
            "  5.83272101e-03 -3.95497913e-03 -4.70296340e-03 -4.40138392e-03\n",
            " -2.66821543e-03 -2.65624467e-03 -2.50413013e-03 -5.86187281e-03\n",
            "  6.00978325e-04 -4.53708722e-04 -1.28188857e-03  2.92269792e-03\n",
            " -5.91868116e-03 -2.48495163e-03  4.01353044e-03  6.70103775e-03\n",
            " -7.66575430e-03  5.61965723e-03  4.15526563e-03 -3.09771299e-03\n",
            "  6.73769321e-03 -7.15261744e-03  5.66246081e-03  4.26008087e-03\n",
            "  9.85841965e-04 -4.10628133e-03 -3.25019588e-03 -2.61222548e-03\n",
            "  1.28108205e-03  1.24865468e-03  5.82506089e-03  7.80742289e-03\n",
            "  6.93350285e-03 -3.08938394e-03  7.56247900e-03 -5.23670344e-04\n",
            "  3.73711600e-03  1.97167136e-03 -4.63132892e-04  2.85691721e-03\n",
            " -4.20561666e-03 -4.55231313e-03 -5.94439125e-03  1.47928542e-03\n",
            "  5.05184289e-03  6.73822535e-04  9.28732043e-04  2.46044085e-03\n",
            "  6.36986131e-03 -6.00371370e-03  1.73082878e-03 -5.86407073e-03\n",
            "  2.87816045e-03  7.43294507e-03  5.87216392e-03  5.02722338e-03\n",
            "  6.27435837e-03  5.13774622e-03  5.31336619e-03  6.73875213e-03\n",
            " -3.89733445e-03  7.20354123e-03  3.95858521e-03 -1.59854104e-03\n",
            "  6.62540551e-03  3.92472045e-03  7.54022226e-03  2.18087039e-03\n",
            "  7.74372742e-03  9.92520479e-04  7.14840600e-03  2.83964048e-03]\n",
            "FastText: [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04  1.07396161e-03\n",
            "  7.47827522e-04  2.43436918e-03  1.25494599e-03  8.32708203e-04\n",
            "  1.39498618e-04 -1.04375544e-03  1.66534202e-03  5.92023076e-04\n",
            " -1.01467571e-03  4.17726085e-04  1.15030364e-03 -8.53901089e-04\n",
            "  3.93663533e-04  1.66030577e-03  8.04261887e-04 -1.37844379e-03\n",
            " -1.00217399e-03 -1.71076367e-03 -6.08318776e-04 -3.13780096e-04\n",
            "  7.09959713e-04  6.52309740e-04 -1.03251881e-03  6.82479527e-04\n",
            "  1.76711939e-04 -1.86265504e-03  6.39586418e-04  1.27322774e-03\n",
            " -2.63598538e-03  1.30318059e-03  1.28268311e-03  7.31006585e-05\n",
            " -8.57610779e-04 -1.77271932e-03  4.76834684e-05  7.52914173e-04\n",
            "  6.25460816e-04 -3.61822196e-04 -2.49825674e-03  6.06271380e-04\n",
            "  2.61506008e-04 -1.91198278e-03 -7.39933399e-04 -4.00340045e-03\n",
            "  3.98896955e-04 -6.40470942e-04 -9.73124232e-04 -4.94266103e-04\n",
            "  9.33958218e-04  3.16818740e-04 -1.39790284e-03  8.03306350e-04\n",
            "  4.68277285e-04 -7.05544895e-04  8.22283386e-04 -1.07828462e-04\n",
            "  3.76482669e-04  2.11784281e-04 -4.11284942e-04  9.16630845e-04\n",
            " -3.64862324e-04 -6.43940584e-04 -1.22504728e-03 -4.09014639e-04\n",
            "  2.33947922e-05 -4.68008395e-04 -1.46471866e-04  1.28898071e-03\n",
            " -1.87438796e-03 -1.11290443e-04 -2.82968773e-04  1.62297476e-03\n",
            " -3.61244201e-05 -1.74025889e-03  2.76980782e-03 -8.65978887e-04\n",
            "  1.14296249e-03 -1.82072268e-04 -1.75701268e-03  7.34397385e-04\n",
            " -1.71435822e-03  3.74486670e-04 -2.81040557e-05 -2.88294628e-04\n",
            "  2.09705951e-03 -7.59013637e-04  1.51762320e-03 -4.17047850e-04\n",
            "  4.31056396e-04 -4.13735892e-04 -1.18768564e-03 -2.78128078e-03\n",
            " -3.55213997e-04 -2.31009349e-03  5.31876693e-04  1.93082809e-03\n",
            "  2.91791657e-04  5.18289220e-04 -7.66348530e-05 -5.61056775e-04\n",
            "  2.11288570e-03  1.20306201e-03  1.37995798e-04  7.44218880e-04\n",
            "  6.21078652e-04  2.57000350e-03  2.15380220e-03  1.53649191e-03\n",
            " -5.03137708e-04 -5.04195632e-04  1.45434562e-04  1.80694833e-03\n",
            "  3.40078317e-04 -9.81442863e-04 -7.77254521e-04 -1.38233358e-04\n",
            " -6.73915958e-04 -6.80455332e-06 -7.82594958e-04  1.34958001e-03\n",
            " -1.20654621e-03  4.79545008e-04  1.65466184e-03 -2.04305412e-04]\n",
            "GloVe: [-0.14491981 -0.09447325  0.12144629  0.33654058 -0.26823103 -0.00851899\n",
            " -0.01720095  0.00417736  0.07016572  0.15440059 -0.05897453 -0.03388286\n",
            "  0.00166583  0.02728988 -0.02364711  0.20430687 -0.27785534  0.17192418\n",
            " -0.4214381  -0.31993437  0.37089122  0.31378692 -0.16434697  0.06254594\n",
            " -0.37126779  0.02074445  0.02755287 -0.03419243 -0.04800101  0.23402676\n",
            " -0.03905685  0.11388236 -0.09545866 -0.06881654  0.46783014 -0.1684731\n",
            " -0.30359971 -0.18722352 -0.31340323 -0.04368029 -0.0997356   0.20585347\n",
            " -0.12803517 -0.03103505 -0.22988654 -0.20921109  0.13892224 -0.25125431\n",
            " -0.34561802 -0.02544955 -0.11478891  0.2110641  -0.10692891  0.14797026\n",
            "  0.21640493  0.0203965   0.02068296 -0.02507762 -0.06478238 -0.21582785\n",
            " -0.18612787  0.33198676 -0.23596947 -0.1166765   0.08838274 -0.11613951\n",
            "  0.17417221  0.04276799 -0.29862126  0.33014894  0.04703465 -0.2152572\n",
            " -0.17628108  0.08623899 -0.0541081  -0.12096651 -0.07759373  0.12235248\n",
            "  0.01088267 -0.03379119  0.01154564 -0.0255124  -0.11684421 -0.08885345\n",
            "  0.17115128  0.17162357  0.25984815 -0.23705988 -0.06767285  0.23263982\n",
            "  0.17997825 -0.36049717 -0.27579434 -0.04070212  0.20846426 -0.25062646\n",
            " -0.22516775 -0.03231266  0.21774265  0.23756354  0.01277131  0.23864298\n",
            " -0.20071755  0.1087316  -0.3951387   0.05903905 -0.21734861  0.11410184\n",
            "  0.02475853  0.34337829 -0.08874847  0.25982878 -0.00071343  0.04635114\n",
            " -0.17474179 -0.08504665 -0.14526755  0.01800153 -0.04054321 -0.16867252\n",
            "  0.0332301   0.03932167 -0.35854248  0.15627902  0.40057809 -0.2624261\n",
            " -0.18998113 -0.09980709]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenization"
      ],
      "metadata": {
        "id": "Vomn4xUHzZEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages and download NLTK data\n",
        "!pip install numpy==1.26.4 gensim==4.3.3 mittens==0.2 spacy==3.7.2 stop-words==2018.7.23 -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe\n",
        "import os\n",
        "\n",
        "# Special characters dictionary\n",
        "specialchar_dic = {\n",
        "    \"’\": \"'\", \"„\": \"\\\"\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"«\": \"<<\", \"»\": \">>\",\n",
        "    \"…\": \"...\", \"—\": \"--\", \"¡\": \"!\", \"¿\": \"?\", \"©\": \" \", \"–\": \" \"\n",
        "}\n",
        "\n",
        "# Stop words function (cached globally)\n",
        "def stopWordsEN():\n",
        "    sw_stop_words = get_stop_words('en')\n",
        "    sw_nltk = stopwords.words('english')\n",
        "    sw_spacy = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
        "    sw_mallet = ['a', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', 'came', 'can', 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', 'course', 'currently', 'd', 'definitely', 'described', 'despite', 'did', 'different', 'do', 'does', 'doing', 'done', 'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'f', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'h', 'had', 'happens', 'hardly', 'has', 'have', 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'i', 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'p', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 't', 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants', 'was', 'way', 'we', 'welcome', 'well', 'went', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', 'wonder', 'would', 'x', 'y', 'yes', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', 'z', 'zero']\n",
        "    return list(set(sw_stop_words + sw_nltk + sw_mallet + sw_spacy))\n",
        "\n",
        "# Precompile regex and load Spacy model\n",
        "punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "specialchar_re = re.compile('(%s)' % '|'.join(specialchar_dic.keys()))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "cachedStopWords_en = stopWordsEN()\n",
        "\n",
        "class Tokenization:\n",
        "    def applyFE(self, text):\n",
        "        \"\"\"Combine negation with words to reduce bias.\"\"\"\n",
        "        final_text = text.replace('cannot', 'can not').replace('can\\'t', 'can not')\n",
        "        final_text = final_text.replace('won\\'t', 'will not').replace('n\\'t', ' not').replace(' not ', ' not')\n",
        "        return final_text\n",
        "\n",
        "    def removeStopWords(self, text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords_en])\n",
        "\n",
        "    def removePunctuation(self, text, punctuation=punctuation):\n",
        "        for c in punctuation:\n",
        "            text = text.replace(c, ' ')\n",
        "        return text\n",
        "\n",
        "    def replaceUTF8Char(self, text, specialchars=specialchar_dic):\n",
        "        def replace(match):\n",
        "            return specialchars[match.group(0)]\n",
        "        return specialchar_re.sub(replace, text)\n",
        "\n",
        "    def createCorpus(self, text, remove_punctuation=True, remove_stopwords=True, apply_FE=True):\n",
        "        corpus = []\n",
        "        try:\n",
        "            text = self.replaceUTF8Char(text).replace(\"\\n\", \" \")\n",
        "            doc = nlp(text)\n",
        "            processed_text = ' '.join([t.lemma_ if t.lemma_ != '-PRON-' else t.text if not t.ent_type_ else t.text for t in doc])\n",
        "            processed_text = processed_text.replace(\"\\s\\s+\", ' ')\n",
        "\n",
        "            doc = nlp(processed_text.lower())\n",
        "            rawText = not (remove_punctuation or remove_stopwords or apply_FE)\n",
        "\n",
        "            for sentence in doc.sents:\n",
        "                sent = str(sentence.text)\n",
        "                if len(sent) == 0:\n",
        "                    continue\n",
        "                if not rawText:\n",
        "                    if apply_FE:\n",
        "                        sent = self.applyFE(text=sent)\n",
        "                    if remove_punctuation:\n",
        "                        sent = self.removePunctuation(text=sent)\n",
        "                    if remove_stopwords:\n",
        "                        sent = self.removeStopWords(text=sent)\n",
        "                sent = sent.lower().split()\n",
        "                if sent:\n",
        "                    corpus.append(sent)\n",
        "        except Exception as exp:\n",
        "            print('exception=', str(exp))\n",
        "            print('text=', text)\n",
        "        return corpus\n",
        "\n",
        "    def __del__(self):\n",
        "        print(\"Destructor Tokenization\")\n",
        "\n",
        "class WordEmbeddings:\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Tokenization example\n",
        "    tkn = Tokenization()\n",
        "    text1 = \"Apple data-intensive is looking at buying U.K. startup for $1 billion. This is great! The new D.P. model is funcitonal and ready\"\n",
        "    corpus1 = tkn.createCorpus(text1)\n",
        "    print(\"Corpus 1:\", corpus1)\n",
        "\n",
        "    # Larger text example\n",
        "    text2 = \"\"\"The lion may be known as the king of the jungle, but lions do not live in jungles. They’re the rulers of the African savannahs that are covered in brown grasses and speckled with sparse trees. Lions’ coloring helps them blend in perfectly with the tall grass so they can ambush their prey as best as possible. And lions are ferocious. Although they’re one of the most powerful predators on land, lions are in danger. Hunters and poachers target lions to prove to the world their machismo.\\n\\nAnd while hunters seek to wipe lions off the face of the earth to bolster their egos, the Kevin Richardson Wildlife Sanctuary hopes to stop them and protect the big African cat at all cost.\\n\\nRichardson has earned the nickname the “Lion Whisperer” for a reason. He aims to educate the world about lions. And for those lucky enough to volunteer alongside Richardson, he encourages them to learn more about lions and help protect the wild species.\\n\\n“To raise awareness, Kevin has now set up his YouTube Channel ‘LionWhispererTV’. The channel is all about raising awareness about not only the declining numbers of lions but also how this rapid decrease is happening. By watching these videos, you are directly contributing to our scheme of land acquisition,” he writes in his bio.\\n\\nAs part of the volunteer program, Richardson hosts a “volunteer enrichment and lion enrichment” walk. As the name suggests, Richardson takes his group of volunteers out into the savannah of South Africa to hang out with two lions. There, the volunteers meet a male lion, Bobcat, and a female lioness, Gabby. Both lions look ferocious, but are truly “affectionate,” at least that’s what Richardson says. And remember, he’s the lion whisperer, so he’s got an advantage with these deadly big cats.\\n\\nAs Richardson showers the pair of lions with love, the volunteers stay locked in the truck, unwilling to put their lives in danger. And while they are in the vehicle, the lions are just feet from them – and if something goes wrong, they could wind up injured anyway.\\n\\nRichardson shared the video on his “The Lion Whisperer” YouTube channel. With more than one million hits, this video has proven to be one of his most famous.\\n\\nThe video describes the moment caught on tape as follows:\\n\\n“It’s an enrichment walk for both the volunteers and the lions as Kevin shows off his lovely lions as well as giving some amazing lion facts to the volunteers.”\\n\\nViewers like you are overwhelmed with the magnificent footage. The following are a few comments shared on the video.\\n\\n“I hope to someday volunteer there with Kevin. I believe in the work and his perspective about conservation. This video makes me want to all the more! Bobcat and Gabby are lovely lions.” “Every time I watch a one of your videos I somehow end up smiling from ear to ear!” “That was so beautiful, wish I could rub my head against a lion.”\\n\\nTake a moment to watch this video. Would you ever want to volunteer with Kevin Richardson and his lions?\"\"\"\n",
        "    corpus2 = tkn.createCorpus(text2, remove_stopwords=False)\n",
        "    print(\"Corpus 2:\", corpus2)\n",
        "\n",
        "    # Generate embeddings from Corpus 2\n",
        "    we = WordEmbeddings(corpus2)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(\"\\nDocuments shape:\", np.array(docs, dtype=object).shape)\n",
        "    print(\"Documents:\", docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec shape:\", w2v.shape)\n",
        "    print(\"Word2Vec embeddings:\", w2v[:5])  # Print first 5 for brevity\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText shape:\", w2f.shape)\n",
        "    print(\"FastText embeddings:\", w2f[:5])\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe shape:\", w2g.shape)\n",
        "    print(\"GloVe embeddings:\", w2g[:5])\n",
        "\n",
        "    print(\"\\nComparison for word 'lion' (ID varies):\")\n",
        "    lion_id = we.word2id.get('lion', -1)\n",
        "    if lion_id != -1:\n",
        "        print(\"Word2Vec:\", w2v[lion_id])\n",
        "        print(\"FastText:\", w2f[lion_id])\n",
        "        print(\"GloVe:\", w2g[lion_id])\n",
        "    else:\n",
        "        print(\"'lion' not found in vocabulary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAIG9UunzNiF",
        "outputId": "71cf2f66-15e8-4815-bf95-cdb320b2998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus 1: [['apple', 'data', 'intensive', 'buy', 'startup', '1', 'billion'], ['great'], ['model', 'funcitonal', 'ready']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus 2: [['the', 'lion', 'may', 'be', 'know', 'as', 'the', 'king', 'of', 'the', 'jungle', 'but', 'lion', 'do', 'notlive', 'in', 'jungle'], ['they', 'be', 'the', 'ruler', 'of', 'the', 'african', 'savannah', 'that', 'be', 'cover', 'in', 'brown', 'grass', 'and', 'speckle', 'with', 'sparse', 'tree'], ['lion', 'coloring', 'help', 'they', 'blend', 'in', 'perfectly', 'with', 'the', 'tall', 'grass', 'so', 'they', 'can', 'ambush', 'their', 'prey', 'as', 'well', 'as', 'possible'], ['and', 'lion', 'be', 'ferocious'], ['although', 'they', 'be', 'one', 'of', 'the', 'most', 'powerful', 'predator', 'on', 'land', 'lion', 'be', 'in', 'danger'], ['hunter', 'and', 'poacher', 'target', 'lion', 'to', 'prove', 'to', 'the', 'world', 'their', 'machismo'], ['and', 'while', 'hunter', 'seek', 'to', 'wipe', 'lion', 'off', 'the', 'face', 'of', 'the', 'earth', 'to', 'bolster', 'their', 'ego', 'the', 'kevin', 'richardson', 'wildlife', 'sanctuary', 'hope', 'to', 'stop', 'they', 'and', 'protect', 'the', 'big', 'african', 'cat', 'at', 'all', 'cost'], ['richardson', 'have', 'earn', 'the', 'nickname', 'the', 'lion', 'whisperer', 'for', 'a', 'reason'], ['he', 'aim', 'to', 'educate', 'the', 'world', 'about', 'lion'], ['and', 'for', 'those', 'lucky', 'enough', 'to', 'volunteer', 'alongside', 'richardson', 'he', 'encourage', 'they', 'to', 'learn', 'more', 'about', 'lion', 'and', 'help', 'protect', 'the', 'wild', 'specie'], ['to', 'raise', 'awareness', 'kevin', 'have', 'now', 'set', 'up', 'his', 'youtube', 'channel', 'lionwhisperertv'], ['the', 'channel', 'be', 'all', 'about', 'raise', 'awareness', 'about', 'notonly', 'the', 'decline', 'number', 'of', 'lion', 'but', 'also', 'how', 'this', 'rapid', 'decrease', 'be', 'happen'], ['by', 'watch', 'these', 'video', 'you', 'be', 'directly', 'contribute', 'to', 'our', 'scheme', 'of', 'land', 'acquisition', 'he', 'write', 'in', 'his', 'bio'], ['as', 'part', 'of', 'the', 'volunteer', 'program', 'richardson', 'host', 'a', 'volunteer', 'enrichment', 'and', 'lion', 'enrichment', 'walk'], ['as', 'the', 'name', 'suggest', 'richardson', 'take', 'his', 'group', 'of', 'volunteer', 'out', 'into', 'the', 'savannah', 'of', 'south', 'africa', 'to', 'hang', 'out', 'with', 'two', 'lion'], ['there', 'the', 'volunteer', 'meet', 'a', 'male', 'lion', 'bobcat', 'and', 'a', 'female', 'lioness', 'gabby'], ['both', 'lion', 'look', 'ferocious', 'but', 'be', 'truly', 'affectionate', 'at', 'least', 'that', 'be', 'what', 'richardson', 'say'], ['and', 'remember', 'he', 'be', 'the', 'lion', 'whisperer', 'so', 'he', 'be', 'get', 'an', 'advantage', 'with', 'these', 'deadly', 'big', 'cat'], ['as', 'richardson', 'shower', 'the', 'pair', 'of', 'lion', 'with', 'love', 'the', 'volunteer', 'stay', 'locked', 'in', 'the', 'truck', 'unwilling', 'to', 'put', 'their', 'life', 'in', 'danger'], ['and', 'while', 'they', 'be', 'in', 'the', 'vehicle', 'the', 'lion', 'be', 'just', 'foot', 'from', 'they', 'and', 'if', 'something', 'go', 'wrong', 'they', 'could', 'wind', 'up', 'injure', 'anyway'], ['richardson', 'share', 'the', 'video', 'on', 'his', 'the', 'lion', 'whisperer', 'youtube', 'channel'], ['with', 'more', 'than', 'one', 'million', 'hit', 'this', 'video', 'have', 'prove', 'to', 'be', 'one', 'of', 'his', 'most', 'famous'], ['the', 'video', 'describe', 'the', 'moment', 'catch', 'on', 'tape', 'as', 'follow', 'it', 'be', 'an', 'enrichment', 'walk', 'for', 'both', 'the', 'volunteer', 'and', 'the', 'lion', 'as', 'kevin', 'show', 'off', 'his', 'lovely', 'lion', 'as', 'well', 'as', 'give', 'some', 'amazing', 'lion', 'fact', 'to', 'the', 'volunteer'], ['viewer', 'like', 'you', 'be', 'overwhelmed', 'with', 'the', 'magnificent', 'footage'], ['the', 'follow', 'be', 'a', 'few', 'comment', 'share', 'on', 'the', 'video'], ['i', 'hope', 'to', 'someday', 'volunteer', 'there', 'with', 'kevin'], ['i', 'believe', 'in', 'the', 'work', 'and', 'his', 'perspective', 'about', 'conservation'], ['this', 'video', 'make', 'i', 'want', 'to', 'all', 'the', 'more'], ['bobcat', 'and', 'gabby', 'be', 'lovely', 'lion'], ['every', 'time', 'i', 'watch', 'a', 'one', 'of', 'your', 'video', 'i', 'somehow', 'end', 'up', 'smile', 'from', 'ear', 'to', 'ear'], ['that', 'be', 'so', 'beautiful', 'wish', 'i', 'could', 'rub', 'my', 'head', 'against', 'a', 'lion'], ['take', 'a', 'moment', 'to', 'watch', 'this', 'video'], ['would', 'you', 'ever', 'want', 'to', 'volunteer', 'with', 'kevin', 'richardson', 'and', 'his', 'lion']]\n",
            "\n",
            "Documents shape: (33,)\n",
            "Documents: [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 3, 12, 7, 6, 13, 9, 14, 1, 2, 3, 12, 5, 7, 15, 6, 16, 1, 2, 3, 17, 18, 7, 15, 4, 3, 11, 18, 1, 4, 5, 6, 7, 19, 6, 7, 6, 1, 4, 5, 20, 3, 5, 7, 17, 18, 7, 15, 4, 3], [1, 2, 3, 10, 11, 3, 1, 2, 3, 21, 18, 4, 3, 21, 6, 16, 1, 2, 3, 9, 16, 21, 5, 22, 9, 7, 14, 9, 20, 9, 7, 7, 9, 2, 1, 2, 9, 1, 11, 3, 22, 6, 20, 3, 21, 5, 7, 11, 21, 6, 13, 7, 15, 21, 9, 14, 14, 9, 7, 19, 14, 23, 3, 22, 12, 4, 3, 13, 5, 1, 2, 14, 23, 9, 21, 14, 3, 1, 21, 3, 3], [4, 5, 6, 7, 22, 6, 4, 6, 21, 5, 7, 15, 2, 3, 4, 23, 1, 2, 3, 10, 11, 4, 3, 7, 19, 5, 7, 23, 3, 21, 16, 3, 22, 1, 4, 10, 13, 5, 1, 2, 1, 2, 3, 1, 9, 4, 4, 15, 21, 9, 14, 14, 14, 6, 1, 2, 3, 10, 22, 9, 7, 9, 8, 11, 18, 14, 2, 1, 2, 3, 5, 21, 23, 21, 3, 10, 9, 14, 13, 3, 4, 4, 9, 14, 23, 6, 14, 14, 5, 11, 4, 3], [9, 7, 19, 4, 5, 6, 7, 11, 3, 16, 3, 21, 6, 22, 5, 6, 18, 14], [9, 4, 1, 2, 6, 18, 15, 2, 1, 2, 3, 10, 11, 3, 6, 7, 3, 6, 16, 1, 2, 3, 8, 6, 14, 1, 23, 6, 13, 3, 21, 16, 18, 4, 23, 21, 3, 19, 9, 1, 6, 21, 6, 7, 4, 9, 7, 19, 4, 5, 6, 7, 11, 3, 5, 7, 19, 9, 7, 15, 3, 21], [2, 18, 7, 1, 3, 21, 9, 7, 19, 23, 6, 9, 22, 2, 3, 21, 1, 9, 21, 15, 3, 1, 4, 5, 6, 7, 1, 6, 23, 21, 6, 20, 3, 1, 6, 1, 2, 3, 13, 6, 21, 4, 19, 1, 2, 3, 5, 21, 8, 9, 22, 2, 5, 14, 8, 6], [9, 7, 19, 13, 2, 5, 4, 3, 2, 18, 7, 1, 3, 21, 14, 3, 3, 12, 1, 6, 13, 5, 23, 3, 4, 5, 6, 7, 6, 16, 16, 1, 2, 3, 16, 9, 22, 3, 6, 16, 1, 2, 3, 3, 9, 21, 1, 2, 1, 6, 11, 6, 4, 14, 1, 3, 21, 1, 2, 3, 5, 21, 3, 15, 6, 1, 2, 3, 12, 3, 20, 5, 7, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 13, 5, 4, 19, 4, 5, 16, 3, 14, 9, 7, 22, 1, 18, 9, 21, 10, 2, 6, 23, 3, 1, 6, 14, 1, 6, 23, 1, 2, 3, 10, 9, 7, 19, 23, 21, 6, 1, 3, 22, 1, 1, 2, 3, 11, 5, 15, 9, 16, 21, 5, 22, 9, 7, 22, 9, 1, 9, 1, 9, 4, 4, 22, 6, 14, 1], [21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 9, 20, 3, 3, 9, 21, 7, 1, 2, 3, 7, 5, 22, 12, 7, 9, 8, 3, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 16, 6, 21, 9, 21, 3, 9, 14, 6, 7], [2, 3, 9, 5, 8, 1, 6, 3, 19, 18, 22, 9, 1, 3, 1, 2, 3, 13, 6, 21, 4, 19, 9, 11, 6, 18, 1, 4, 5, 6, 7], [9, 7, 19, 16, 6, 21, 1, 2, 6, 14, 3, 4, 18, 22, 12, 10, 3, 7, 6, 18, 15, 2, 1, 6, 20, 6, 4, 18, 7, 1, 3, 3, 21, 9, 4, 6, 7, 15, 14, 5, 19, 3, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 3, 3, 7, 22, 6, 18, 21, 9, 15, 3, 1, 2, 3, 10, 1, 6, 4, 3, 9, 21, 7, 8, 6, 21, 3, 9, 11, 6, 18, 1, 4, 5, 6, 7, 9, 7, 19, 2, 3, 4, 23, 23, 21, 6, 1, 3, 22, 1, 1, 2, 3, 13, 5, 4, 19, 14, 23, 3, 22, 5, 3], [1, 6, 21, 9, 5, 14, 3, 9, 13, 9, 21, 3, 7, 3, 14, 14, 12, 3, 20, 5, 7, 2, 9, 20, 3, 7, 6, 13, 14, 3, 1, 18, 23, 2, 5, 14, 10, 6, 18, 1, 18, 11, 3, 22, 2, 9, 7, 7, 3, 4, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 1, 20], [1, 2, 3, 22, 2, 9, 7, 7, 3, 4, 11, 3, 9, 4, 4, 9, 11, 6, 18, 1, 21, 9, 5, 14, 3, 9, 13, 9, 21, 3, 7, 3, 14, 14, 9, 11, 6, 18, 1, 7, 6, 1, 6, 7, 4, 10, 1, 2, 3, 19, 3, 22, 4, 5, 7, 3, 7, 18, 8, 11, 3, 21, 6, 16, 4, 5, 6, 7, 11, 18, 1, 9, 4, 14, 6, 2, 6, 13, 1, 2, 5, 14, 21, 9, 23, 5, 19, 19, 3, 22, 21, 3, 9, 14, 3, 11, 3, 2, 9, 23, 23, 3, 7], [11, 10, 13, 9, 1, 22, 2, 1, 2, 3, 14, 3, 20, 5, 19, 3, 6, 10, 6, 18, 11, 3, 19, 5, 21, 3, 22, 1, 4, 10, 22, 6, 7, 1, 21, 5, 11, 18, 1, 3, 1, 6, 6, 18, 21, 14, 22, 2, 3, 8, 3, 6, 16, 4, 9, 7, 19, 9, 22, 24, 18, 5, 14, 5, 1, 5, 6, 7, 2, 3, 13, 21, 5, 1, 3, 5, 7, 2, 5, 14, 11, 5, 6], [9, 14, 23, 9, 21, 1, 6, 16, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 23, 21, 6, 15, 21, 9, 8, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 2, 6, 14, 1, 9, 20, 6, 4, 18, 7, 1, 3, 3, 21, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 9, 7, 19, 4, 5, 6, 7, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 13, 9, 4, 12], [9, 14, 1, 2, 3, 7, 9, 8, 3, 14, 18, 15, 15, 3, 14, 1, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 1, 9, 12, 3, 2, 5, 14, 15, 21, 6, 18, 23, 6, 16, 20, 6, 4, 18, 7, 1, 3, 3, 21, 6, 18, 1, 5, 7, 1, 6, 1, 2, 3, 14, 9, 20, 9, 7, 7, 9, 2, 6, 16, 14, 6, 18, 1, 2, 9, 16, 21, 5, 22, 9, 1, 6, 2, 9, 7, 15, 6, 18, 1, 13, 5, 1, 2, 1, 13, 6, 4, 5, 6, 7], [1, 2, 3, 21, 3, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 8, 3, 3, 1, 9, 8, 9, 4, 3, 4, 5, 6, 7, 11, 6, 11, 22, 9, 1, 9, 7, 19, 9, 16, 3, 8, 9, 4, 3, 4, 5, 6, 7, 3, 14, 14, 15, 9, 11, 11, 10], [11, 6, 1, 2, 4, 5, 6, 7, 4, 6, 6, 12, 16, 3, 21, 6, 22, 5, 6, 18, 14, 11, 18, 1, 11, 3, 1, 21, 18, 4, 10, 9, 16, 16, 3, 22, 1, 5, 6, 7, 9, 1, 3, 9, 1, 4, 3, 9, 14, 1, 1, 2, 9, 1, 11, 3, 13, 2, 9, 1, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 9, 10], [9, 7, 19, 21, 3, 8, 3, 8, 11, 3, 21, 2, 3, 11, 3, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 14, 6, 2, 3, 11, 3, 15, 3, 1, 9, 7, 9, 19, 20, 9, 7, 1, 9, 15, 3, 13, 5, 1, 2, 1, 2, 3, 14, 3, 19, 3, 9, 19, 4, 10, 11, 5, 15, 22, 9, 1], [9, 14, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 2, 6, 13, 3, 21, 1, 2, 3, 23, 9, 5, 21, 6, 16, 4, 5, 6, 7, 13, 5, 1, 2, 4, 6, 20, 3, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 14, 1, 9, 10, 4, 6, 22, 12, 3, 19, 5, 7, 1, 2, 3, 1, 21, 18, 22, 12, 18, 7, 13, 5, 4, 4, 5, 7, 15, 1, 6, 23, 18, 1, 1, 2, 3, 5, 21, 4, 5, 16, 3, 5, 7, 19, 9, 7, 15, 3, 21], [9, 7, 19, 13, 2, 5, 4, 3, 1, 2, 3, 10, 11, 3, 5, 7, 1, 2, 3, 20, 3, 2, 5, 22, 4, 3, 1, 2, 3, 4, 5, 6, 7, 11, 3, 17, 18, 14, 1, 16, 6, 6, 1, 16, 21, 6, 8, 1, 2, 3, 10, 9, 7, 19, 5, 16, 14, 6, 8, 3, 1, 2, 5, 7, 15, 15, 6, 13, 21, 6, 7, 15, 1, 2, 3, 10, 22, 6, 18, 4, 19, 13, 5, 7, 19, 18, 23, 5, 7, 17, 18, 21, 3, 9, 7, 10, 13, 9, 10], [21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 14, 2, 9, 21, 3, 1, 2, 3, 20, 5, 19, 3, 6, 6, 7, 2, 5, 14, 1, 2, 3, 4, 5, 6, 7, 13, 2, 5, 14, 23, 3, 21, 3, 21, 10, 6, 18, 1, 18, 11, 3, 22, 2, 9, 7, 7, 3, 4], [13, 5, 1, 2, 8, 6, 21, 3, 1, 2, 9, 7, 6, 7, 3, 8, 5, 4, 4, 5, 6, 7, 2, 5, 1, 1, 2, 5, 14, 20, 5, 19, 3, 6, 2, 9, 20, 3, 23, 21, 6, 20, 3, 1, 6, 11, 3, 6, 7, 3, 6, 16, 2, 5, 14, 8, 6, 14, 1, 16, 9, 8, 6, 18, 14], [1, 2, 3, 20, 5, 19, 3, 6, 19, 3, 14, 22, 21, 5, 11, 3, 1, 2, 3, 8, 6, 8, 3, 7, 1, 22, 9, 1, 22, 2, 6, 7, 1, 9, 23, 3, 9, 14, 16, 6, 4, 4, 6, 13, 5, 1, 11, 3, 9, 7, 3, 7, 21, 5, 22, 2, 8, 3, 7, 1, 13, 9, 4, 12, 16, 6, 21, 11, 6, 1, 2, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21, 9, 7, 19, 1, 2, 3, 4, 5, 6, 7, 9, 14, 12, 3, 20, 5, 7, 14, 2, 6, 13, 6, 16, 16, 2, 5, 14, 4, 6, 20, 3, 4, 10, 4, 5, 6, 7, 9, 14, 13, 3, 4, 4, 9, 14, 15, 5, 20, 3, 14, 6, 8, 3, 9, 8, 9, 25, 5, 7, 15, 4, 5, 6, 7, 16, 9, 22, 1, 1, 6, 1, 2, 3, 20, 6, 4, 18, 7, 1, 3, 3, 21], [20, 5, 3, 13, 3, 21, 4, 5, 12, 3, 10, 6, 18, 11, 3, 6, 20, 3, 21, 13, 2, 3, 4, 8, 3, 19, 13, 5, 1, 2, 1, 2, 3, 8, 9, 15, 7, 5, 16, 5, 22, 3, 7, 1, 16, 6, 6, 1, 9, 15, 3], [1, 2, 3, 16, 6, 4, 4, 6, 13, 11, 3, 9, 16, 3, 13, 22, 6, 8, 8, 3, 7, 1, 14, 2, 9, 21, 3, 6, 7, 1, 2, 3, 20, 5, 19, 3, 6], [5, 2, 6, 23, 3, 1, 6, 14, 6, 8, 3, 19, 9, 10, 20, 6, 4, 18, 7, 1, 3, 3, 21, 1, 2, 3, 21, 3, 13, 5, 1, 2, 12, 3, 20, 5, 7], [5, 11, 3, 4, 5, 3, 20, 3, 5, 7, 1, 2, 3, 13, 6, 21, 12, 9, 7, 19, 2, 5, 14, 23, 3, 21, 14, 23, 3, 22, 1, 5, 20, 3, 9, 11, 6, 18, 1, 22, 6, 7, 14, 3, 21, 20, 9, 1, 5, 6, 7], [1, 2, 5, 14, 20, 5, 19, 3, 6, 8, 9, 12, 3, 5, 13, 9, 7, 1, 1, 6, 9, 4, 4, 1, 2, 3, 8, 6, 21, 3], [11, 6, 11, 22, 9, 1, 9, 7, 19, 15, 9, 11, 11, 10, 11, 3, 4, 6, 20, 3, 4, 10, 4, 5, 6, 7], [3, 20, 3, 21, 10, 1, 5, 8, 3, 5, 13, 9, 1, 22, 2, 9, 6, 7, 3, 6, 16, 10, 6, 18, 21, 20, 5, 19, 3, 6, 5, 14, 6, 8, 3, 2, 6, 13, 3, 7, 19, 18, 23, 14, 8, 5, 4, 3, 16, 21, 6, 8, 3, 9, 21, 1, 6, 3, 9, 21], [1, 2, 9, 1, 11, 3, 14, 6, 11, 3, 9, 18, 1, 5, 16, 18, 4, 13, 5, 14, 2, 5, 22, 6, 18, 4, 19, 21, 18, 11, 8, 10, 2, 3, 9, 19, 9, 15, 9, 5, 7, 14, 1, 9, 4, 5, 6, 7], [1, 9, 12, 3, 9, 8, 6, 8, 3, 7, 1, 1, 6, 13, 9, 1, 22, 2, 1, 2, 5, 14, 20, 5, 19, 3, 6], [13, 6, 18, 4, 19, 10, 6, 18, 3, 20, 3, 21, 13, 9, 7, 1, 1, 6, 20, 6, 4, 18, 7, 1, 3, 3, 21, 13, 5, 1, 2, 12, 3, 20, 5, 7, 21, 5, 22, 2, 9, 21, 19, 14, 6, 7, 9, 7, 19, 2, 5, 14, 4, 5, 6, 7]]\n",
            "Word2Vec shape: (26, 128)\n",
            "Word2Vec embeddings: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [ 0.01499402 -0.01157733  0.17544267  0.02072983 -0.01279209 -0.22414222\n",
            "   0.02005932  0.05753706 -0.01944208 -0.01496397  0.26419944 -0.05098562\n",
            "   0.00068617 -0.10155127 -0.0083288  -0.10500033 -0.02105615  0.12449843\n",
            "  -0.09189223  0.02844688  0.17492576  0.15495333  0.1234379   0.01979536\n",
            "  -0.08433766  0.14595085 -0.09517133  0.08291405  0.01341272 -0.07428417\n",
            "  -0.32279915  0.03707847 -0.01850857 -0.00256643 -0.03621771  0.03751522\n",
            "   0.25613242  0.15841964  0.22752108 -0.06902725 -0.07913905  0.14114203\n",
            "  -0.07540777 -0.05079257  0.10607625  0.11041861 -0.02181652 -0.07784761\n",
            "   0.00213869  0.14830884 -0.00059169  0.08966215  0.1156004   0.12130155\n",
            "   0.16061838  0.0336818   0.13044322 -0.10215595 -0.09064406 -0.02845797\n",
            "   0.12307254 -0.12313317  0.0758945  -0.05884093  0.09977613 -0.08700339\n",
            "   0.11170813  0.10546141  0.05461083 -0.0199768   0.08025031  0.06022271\n",
            "  -0.0984007  -0.07962459 -0.06485014  0.02855733  0.04233344  0.09179606\n",
            "  -0.03789996  0.1922449  -0.02950055 -0.05775835  0.07863863  0.20354739\n",
            "  -0.01033415  0.03245977  0.21939985 -0.12307432  0.09601112  0.12998174\n",
            "  -0.07754666 -0.07079767 -0.14696963 -0.00380163  0.17493714  0.00878621\n",
            "  -0.27671295 -0.2373458   0.05133488 -0.07435016 -0.27829465 -0.02052513\n",
            "   0.15102841  0.07837185  0.01408205 -0.06637745  0.08462285 -0.14705178\n",
            "  -0.0670146  -0.11807993  0.01047196 -0.04148376 -0.00957589  0.0374644\n",
            "  -0.05080111 -0.02199528 -0.03624016  0.18639028  0.03645542  0.12346306\n",
            "  -0.0484759  -0.02065499  0.05408379 -0.04601029  0.0070316  -0.16495083\n",
            "  -0.09677251  0.11445434]\n",
            " [ 0.01120927 -0.01229759  0.14619313  0.01820905 -0.00984941 -0.17653432\n",
            "   0.00625947  0.0445849  -0.00302503 -0.02235435  0.20662643 -0.04820666\n",
            "  -0.0003899  -0.08616165 -0.01862833 -0.08342921 -0.01871815  0.09652351\n",
            "  -0.06410894  0.02295668  0.138972    0.11943815  0.1020916   0.01117401\n",
            "  -0.07332649  0.12683004 -0.07058313  0.06515531  0.00873678 -0.0585236\n",
            "  -0.24777117  0.03044221 -0.02774958  0.00622973 -0.02271798  0.03362234\n",
            "   0.20179845  0.12956372  0.18266998 -0.0628015  -0.07178313  0.11402784\n",
            "  -0.06304166 -0.04129346  0.0980479   0.07707357 -0.0087734  -0.06073997\n",
            "  -0.00864474  0.11786789 -0.00688951  0.06209255  0.08560757  0.11011614\n",
            "   0.12724286  0.01544299  0.10301307 -0.07654072 -0.07999831 -0.02951059\n",
            "   0.09318781 -0.10079204  0.07130464 -0.05790024  0.08042991 -0.05926042\n",
            "   0.08084351  0.08263571  0.04880581 -0.01118087  0.06234659  0.0372063\n",
            "  -0.08074088 -0.05885597 -0.05293849  0.02506431  0.03634458  0.07233185\n",
            "  -0.03139332  0.14835022 -0.03495574 -0.04410892  0.06820326  0.15439025\n",
            "  -0.01060585  0.01798056  0.17270879 -0.09880178  0.07301574  0.1021336\n",
            "  -0.05871237 -0.05843655 -0.11893436 -0.00554401  0.14368182  0.00530237\n",
            "  -0.21737449 -0.18138793  0.04190405 -0.05320113 -0.22867918 -0.01915473\n",
            "   0.10776629  0.06341786  0.01441992 -0.05051031  0.05467576 -0.11880143\n",
            "  -0.06228844 -0.09512389  0.0007074  -0.04084899 -0.00740577  0.03142025\n",
            "  -0.03817569 -0.01392264 -0.02176478  0.14214489  0.03033371  0.09394103\n",
            "  -0.03704738 -0.01754271  0.04157491 -0.03768833  0.01093687 -0.13729051\n",
            "  -0.07281277  0.09601191]\n",
            " [ 0.01730257 -0.00953603  0.21957414  0.03580673 -0.02896699 -0.26889575\n",
            "   0.02110887  0.07295913 -0.0222119  -0.0304713   0.31444907 -0.06436796\n",
            "   0.00233396 -0.121361   -0.01844882 -0.13131161 -0.02625451  0.14783923\n",
            "  -0.11116016  0.01567253  0.2039125   0.18597323  0.1554957   0.02267443\n",
            "  -0.0950366   0.17961089 -0.10558522  0.10365453  0.00747619 -0.08672766\n",
            "  -0.38545167  0.04988506 -0.02197753 -0.00878327 -0.0406637   0.03750611\n",
            "   0.30338243  0.18681757  0.26237568 -0.09238958 -0.10685302  0.17111628\n",
            "  -0.105108   -0.05755792  0.13442914  0.12161613 -0.03288093 -0.08361109\n",
            "   0.00141274  0.18726119 -0.00868135  0.10198653  0.12616743  0.15383993\n",
            "   0.18938276  0.02897169  0.15365106 -0.12337323 -0.11901077 -0.02392855\n",
            "   0.13783234 -0.14201102  0.09482872 -0.08462695  0.1131926  -0.09839271\n",
            "   0.12155097  0.12312762  0.07103656 -0.02572436  0.09411974  0.07343425\n",
            "  -0.11980262 -0.1030589  -0.07468288  0.0403131   0.06259272  0.10857429\n",
            "  -0.05095596  0.21047047 -0.04627442 -0.05926947  0.10722244  0.23876509\n",
            "  -0.02149254  0.03391412  0.26014698 -0.14812325  0.10499465  0.15755513\n",
            "  -0.09484807 -0.08019046 -0.16803972 -0.00205919  0.21280335  0.01558243\n",
            "  -0.32513154 -0.27744862  0.06896555 -0.08233567 -0.33947471 -0.02970529\n",
            "   0.18049055  0.10088883  0.02223437 -0.08937211  0.09491598 -0.16674116\n",
            "  -0.08689647 -0.14038013  0.01296616 -0.06396686 -0.01390059  0.05992101\n",
            "  -0.06197552 -0.01514385 -0.03496974  0.21849996  0.04159915  0.14959928\n",
            "  -0.05028775 -0.03420506  0.07657877 -0.06605278  0.0185842  -0.20176147\n",
            "  -0.12363981  0.13757817]\n",
            " [ 0.01160929 -0.00571138  0.19115035  0.02154689 -0.01153172 -0.23134071\n",
            "   0.0104657   0.05938489 -0.00768537 -0.01794801  0.27871984 -0.05453704\n",
            "   0.00754639 -0.11534719 -0.01852744 -0.11607613 -0.02726089  0.13066071\n",
            "  -0.09849925  0.02861637  0.17301539  0.15534428  0.1320194   0.01913837\n",
            "  -0.09695223  0.16313168 -0.09817943  0.08676554  0.00783102 -0.07279933\n",
            "  -0.33661956  0.04538644 -0.03189864 -0.00351229 -0.02848195  0.03881381\n",
            "   0.25633109  0.169254    0.23618399 -0.0765278  -0.09600569  0.15249002\n",
            "  -0.09479634 -0.05376277  0.12323415  0.10634656 -0.01959261 -0.07507385\n",
            "  -0.00617921  0.16814321 -0.00139284  0.09605507  0.12198368  0.12899549\n",
            "   0.1598122   0.03550463  0.13918534 -0.09671399 -0.09806382 -0.02321306\n",
            "   0.11616217 -0.12290662  0.08495273 -0.0665621   0.10799092 -0.08686738\n",
            "   0.11613295  0.10651687  0.0651307  -0.01926764  0.07544614  0.05948778\n",
            "  -0.09853823 -0.08870437 -0.06749688  0.02787233  0.05734394  0.10453244\n",
            "  -0.04215761  0.20043699 -0.03848394 -0.06149787  0.09026626  0.21355872\n",
            "  -0.01692095  0.02583307  0.231975   -0.12670907  0.09550221  0.13244164\n",
            "  -0.07956137 -0.07756685 -0.15527655 -0.00701684  0.17900249  0.00271225\n",
            "  -0.2881248  -0.24991532  0.06076964 -0.0861194  -0.30475989 -0.03581985\n",
            "   0.14989203  0.0913241   0.01765605 -0.07481111  0.08090401 -0.16109481\n",
            "  -0.07503198 -0.12031668  0.01088947 -0.05096997 -0.00738508  0.04757883\n",
            "  -0.06537563 -0.02475809 -0.04235476  0.18904702  0.04237592  0.14104275\n",
            "  -0.04873987 -0.02882081  0.06889497 -0.05037365  0.00941983 -0.1746801\n",
            "  -0.10425587  0.11571732]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.1536"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText shape: (26, 128)\n",
            "FastText embeddings: [[ 0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]\n",
            " [-0.03521762 -0.03479476  0.02845298  0.03818076 -0.10347812 -0.24461722\n",
            "  -0.0398801   0.00829738  0.07086217  0.03210483  0.14250544 -0.05988738\n",
            "   0.043044   -0.21647644  0.12729996 -0.12470272 -0.01031252  0.17025226\n",
            "  -0.00640404 -0.01018168  0.1128727   0.24142292  0.07770351  0.01904791\n",
            "  -0.16076791  0.07717168 -0.06782666  0.00315943  0.04416052 -0.20612578\n",
            "  -0.22635052 -0.02949098  0.1662809   0.0055493  -0.07213143  0.08606412\n",
            "   0.27374834 -0.01323915  0.0514768  -0.07055693  0.01257666 -0.11110409\n",
            "   0.01348197 -0.05160948  0.13984257  0.15162733 -0.03907603  0.04631592\n",
            "  -0.07320632  0.08950317  0.14034824  0.02085699  0.09221118  0.02751477\n",
            "   0.05860198 -0.0096325   0.08359747 -0.08662512 -0.02877791  0.10509843\n",
            "   0.01697085 -0.06064966  0.01473941  0.01839161 -0.04832568 -0.03552043\n",
            "  -0.01407829 -0.08453895  0.02666492 -0.0491309   0.05176568 -0.03498224\n",
            "  -0.04261473 -0.05162619 -0.21276352  0.05485211  0.05130785  0.32911539\n",
            "  -0.11335763  0.16664857 -0.09866799 -0.00948143  0.13258909  0.22322884\n",
            "  -0.07449373  0.09767507  0.1009602  -0.04988967  0.13869271  0.09700397\n",
            "  -0.06731243  0.03723895 -0.07815526  0.13919882  0.21837261 -0.10972118\n",
            "  -0.14000946 -0.19459903  0.09720778 -0.09949904 -0.07235846  0.04634211\n",
            "   0.12396379  0.2277104  -0.00532926  0.05510124  0.06808233 -0.17318082\n",
            "   0.06054887 -0.07227612  0.038886   -0.07327665  0.09935898 -0.00697105\n",
            "  -0.09061994  0.00271671 -0.13481113  0.12069831 -0.06475468  0.02834334\n",
            "  -0.10791166  0.05857265  0.07574338 -0.10499662  0.15036327 -0.04937436\n",
            "  -0.08445308  0.0817403 ]\n",
            " [-0.02508084 -0.02698006  0.03112009  0.03011565 -0.07832682 -0.18023914\n",
            "  -0.04129011  0.01095258  0.05981293  0.01368426  0.10345447 -0.05337849\n",
            "   0.03306868 -0.16989928  0.08780941 -0.09880283 -0.00947401  0.12439243\n",
            "  -0.00274204 -0.00839408  0.08693956  0.18482663  0.06443585  0.0102375\n",
            "  -0.12505949  0.06143058 -0.04761124 -0.00164278  0.03510197 -0.15347147\n",
            "  -0.17043817 -0.02605797  0.1218322   0.01111209 -0.05053085  0.06736852\n",
            "   0.21189308 -0.01226938  0.04315957 -0.05591968  0.00567977 -0.07998382\n",
            "   0.01055386 -0.04238204  0.1140881   0.11069563 -0.02111855  0.03447913\n",
            "  -0.05761512  0.06635045  0.10533063  0.01022345  0.06586535  0.02375779\n",
            "   0.04372685 -0.01300844  0.06832409 -0.06374122 -0.02778277  0.07677603\n",
            "   0.00904306 -0.04649606  0.01260574  0.00940854 -0.03825759 -0.01513013\n",
            "  -0.00991239 -0.06488805  0.0222335  -0.03208063  0.04097136 -0.03373407\n",
            "  -0.0375471  -0.03273152 -0.16583432  0.04299524  0.03778704  0.25794134\n",
            "  -0.08815387  0.12467932 -0.07930787 -0.00977296  0.09981501  0.1659812\n",
            "  -0.05536789  0.07076938  0.07406545 -0.04176927  0.10832403  0.07659382\n",
            "  -0.04688633  0.02613531 -0.05844467  0.10293429  0.16442236 -0.089151\n",
            "  -0.10703923 -0.14960019  0.07527824 -0.07506679 -0.06096547  0.03586984\n",
            "   0.08481038  0.17213634 -0.00267179  0.04163826  0.04619286 -0.129576\n",
            "   0.04034287 -0.05602095  0.02622984 -0.06027877  0.07537665 -0.01019626\n",
            "  -0.06938562  0.00052021 -0.10295121  0.08561063 -0.04777267  0.01923161\n",
            "  -0.08910578  0.04440987  0.05931528 -0.08307655  0.11638648 -0.0363659\n",
            "  -0.05951105  0.06051779]\n",
            " [-0.04655656 -0.03656323  0.04274834  0.04753626 -0.12464498 -0.28773445\n",
            "  -0.05049339  0.01202018  0.0876396   0.02869234  0.16293544 -0.07412809\n",
            "   0.04951278 -0.25496006  0.14066565 -0.15270078 -0.00770001  0.19730687\n",
            "  -0.00663305 -0.02106366  0.13334194  0.29008567  0.09595728  0.01311407\n",
            "  -0.17934094  0.09001363 -0.07344604  0.00958544  0.04866437 -0.24058101\n",
            "  -0.26808947 -0.03960526  0.19813265  0.00266484 -0.0834408   0.09991624\n",
            "   0.32336247 -0.01856872  0.05616411 -0.0897842   0.00880307 -0.13076314\n",
            "   0.00699178 -0.0655961   0.16270041  0.16893971 -0.04169448  0.06281222\n",
            "  -0.0870932   0.1042368   0.15995634  0.02226448  0.10786603  0.03239812\n",
            "   0.0697051  -0.01656957  0.09910575 -0.10526793 -0.03319596  0.12780821\n",
            "   0.0183264  -0.06956814  0.01761118  0.01842819 -0.06252848 -0.02973371\n",
            "  -0.02388089 -0.09834158  0.03901184 -0.0546715   0.06990026 -0.03863223\n",
            "  -0.05248497 -0.06052505 -0.25141498  0.06796636  0.06177276  0.39370057\n",
            "  -0.1355157   0.18340617 -0.12111765 -0.01345038  0.15782806  0.25730616\n",
            "  -0.08472843  0.10820681  0.11512201 -0.05721503  0.15787014  0.11649606\n",
            "  -0.07602608  0.04320846 -0.08037652  0.16033606  0.25686121 -0.13357183\n",
            "  -0.15968208 -0.2315208   0.11857019 -0.11599316 -0.08619498  0.05326046\n",
            "   0.14067581  0.2709294  -0.00603593  0.06046483  0.07076791 -0.19945243\n",
            "   0.06042035 -0.09200229  0.04589754 -0.09237014  0.11281388 -0.00347989\n",
            "  -0.10848705  0.00650901 -0.15983771  0.13646299 -0.07595762  0.02875447\n",
            "  -0.12898025  0.06098489  0.09168398 -0.12445097  0.18013944 -0.05614671\n",
            "  -0.09908716  0.0895521 ]\n",
            " [-0.04112015 -0.03047254  0.0313697   0.03586952 -0.10725853 -0.24700528\n",
            "  -0.04804906  0.01011048  0.08229772  0.03221561  0.14480232 -0.06198044\n",
            "   0.0417206  -0.23044078  0.12182869 -0.12736483 -0.00945099  0.1749649\n",
            "  -0.00950279 -0.00875824  0.11397955  0.24618788  0.08341399  0.01528031\n",
            "  -0.16785401  0.07594374 -0.06749722  0.00434219  0.04784162 -0.20896153\n",
            "  -0.23637421 -0.03451758  0.16140054  0.00392304 -0.06643859  0.09103919\n",
            "   0.27525634 -0.0155637   0.05456893 -0.07461032  0.00515218 -0.11580438\n",
            "   0.00665349 -0.05940952  0.1490843   0.14566377 -0.03502584  0.05277383\n",
            "  -0.07769541  0.09328726  0.14603046  0.02493846  0.09650721  0.02338309\n",
            "   0.06049962 -0.01301832  0.08422471 -0.0891247  -0.02861424  0.10976239\n",
            "   0.00616095 -0.06161483  0.01389549  0.02167639 -0.05078018 -0.03262016\n",
            "  -0.01773676 -0.08617331  0.03333109 -0.04819953  0.05375933 -0.039965\n",
            "  -0.04554479 -0.0510384  -0.2141806   0.05425691  0.06239812  0.34794042\n",
            "  -0.11362843  0.16292621 -0.10358663 -0.01142     0.1393995   0.22419053\n",
            "  -0.08135039  0.09696622  0.10151511 -0.05317742  0.14671844  0.09616496\n",
            "  -0.06817326  0.03568736 -0.07667695  0.13882065  0.21887714 -0.11704855\n",
            "  -0.13990477 -0.19826615  0.10604647 -0.10693749 -0.0768421   0.04087039\n",
            "   0.12117764  0.23876134 -0.00560124  0.0528237   0.06168098 -0.18255478\n",
            "   0.06139087 -0.07295129  0.04134827 -0.07357964  0.10107006 -0.00846275\n",
            "  -0.0936726   0.00174898 -0.13768417  0.11428876 -0.06826796  0.02786807\n",
            "  -0.11657967  0.05451152  0.08357084 -0.10959513  0.1577367  -0.04522966\n",
            "  -0.08383857  0.07511681]]\n",
            "GloVe shape: (26, 128)\n",
            "GloVe embeddings: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [ 3.55777558e-01 -2.84589748e-01  1.58124390e-01 -4.49625118e-01\n",
            "  -2.34479698e-01  1.59628614e-01  5.16432431e-01  5.91838298e-01\n",
            "  -5.62957136e-01 -7.60846802e-01  3.55518843e-01 -5.95589271e-01\n",
            "   4.02334099e-01  2.85359598e-01  4.61384199e-01  6.43594317e-01\n",
            "   3.81255708e-01 -4.00065950e-01 -2.35468236e-01  1.97672703e-01\n",
            "   4.59291390e-01  1.89182498e-01 -2.56116137e-01  5.02830929e-01\n",
            "  -5.84163458e-01  6.56442604e-01 -3.37902993e-01  4.11871683e-01\n",
            "  -5.89257421e-01 -4.37873320e-01  4.04892650e-01 -1.60258287e-01\n",
            "   4.72145821e-01  4.34523616e-01 -6.11569651e-01 -4.78280331e-01\n",
            "   9.31152675e-03  4.38140614e-01 -3.31671117e-02 -4.52279117e-01\n",
            "   2.99345406e-02  6.04339217e-01 -2.77076091e-01  2.15272243e-01\n",
            "   4.27422383e-01 -5.78140951e-01  3.66636192e-01  4.16591247e-01\n",
            "   1.53119960e-01 -3.12115871e-02 -2.77278657e-01 -5.43602416e-01\n",
            "  -1.20645189e-01  1.65586769e-01 -5.43155885e-01  3.59758341e-01\n",
            "   2.89476638e-01 -6.66789428e-01  4.65117980e-01  4.53114911e-01\n",
            "  -2.33444105e-01 -2.90890983e-01  3.23240406e-01 -4.58158619e-01\n",
            "  -6.50989450e-01 -2.52847738e-01 -1.88654827e-01 -2.62354539e-01\n",
            "   2.90887808e-01 -3.75630421e-01 -4.34492938e-01  2.43220148e-01\n",
            "  -1.82965690e-01  1.31845248e-01  2.38795264e-01 -2.25624388e-01\n",
            "   2.10490512e-01  3.48143108e-01  4.85092930e-01  2.46152228e-01\n",
            "   4.23731538e-01 -4.49241372e-01  2.87516550e-01 -5.22551148e-01\n",
            "  -6.25565237e-01  2.55355235e-01 -4.62971257e-01  9.80951655e-02\n",
            "   4.90010979e-02 -2.97873717e-01 -3.43475899e-02  2.14127509e-01\n",
            "  -5.86129667e-01  2.42840714e-01  5.44654727e-01 -1.23109605e-01\n",
            "   1.53032023e-01  3.41148454e-01 -2.06755558e-01  3.11695431e-01\n",
            "   1.37015179e-01 -2.84290556e-01  4.18452974e-01 -2.30864897e-01\n",
            "  -3.94364167e-01  5.43645866e-01 -4.01671518e-01 -3.98222476e-01\n",
            "  -4.86448583e-01  1.53084641e-01 -5.76991990e-01  3.79230868e-01\n",
            "   2.32952386e-01 -1.62505718e-01  1.77696129e-02  3.72227819e-01\n",
            "  -2.15148055e-01  5.76752757e-01 -1.56037328e-01  1.47591166e-01\n",
            "  -3.68447771e-01  5.35495403e-01  3.22011585e-01 -3.09173468e-01\n",
            "   3.78559213e-01  2.51170681e-01 -5.10594775e-01  4.80761869e-01]\n",
            " [ 3.92200432e-01  1.20337584e-01  1.47503241e-01 -3.96638862e-01\n",
            "  -5.86273382e-01  2.65812768e-01  2.30785955e-01  1.68064407e-01\n",
            "  -1.35871512e-01 -6.54216432e-01  3.17073459e-01 -6.09706585e-01\n",
            "   6.86866335e-01  1.50871296e-01  5.57001905e-01  3.30065340e-01\n",
            "   2.20623748e-01 -4.26007425e-01 -3.16513823e-01  7.25077835e-02\n",
            "   2.79554848e-01  2.94667952e-01 -3.83329854e-01  4.51668896e-01\n",
            "  -3.17326443e-01  6.12164305e-01 -4.56296239e-01  4.13782653e-01\n",
            "  -2.11258890e-01 -4.11148943e-01  6.08891704e-01 -1.54375124e-01\n",
            "   3.70856237e-01  2.77058487e-01 -2.93206889e-01 -2.61701011e-01\n",
            "   2.21988749e-01  6.39638203e-01 -1.32930985e-01 -2.00458408e-01\n",
            "   6.54820146e-02  5.68924229e-01 -3.67643988e-01  1.59187530e-01\n",
            "   2.26627478e-01 -2.31814238e-01  4.49324589e-01  5.36490345e-01\n",
            "   1.60880821e-01 -2.63744574e-01 -1.58629277e-01 -5.46390818e-01\n",
            "  -2.18392737e-01  2.14996165e-02 -3.46471937e-01  2.97818798e-01\n",
            "   5.14172834e-01 -5.48072149e-01  3.93303614e-01  8.15264552e-02\n",
            "  -3.15566582e-01 -3.17561618e-01 -3.20693366e-02 -3.95241741e-01\n",
            "  -6.03727786e-01 -4.74622229e-01 -3.11519797e-01 -1.53653993e-01\n",
            "   4.05948804e-01 -2.92697466e-01 -4.23708204e-01  3.89497563e-01\n",
            "   3.30945358e-02  3.75674913e-02  1.41471031e-01 -3.83889548e-02\n",
            "   7.55258016e-02  1.03630955e-01  3.20607337e-01  3.84413581e-01\n",
            "   7.10214688e-02 -6.52313879e-01  2.08169069e-01 -2.62713731e-01\n",
            "  -2.03455165e-01 -1.99988573e-03 -5.20702143e-01  3.25139184e-02\n",
            "   1.09068037e-01 -3.89728285e-01 -2.89006938e-01  9.47875157e-02\n",
            "  -1.60149574e-01  2.90538234e-01  3.30457615e-01 -2.95277356e-01\n",
            "   1.90424824e-01  6.76035727e-01 -1.78105149e-01  2.38044374e-01\n",
            "   1.09756202e-01 -4.89890829e-02  3.16846537e-01 -5.52626859e-01\n",
            "  -1.14289001e-01  4.37519445e-01 -4.29883138e-01 -3.22101111e-01\n",
            "  -4.32437694e-01  3.73441993e-01 -1.98127015e-01  7.33904503e-02\n",
            "   4.53739072e-01 -9.40628374e-02  3.46673867e-04  3.39762827e-01\n",
            "  -4.71004949e-01  3.54020001e-01 -1.59789711e-01 -7.52565693e-02\n",
            "  -2.91325872e-01  2.76028875e-01  5.54427154e-01 -5.44131087e-01\n",
            "   5.89532717e-01  1.42864148e-01 -3.56589191e-01  4.01753372e-01]\n",
            " [ 6.09767636e-01 -4.62513110e-01  1.05418476e-01 -4.40765307e-01\n",
            "  -5.03983252e-01  3.90878649e-02  2.65900933e-01  3.50746665e-01\n",
            "  -1.27000373e-01 -5.08762371e-01  6.27310452e-01 -6.39080526e-01\n",
            "   4.55336994e-01  3.54157442e-01  4.48072331e-01  3.56064723e-01\n",
            "   5.34930011e-01 -2.41990180e-01 -5.92210098e-01  2.07202040e-01\n",
            "   2.10611509e-01  5.97374570e-01 -2.35943232e-01  4.78935234e-01\n",
            "  -6.76317361e-01  4.43265104e-01 -5.15868160e-01  5.32476052e-01\n",
            "  -4.66869456e-01 -3.93536133e-01  3.96661196e-01 -7.67587024e-02\n",
            "   3.23803281e-01  2.95689871e-03 -4.94638552e-01 -3.90760580e-01\n",
            "   3.30796248e-01  2.81246780e-01  1.20218915e-01 -5.88926052e-01\n",
            "   2.54554336e-01  6.70032073e-01 -3.14662157e-01  3.02003010e-01\n",
            "   4.02134758e-01 -3.70738891e-01  3.94378433e-01  4.08981216e-01\n",
            "   1.55294105e-01  7.07784002e-02 -4.26281882e-01 -2.48522206e-01\n",
            "  -1.21630297e-01  1.54496462e-01 -3.32595204e-01  1.78569431e-01\n",
            "   6.63698115e-01 -5.70495935e-01  5.48291438e-01  5.61099809e-01\n",
            "  -5.17946132e-01 -3.79010922e-01 -7.21171545e-02 -5.59583220e-01\n",
            "  -2.67814226e-01 -2.73328314e-01 -4.05023828e-01 -3.79911947e-01\n",
            "   3.03005913e-01 -4.32381846e-01 -5.13556651e-01  4.08623846e-01\n",
            "  -4.25441286e-01  3.17006672e-01  2.58259066e-01 -1.73330729e-01\n",
            "   2.12293514e-01  7.01236824e-01  4.57731161e-01  2.25327252e-01\n",
            "   2.97963943e-01 -2.45244086e-01  3.19895199e-01 -5.19710158e-01\n",
            "  -6.38572487e-01  1.54750061e-01 -5.35250956e-01  5.55839668e-01\n",
            "   1.91625832e-01 -6.21360476e-01 -1.91858599e-01  3.23641371e-01\n",
            "  -3.58401821e-01  4.99689700e-01  3.72718797e-01 -1.07616432e-01\n",
            "   1.21491375e-01  7.00066911e-01 -3.08578790e-01 -6.44027816e-02\n",
            "   3.41496648e-01 -3.03912972e-01  5.73609358e-01 -5.79982548e-01\n",
            "  -5.92263758e-01  6.08260228e-01 -5.22335810e-01 -5.52317174e-01\n",
            "  -9.24867921e-02  2.29177887e-01 -7.20477103e-01  3.09414824e-01\n",
            "   3.95137725e-01 -2.82621829e-03 -1.72712746e-01  6.49401528e-01\n",
            "  -2.51842956e-01  4.57860041e-01 -4.39252056e-01  1.37918169e-01\n",
            "  -5.16181787e-01  6.36351255e-01  4.13132933e-01 -6.51511896e-01\n",
            "   6.15645175e-01  3.25138211e-01 -4.29383000e-01  4.99875456e-01]\n",
            " [ 3.41687668e-01 -5.30249747e-01 -1.48585525e-01  8.33030538e-02\n",
            "  -4.50773472e-02 -4.94156264e-02  7.01485892e-01  3.76897144e-01\n",
            "  -1.13887504e-01 -3.65256931e-01  6.15410877e-01 -5.95256862e-01\n",
            "   1.96525815e-02 -2.19391073e-02 -4.42626110e-02  4.05901350e-01\n",
            "   2.07476651e-01 -5.54956525e-01 -5.42120709e-01  1.32095060e-01\n",
            "   1.23413551e-01  4.02419587e-01 -5.66635074e-01  3.46665492e-01\n",
            "  -1.59802408e-01  4.26499336e-01 -6.57365257e-01  4.59910220e-01\n",
            "  -2.28532451e-01 -3.01559799e-01  1.18326755e-01  5.17379297e-01\n",
            "  -1.99944493e-02 -3.02958733e-01 -4.86666739e-01  1.43628526e-01\n",
            "   3.22371154e-02  1.54907649e-02  3.32367052e-01 -3.85683894e-01\n",
            "   3.45037760e-03  6.00166336e-01 -1.07373258e-01  3.48855501e-01\n",
            "   3.98261443e-01 -6.87162179e-02  1.38580960e-02  5.30279159e-01\n",
            "  -1.80623566e-01  3.21445071e-01 -2.30153365e-01 -4.05851339e-01\n",
            "   1.57990625e-01  2.32010906e-01 -4.29507123e-01  5.62536292e-01\n",
            "   4.22157044e-01 -4.05021815e-01  3.96782524e-01  3.30065467e-01\n",
            "  -5.58667436e-01  9.41448328e-02 -5.98173819e-01 -3.22195945e-01\n",
            "  -3.26307593e-01 -4.25134084e-01 -4.46022037e-01 -2.81337666e-01\n",
            "   2.99482830e-01 -2.70697280e-01 -4.44089380e-01  9.25708458e-02\n",
            "  -2.79174745e-01 -5.29489700e-01  3.19034533e-01 -3.68585142e-01\n",
            "   5.17643450e-01  2.69239435e-01  4.94345826e-01  1.36246812e-01\n",
            "   5.15297852e-01  2.10458922e-01  8.57966675e-02 -3.13759922e-01\n",
            "  -5.36196855e-01  1.37347736e-01 -4.91055226e-01  6.29036200e-01\n",
            "   7.21591465e-01 -6.94373577e-01 -1.77810648e-01  1.38968089e-01\n",
            "  -2.80454379e-01  4.17395913e-01  6.21114933e-01 -2.30855028e-01\n",
            "  -7.05660733e-02  2.39871595e-01 -8.99830641e-02  6.89475267e-02\n",
            "   5.17254755e-01 -1.05896593e-01  7.14843112e-01 -4.64085317e-01\n",
            "  -1.76847245e-01  2.27128511e-01 -4.85788031e-01 -8.83310282e-02\n",
            "  -3.04818533e-02  1.12945779e-01 -4.94260245e-01  3.22681587e-01\n",
            "   9.45256811e-02 -9.00047399e-02  2.15934427e-01  3.49882846e-01\n",
            "  -4.96091109e-01  1.35221256e-01 -2.97893156e-02  5.38923019e-01\n",
            "  -2.84851247e-01  4.00269595e-02  7.93487329e-02 -5.42662998e-01\n",
            "   3.32037061e-01  1.59707840e-01 -1.65347768e-02  3.78271592e-01]]\n",
            "\n",
            "Comparison for word 'lion' (ID varies):\n",
            "'lion' not found in vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "S6BE_eCL3gmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install numpy==1.26.4 gensim==4.3.3 mittens==0.2 spacy==3.7.2 stop-words==2018.7.23 pandas scipy -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import io as sio\n",
        "import numpy as np\n",
        "from multiprocessing import cpu_count\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sys\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Tokenization class (from earlier)\n",
        "specialchar_dic = {\n",
        "    \"’\": \"'\", \"„\": \"\\\"\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"«\": \"<<\", \"»\": \">>\",\n",
        "    \"…\": \"...\", \"—\": \"--\", \"¡\": \"!\", \"¿\": \"?\", \"©\": \" \", \"–\": \" \"\n",
        "}\n",
        "punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "specialchar_re = re.compile('(%s)' % '|'.join(specialchar_dic.keys()))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "cachedStopWords_en = stopWordsEN()  # Assume stopWordsEN() is defined as before\n",
        "\n",
        "class Tokenization:\n",
        "    def applyFE(self, text):\n",
        "        final_text = text.replace('cannot', 'can not').replace(\"can't\", 'can not')\n",
        "        final_text = final_text.replace(\"won't\", 'will not').replace(\"n't\", ' not').replace(' not ', ' not')\n",
        "        return final_text\n",
        "\n",
        "    def removeStopWords(self, text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords_en])\n",
        "\n",
        "    def removePunctuation(self, text, punctuation=punctuation):\n",
        "        for c in punctuation:\n",
        "            text = text.replace(c, ' ')\n",
        "        return text\n",
        "\n",
        "    def replaceUTF8Char(self, text, specialchars=specialchar_dic):\n",
        "        def replace(match):\n",
        "            return specialchars[match.group(0)]\n",
        "        return specialchar_re.sub(replace, text)\n",
        "\n",
        "    def createCorpus(self, text, remove_punctuation=True, remove_stopwords=True, apply_FE=True):\n",
        "        corpus = []\n",
        "        try:\n",
        "            text = self.replaceUTF8Char(text).replace(\"\\n\", \" \")\n",
        "            doc = nlp(text)\n",
        "            processed_text = ' '.join([t.lemma_ if t.lemma_ != '-PRON-' else t.text if not t.ent_type_ else t.text for t in doc])\n",
        "            processed_text = re.sub(\"\\\\s\\\\s+\", ' ', processed_text)\n",
        "            doc = nlp(processed_text.lower())\n",
        "            rawText = not (remove_punctuation or remove_stopwords or apply_FE)\n",
        "\n",
        "            for sentence in doc.sents:\n",
        "                sent = str(sentence.text)\n",
        "                if len(sent) == 0:\n",
        "                    continue\n",
        "                if not rawText:\n",
        "                    if apply_FE:\n",
        "                        sent = self.applyFE(text=sent)\n",
        "                    if remove_punctuation:\n",
        "                        sent = self.removePunctuation(text=sent)\n",
        "                    if remove_stopwords:\n",
        "                        sent = self.removeStopWords(text=sent)\n",
        "                sent = sent.lower().split()\n",
        "                if sent:\n",
        "                    corpus.append(sent)\n",
        "        except Exception as exp:\n",
        "            print('exception=', str(exp))\n",
        "            print('text=', text)\n",
        "        return corpus\n",
        "\n",
        "# Helper function for parallel processing\n",
        "def processElement(elem):\n",
        "    id_line = elem[0]\n",
        "    text = elem[1]\n",
        "    tkn = Tokenization()\n",
        "    text = tkn.createCorpus(text, remove_stopwords=False)\n",
        "    return id_line, text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    fn = list(uploaded.keys())[0]\n",
        "    df = pd.read_csv(fn, sep=',',encoding='latin-1')\n",
        "    print(df)\n",
        "\n",
        "    labels = df['label'].unique()\n",
        "    num_classes = len(labels)\n",
        "    label2id = {'mostly true': 0, 'mixture of true and false': 1, 'no factual content': 1, 'mostly false': 1}\n",
        "    for label in labels:\n",
        "        df.loc[df['label'] == label, 'label'] = label2id[label]\n",
        "\n",
        "    y = df['label'].astype(int).to_list()\n",
        "    sio.savemat('labels.mat', {'y': y})\n",
        "\n",
        "    X_network = df[['num_comments', 'num_shares', 'num_likes', 'num_loves', 'num_wows', 'num_hahas', 'num_sads', 'num_angrys']].to_numpy()\n",
        "    scaler_std = StandardScaler()\n",
        "    X_net_std = scaler_std.fit_transform(X_network)\n",
        "    X_net_std = X_net_std.reshape((X_net_std.shape[0], 1, X_net_std.shape[1]))\n",
        "    sio.savemat('network.mat', {'X_net_std': X_net_std})\n",
        "\n",
        "    print(\"Start Tokenization\")\n",
        "    texts = df[['id', 'content']].to_numpy().tolist()\n",
        "    corpus = [None] * len(texts)\n",
        "    no_threads = cpu_count() - 1\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=no_threads) as worker:\n",
        "        for result in worker.map(processElement, texts):\n",
        "            if result:\n",
        "                corpus[result[0]] = result[1]\n",
        "\n",
        "    print(\"Corpus sample:\")\n",
        "    for idx, doc in enumerate(corpus[:5]):\n",
        "        print(idx, doc)\n",
        "\n",
        "    print(\"Start Document Tokenization\")\n",
        "    we = WordEmbeddings(corpus)\n",
        "    documents = we.prepareDocuments()\n",
        "    vocabulary_size = we.no_words\n",
        "    max_size = we.max_size\n",
        "\n",
        "    print(\"Vocabulary size:\", vocabulary_size)\n",
        "    print(\"Max Document size:\", max_size)\n",
        "\n",
        "    X_docs = []\n",
        "    for document in documents:\n",
        "        doc_size = len(document)\n",
        "        X_docs.append(document + [0] * (max_size - doc_size))\n",
        "    X_docs = np.array(X_docs)\n",
        "    sio.savemat('corpus.mat', {'X': X_docs})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IOWHWvin1v-g",
        "outputId": "bdbfe40d-94f0-451b-94b5-1885f29e39be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/12.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/12.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m171.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m171.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8ea4a16-97db-43d8-8100-7a6c6afcd896\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8ea4a16-97db-43d8-8100-7a6c6afcd896\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving facebook-fact-check.csv to facebook-fact-check (1).csv\n",
            "        account_id       post_id    Category               Page  \\\n",
            "0     1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1     1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "2     1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "3     1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "4     1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "...            ...           ...         ...                ...   \n",
            "2277  1.150000e+14  1.470000e+15        left      The Other 98%   \n",
            "2278  1.150000e+14  1.470000e+15        left      The Other 98%   \n",
            "2279  1.150000e+14  1.470000e+15        left      The Other 98%   \n",
            "2280  1.150000e+14  1.470000e+15        left      The Other 98%   \n",
            "2281  1.150000e+14  1.470000e+15        left      The Other 98%   \n",
            "\n",
            "                                               Post URL Date Published  \\\n",
            "0     https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016   \n",
            "1     https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016   \n",
            "2     https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016   \n",
            "3     https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016   \n",
            "4     https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016   \n",
            "...                                                 ...            ...   \n",
            "2277  https://www.facebook.com/TheOther98/posts/1472...      9/27/2016   \n",
            "2278  https://www.facebook.com/TheOther98/posts/1472...      9/27/2016   \n",
            "2279  https://www.facebook.com/TheOther98/posts/1472...      9/27/2016   \n",
            "2280  https://www.facebook.com/TheOther98/posts/1472...      9/27/2016   \n",
            "2281  https://www.facebook.com/TheOther98/posts/1472...      9/27/2016   \n",
            "\n",
            "     Post Type                     Rating Debate  share_count  reaction_count  \\\n",
            "0        video         no factual content    NaN          NaN           146.0   \n",
            "1         link                mostly true    NaN          1.0            33.0   \n",
            "2         link                mostly true    NaN         34.0            63.0   \n",
            "3         link                mostly true    NaN         35.0           170.0   \n",
            "4        video                mostly true    NaN        568.0          3188.0   \n",
            "...        ...                        ...    ...          ...             ...   \n",
            "2277     photo         no factual content    NaN      21563.0         33388.0   \n",
            "2278      link                mostly true    NaN       1451.0          4828.0   \n",
            "2279      link  mixture of true and false    NaN       8236.0         12083.0   \n",
            "2280      link                mostly true    yes       3985.0         12966.0   \n",
            "2281     photo         no factual content    NaN      24499.0         47312.0   \n",
            "\n",
            "      comment_count                                       Context Post  \n",
            "0              15.0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1              34.0  Can either candidate move the needle in the de...  \n",
            "2              27.0  BREAKING: Ahmad Rahami, 28, wanted in connecti...  \n",
            "3              86.0  Donald J. Trump: &quot;Do we have a choice? Lo...  \n",
            "4            2815.0  WATCH LIVE: Hillary Clinton holds news confere...  \n",
            "...             ...                                                ...  \n",
            "2277          391.0                                              Word.  \n",
            "2278          342.0                                            Insane.  \n",
            "2279          856.0                                                  0  \n",
            "2280          538.0                                         Nailed it.  \n",
            "2281         1375.0       So excited for the season finale of America.  \n",
            "\n",
            "[2282 rows x 13 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8daa273ba863>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mlabel2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'mostly true'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mixture of true and false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no factual content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mostly false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install numpy==1.26.4 gensim==4.3.3 spacy==3.7.2 stop-words==2018.7.23 pandas scipy -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import io as sio\n",
        "import re\n",
        "import spacy\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe\n",
        "from multiprocessing import cpu_count\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define stop words (simplified for brevity; use your full list)\n",
        "def stopWordsEN():\n",
        "    sw_stop_words = get_stop_words('en')\n",
        "    sw_nltk = stopwords.words('english')\n",
        "    sw_spacy = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
        "    return list(set(sw_stop_words + sw_nltk + sw_spacy))\n",
        "\n",
        "# Tokenization setup\n",
        "specialchar_dic = {\n",
        "    \"’\": \"'\", \"„\": \"\\\"\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"«\": \"<<\", \"»\": \">>\",\n",
        "    \"…\": \"...\", \"—\": \"--\", \"¡\": \"!\", \"¿\": \"?\", \"©\": \" \", \"–\": \" \"\n",
        "}\n",
        "punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "specialchar_re = re.compile('(%s)' % '|'.join(specialchar_dic.keys()))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "cachedStopWords_en = stopWordsEN()\n",
        "\n",
        "class Tokenization:\n",
        "    def applyFE(self, text):\n",
        "        final_text = text.replace('cannot', 'can not').replace('can\\'t', 'can not')\n",
        "        final_text = final_text.replace('won\\'t', 'will not').replace('n\\'t', ' not').replace(' not ', ' not')\n",
        "        return final_text\n",
        "\n",
        "    def removeStopWords(self, text):\n",
        "        return ' '.join([word for word in text.split() if word not in cachedStopWords_en])\n",
        "\n",
        "    def removePunctuation(self, text, punctuation=punctuation):\n",
        "        for c in punctuation:\n",
        "            text = text.replace(c, ' ')\n",
        "        return text\n",
        "\n",
        "    def replaceUTF8Char(self, text, specialchars=specialchar_dic):\n",
        "        def replace(match):\n",
        "            return specialchars[match.group(0)]\n",
        "        return specialchar_re.sub(replace, text)\n",
        "\n",
        "    def createCorpus(self, text, remove_punctuation=True, remove_stopwords=True, apply_FE=True):\n",
        "        if pd.isna(text):\n",
        "            text = \"\"\n",
        "        corpus = []\n",
        "        try:\n",
        "            text = self.replaceUTF8Char(text).replace(\"\\n\", \" \")\n",
        "            doc = nlp(text)\n",
        "            processed_text = ' '.join([t.lemma_ if t.lemma_ != '-PRON-' else t.text if not t.ent_type_ else t.text for t in doc])\n",
        "            processed_text = processed_text.replace(\"\\s\\s+\", ' ')\n",
        "            doc = nlp(processed_text.lower())\n",
        "            rawText = not (remove_punctuation or remove_stopwords or apply_FE)\n",
        "            for sentence in doc.sents:\n",
        "                sent = str(sentence.text)\n",
        "                if len(sent) == 0:\n",
        "                    continue\n",
        "                if not rawText:\n",
        "                    if apply_FE:\n",
        "                        sent = self.applyFE(text=sent)\n",
        "                    if remove_punctuation:\n",
        "                        sent = self.removePunctuation(text=sent)\n",
        "                    if remove_stopwords:\n",
        "                        sent = self.removeStopWords(text=sent)\n",
        "                sent = sent.lower().split()\n",
        "                if sent:\n",
        "                    corpus.append(sent)\n",
        "        except Exception as exp:\n",
        "            print('exception=', str(exp))\n",
        "            print('text=', text)\n",
        "        return corpus\n",
        "\n",
        "class WordEmbeddings:\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=cpu_count(), sg=0):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components)\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=cpu_count(), sg=0):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "def processElement(elem):\n",
        "    idx, text = elem  # Unpack as (index, text)\n",
        "    tkn = Tokenization()\n",
        "    text = tkn.createCorpus(text, remove_stopwords=False)\n",
        "    return idx, text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    file_path = '/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv'\n",
        "    df = pd.read_csv(file_path, encoding='latin-1')\n",
        "    print(\"Dataset Head:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset Info:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Label mapping\n",
        "    label2id = {\n",
        "        'mostly true': 0,\n",
        "        'mixture of true and false': 1,\n",
        "        'no factual content': 1,\n",
        "        'mostly false': 1\n",
        "    }\n",
        "    df['Rating'] = df['Rating'].map(label2id)\n",
        "    y = df['Rating'].astype(int).to_numpy()\n",
        "    sio.savemat('labels.mat', {'y': y})\n",
        "\n",
        "    # Network features\n",
        "    network_cols = ['share_count', 'reaction_count', 'comment_count']\n",
        "    X_network = df[network_cols].fillna(0).to_numpy()\n",
        "    scaler_std = StandardScaler()\n",
        "    X_net_std = scaler_std.fit_transform(X_network)\n",
        "    X_net_std = X_net_std.reshape((X_net_std.shape[0], 1, X_net_std.shape[1]))\n",
        "    print(\"\\nX_network shape:\", X_network.shape)\n",
        "    print(\"X_net_std shape:\", X_net_std.shape)\n",
        "    sio.savemat('network.mat', {'X_net_std': X_net_std})\n",
        "\n",
        "    # Tokenization\n",
        "    print(\"\\nStart Tokenization\")\n",
        "    # Use row indices (0 to 2281) paired with Context Post\n",
        "    texts = list(enumerate(df['Context Post'].tolist()))\n",
        "    corpus = [None] * len(texts)\n",
        "    no_threads = cpu_count() - 1\n",
        "    with ProcessPoolExecutor(max_workers=no_threads) as worker:\n",
        "        for result in worker.map(processElement, texts):\n",
        "            if result:\n",
        "                corpus[result[0]] = result[1]\n",
        "\n",
        "    print(\"Corpus sample (first 5):\")\n",
        "    for idx, doc in enumerate(corpus[:5]):\n",
        "        print(idx, doc)\n",
        "\n",
        "    # Word Embeddings\n",
        "    print(\"\\nStart Document Tokenization\")\n",
        "    we = WordEmbeddings(corpus)\n",
        "    documents = we.prepareDocuments()\n",
        "    vocabulary_size = we.no_words\n",
        "    max_size = we.max_size\n",
        "    print(\"Vocabulary size:\", vocabulary_size)\n",
        "    print(\"Max Document size:\", max_size)\n",
        "\n",
        "    X_docs = []\n",
        "    for document in documents:\n",
        "        doc_size = len(document)\n",
        "        X_docs.append(document + [0] * (max_size - doc_size))\n",
        "    X_docs = np.array(X_docs)\n",
        "    sio.savemat('corpus.mat', {'X': X_docs})\n",
        "\n",
        "    print(\"Start W2V CBOW\")\n",
        "    w2v_cbow = we.word2vecEmbedding(sg=0)\n",
        "    sio.savemat('w2v_cbow.mat', {'w2v_cbow': w2v_cbow})\n",
        "\n",
        "    print(\"Start W2V SG\")\n",
        "    w2v_sg = we.word2vecEmbedding(sg=1)\n",
        "    sio.savemat('w2v_sg.mat', {'w2v_sg': w2v_sg})\n",
        "\n",
        "    print(\"Start FT CBOW\")\n",
        "    ft_cbow = we.word2FastTextEmbeddings(sg=0)\n",
        "    sio.savemat('ft_cbow.mat', {'ft_cbow': ft_cbow})\n",
        "\n",
        "    print(\"Start FT SG\")\n",
        "    ft_sg = we.word2FastTextEmbeddings(sg=1)\n",
        "    sio.savemat('ft_sg.mat', {'ft_sg': ft_sg})\n",
        "\n",
        "    print(\"Start GLOVE\")\n",
        "    glove = we.word2GloVeEmbedding()\n",
        "    sio.savemat('glove.mat', {'glove': glove})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8obA6Gw5sU6",
        "outputId": "8ec4f188-a58a-41cc-f183-8322a7f82c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "     account_id       post_id    Category               Page  \\\n",
            "0  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "2  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "3  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "4  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "\n",
            "                                            Post URL Date Published Post Type  \\\n",
            "0  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "1  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "2  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "3  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "4  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "\n",
            "               Rating Debate  share_count  reaction_count  comment_count  \\\n",
            "0  no factual content    NaN          NaN           146.0           15.0   \n",
            "1         mostly true    NaN          1.0            33.0           34.0   \n",
            "2         mostly true    NaN         34.0            63.0           27.0   \n",
            "3         mostly true    NaN         35.0           170.0           86.0   \n",
            "4         mostly true    NaN        568.0          3188.0         2815.0   \n",
            "\n",
            "                                        Context Post  \n",
            "0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1  Can either candidate move the needle in the de...  \n",
            "2  BREAKING: Ahmad Rahami, 28, wanted in connecti...  \n",
            "3  Donald J. Trump: &quot;Do we have a choice? Lo...  \n",
            "4  WATCH LIVE: Hillary Clinton holds news confere...  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2282 entries, 0 to 2281\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   account_id      2282 non-null   float64\n",
            " 1   post_id         2282 non-null   float64\n",
            " 2   Category        2282 non-null   object \n",
            " 3   Page            2282 non-null   object \n",
            " 4   Post URL        2282 non-null   object \n",
            " 5   Date Published  2282 non-null   object \n",
            " 6   Post Type       2282 non-null   object \n",
            " 7   Rating          2282 non-null   object \n",
            " 8   Debate          298 non-null    object \n",
            " 9   share_count     2212 non-null   float64\n",
            " 10  reaction_count  2280 non-null   float64\n",
            " 11  comment_count   2280 non-null   float64\n",
            " 12  Context Post    2282 non-null   object \n",
            "dtypes: float64(5), object(8)\n",
            "memory usage: 231.9+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "account_id           0\n",
            "post_id              0\n",
            "Category             0\n",
            "Page                 0\n",
            "Post URL             0\n",
            "Date Published       0\n",
            "Post Type            0\n",
            "Rating               0\n",
            "Debate            1984\n",
            "share_count         70\n",
            "reaction_count       2\n",
            "comment_count        2\n",
            "Context Post         0\n",
            "dtype: int64\n",
            "\n",
            "X_network shape: (2282, 3)\n",
            "X_net_std shape: (2282, 1, 3)\n",
            "\n",
            "Start Tokenization\n",
            "Corpus sample (first 5):\n",
            "0 [['watch', 'quot', 'jeb', 'exclamation', 'point', 'quot', 'jeb', 'bush', 'now', 'drive', 'around', 'selina', 'meyer', 'in', 'the', 'opening', 'intro', 'to', 'the', 'emmys', 'with', 'jimmy', 'kimmel']]\n",
            "1 [['can', 'either', 'candidate', 'move', 'the', 'needle', 'in', 'the', 'debate'], ['an', 'abc', 'news', 'review', 'of', 'datum', 'since', '1960', 'suggest', 'that', 'past', 'debate', 'have', 'almost', 'never', 'directly', 'and']]\n",
            "2 [['breaking', 'ahmad', 'rahami', '28', 'want', 'in', 'connection', 'with', 'nyc', 'bombing', 'say', 'nypd']]\n",
            "3 [['donald', 'j', 'trump', 'quot', 'do', 'we', 'have', 'a', 'choice'], ['look', 'what', '039', 'go', 'on'], ['do', 'we', 'really', 'have', 'a', 'choice'], ['we', '039', 're', 'try', 'to', 'be', 'so', 'politically', 'correct', 'in', 'our', 'country', 'and']]\n",
            "4 [['watch', 'live', 'hillary', 'clinton', 'hold', 'news', 'conference', 'in', 'white', 'plains', 'ny'], ['http', 'abcn', 'ws', '2cyazvp']]\n",
            "\n",
            "Start Document Tokenization\n",
            "Vocabulary size: 4023\n",
            "Max Document size: 117\n",
            "Start W2V CBOW\n",
            "Start W2V SG\n",
            "Start FT CBOW\n",
            "Start FT SG\n",
            "Start GLOVE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 117.3983"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset Size: 2282 samples.\n",
        "\n",
        "- Network Features: X_net_std has shape (2282, 1, 3) (from share_count, reaction_count, comment_count).\n",
        "\n",
        "- Text Data: X_docs will have shape (2282, 117) (max document size is 117).\n",
        "\n",
        "- Vocabulary Size: 4023 unique words (including padding token 0).\n",
        "\n",
        "- Embeddings: Successfully generated w2v_cbow, w2v_sg, ft_cbow, ft_sg, and glove, each with 128 dimensions (default no_components).\n",
        "\n"
      ],
      "metadata": {
        "id": "2BoiXHOL7ll_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Script"
      ],
      "metadata": {
        "id": "Au4jSj444VEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlJaMAFn8tkL",
        "outputId": "d122ad7a-4044-4b60-bd8b-35d1ebeaae8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy import io as sio\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, Concatenate, Conv1D, Flatten, MaxPooling1D, Reshape\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 2\n",
        "batch_size = 256\n",
        "epochs_n = 50\n",
        "units = 128\n",
        "filters = int(units / 2)\n",
        "no_attributes_lstm = units\n",
        "kernel_size_lstm = int(no_attributes_lstm / 2)\n",
        "no_attributes_bilstm = int(units * 2)\n",
        "kernel_size_bilstm = int(no_attributes_bilstm / 2)\n",
        "\n",
        "execution = {}\n",
        "accuracies = {}\n",
        "precisions = {}\n",
        "recalls = {}\n",
        "\n",
        "def evaluate(y_test, y_pred, modelName='LSTM', wordemb='w2v_sg', iters=0):\n",
        "    y_pred_norm = []\n",
        "    for elem in y_pred:\n",
        "        line = [0] * len(elem)\n",
        "        try:\n",
        "            elem[np.isnan(elem)] = 0\n",
        "            line[elem.tolist().index(max(elem.tolist()))] = 1\n",
        "        except:\n",
        "            print(\"Error for getting predicted class\")\n",
        "            print(elem.tolist())\n",
        "            line[random.randint(0, len(elem)-1)] = 1\n",
        "        y_pred_norm.append(line)\n",
        "    y_p = np.argmax(np.array(y_pred_norm), 1)\n",
        "    y_t = np.argmax(np.array(y_test), 1)\n",
        "    accuracy = accuracy_score(y_t, y_p)\n",
        "    accuracies[wordemb][modelName].append(accuracy)\n",
        "    precision = precision_score(y_t, y_p, average='weighted')\n",
        "    precisions[wordemb][modelName].append(precision)\n",
        "    recall = recall_score(y_t, y_p, average='weighted')\n",
        "    recalls[wordemb][modelName].append(recall)\n",
        "    print(f\"{modelName} {wordemb} Accuracy {accuracy:.4f}\")\n",
        "    print(f\"{modelName} {wordemb} Precision {precision:.4f}\")\n",
        "    print(f\"{modelName} {wordemb} Recall {recall:.4f}\")\n",
        "    return y_p, y_t\n",
        "\n",
        "# Model definitions with corrected shapes\n",
        "def modelContentNetworkLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')  # Tuple (117,)\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-00CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Reshape((no_attributes_lstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_lstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-01CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-10CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(input_net)\n",
        "    model_net = Reshape((no_attributes_lstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_lstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"LSTM-11CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"LSTM-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_lstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"LSTM-CNN-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-00CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Reshape((no_attributes_bilstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_bilstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-01CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-10CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentNetworkBiLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    input_net = Input(shape=(1, 3), name='NETS_INPUT')\n",
        "    model_net = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(input_net)\n",
        "    model_net = Reshape((no_attributes_bilstm, 1))(model_net)\n",
        "    model_net = Conv1D(filters=filters, kernel_size=kernel_size_bilstm, activation='relu')(model_net)\n",
        "    model_net = MaxPooling1D()(model_net)\n",
        "    model_net = Flatten()(model_net)\n",
        "    combined = Concatenate()([model_docs, model_net])\n",
        "    output = Dense(units=num_classes, activation='softmax')(combined)\n",
        "    model = Model(inputs=[input_docs, input_net], outputs=output, name=\"BiLSTM-11CNN-ContentNets\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=[X_train_docs, X_train_net], y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=([X_val_docs, X_val_net], y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict([X_test_docs, X_test_net], verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentBiLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"BiLSTM-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "def modelContentBiLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx):\n",
        "    input_docs = Input(shape=(X_train_docs.shape[1],), name='DOCS_INPUT')\n",
        "    model_docs = Embedding(input_dim=4023, output_dim=units, weights=[w2v], trainable=False)(input_docs)\n",
        "    model_docs = Bidirectional(LSTM(units=units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(model_docs)\n",
        "    model_docs = Conv1D(filters=int(filters/2), kernel_size=int(kernel_size_bilstm/2), activation='relu')(model_docs)\n",
        "    model_docs = MaxPooling1D()(model_docs)\n",
        "    model_docs = Flatten()(model_docs)\n",
        "    output = Dense(units=num_classes, activation='softmax')(model_docs)\n",
        "    model = Model(inputs=input_docs, outputs=output, name=\"BiLSTM-CNN-Content\")\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    start_time = time.time()\n",
        "    model.fit(x=X_train_docs, y=y_train, epochs=epochs_n, verbose=1,\n",
        "              validation_data=(X_val_docs, y_val), batch_size=batch_size, callbacks=[es])\n",
        "    end_time = time.time()\n",
        "    y_pred = model.predict(X_test_docs, verbose=0)\n",
        "    evaluate(y_test, y_pred, modelName=model.name, wordemb=wordemb, iters=idx)\n",
        "    exc_time = end_time - start_time\n",
        "    execution[wordemb][model.name].append(exc_time)\n",
        "    print(f\"Time taken to train: {exc_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    y = sio.loadmat('labels.mat')['y'][0]\n",
        "    X_net_std = sio.loadmat('network.mat')['X_net_std']\n",
        "    X_docs = sio.loadmat('corpus.mat')['X']\n",
        "    print(\"y shape:\", y.shape)\n",
        "    print(\"X_net_std shape:\", X_net_std.shape)\n",
        "    print(\"X_docs shape:\", X_docs.shape)\n",
        "\n",
        "    # Verify vocabulary size\n",
        "    vocabulary_size = 4023\n",
        "    max_size = 117\n",
        "    print(f\"Vocabulary size: {vocabulary_size}, Max size: {max_size}\")\n",
        "\n",
        "    embedding_types = ['w2v_cbow', 'w2v_sg', 'ft_cbow', 'ft_sg', 'glove']\n",
        "    models = [\n",
        "        \"LSTM-00CNN-ContentNets\", \"LSTM-01CNN-ContentNets\", \"LSTM-10CNN-ContentNets\", \"LSTM-11CNN-ContentNets\",\n",
        "        \"LSTM-Content\", \"LSTM-CNN-Content\",\n",
        "        \"BiLSTM-00CNN-ContentNets\", \"BiLSTM-01CNN-ContentNets\", \"BiLSTM-10CNN-ContentNets\", \"BiLSTM-11CNN-ContentNets\",\n",
        "        \"BiLSTM-Content\", \"BiLSTM-CNN-Content\"\n",
        "    ]\n",
        "\n",
        "    for wordemb in embedding_types:\n",
        "        accuracies[wordemb] = {model: [] for model in models}\n",
        "        precisions[wordemb] = {model: [] for model in models}\n",
        "        recalls[wordemb] = {model: [] for model in models}\n",
        "        execution[wordemb] = {model: [] for model in models}\n",
        "\n",
        "        w2v = sio.loadmat(f'{wordemb}.mat')[wordemb]\n",
        "        print(f\"Loaded {wordemb} shape: {w2v.shape}\")\n",
        "\n",
        "        for idx in range(5):\n",
        "            X_train_docs, X_test_docs, X_train_net, X_test_net, y_train, y_test = train_test_split(\n",
        "                X_docs, X_net_std, y, test_size=0.30, shuffle=True, stratify=y)\n",
        "            X_train_docs, X_val_docs, X_train_net, X_val_net, y_train, y_val = train_test_split(\n",
        "                X_train_docs, X_train_net, y_train, test_size=0.20, shuffle=True, stratify=y_train)\n",
        "            y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "            y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "            y_val = to_categorical(y_val, num_classes=num_classes)\n",
        "\n",
        "            print(f\"\\nIteration {idx+1} - Split shapes:\")\n",
        "            print(\"X_train_docs:\", X_train_docs.shape, \"X_val_docs:\", X_val_docs.shape, \"X_test_docs:\", X_test_docs.shape)\n",
        "            print(\"X_train_net:\", X_train_net.shape, \"X_val_net:\", X_val_net.shape, \"X_test_net:\", X_test_net.shape)\n",
        "            print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "            print(f\"\\nRunning models with {wordemb} embedding:\")\n",
        "            modelContentLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentBiLSTM(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentBiLSTMCNN(X_train_docs, X_val_docs, X_test_docs, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_00CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_01CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_10CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "            modelContentNetworkBiLSTM_11CNN(X_train_docs, X_val_docs, X_test_docs, X_train_net, X_val_net, X_test_net, y_train, y_val, y_test, w2v, num_classes, wordemb, idx)\n",
        "\n",
        "        print(f\"\\nSummary for {wordemb}:\")\n",
        "        for model in models:\n",
        "            print(f\"{model} {wordemb} ACCURACY {np.mean(accuracies[wordemb][model]):.4f} ± {np.std(accuracies[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} PRECISION {np.mean(precisions[wordemb][model]):.4f} ± {np.std(precisions[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} RECALL {np.mean(recalls[wordemb][model]):.4f} ± {np.std(recalls[wordemb][model]):.4f}\")\n",
        "            print(f\"{model} {wordemb} EXECUTION TIME {np.mean(execution[wordemb][model]):.2f} ± {np.std(execution[wordemb][model]):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ9z0Kf_8qSV",
        "outputId": "59d51b39-3a82-465c-e89d-40e458f28149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape: (2282,)\n",
            "X_net_std shape: (2282, 1, 3)\n",
            "X_docs shape: (2282, 117)\n",
            "Vocabulary size: 4023, Max size: 117\n",
            "Loaded w2v_cbow shape: (4023, 128)\n",
            "\n",
            "Iteration 1 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.5475 - loss: 0.6085 - val_accuracy: 0.7312 - val_loss: 0.5077\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 349ms/step - accuracy: 0.7363 - loss: 0.4956 - val_accuracy: 0.7375 - val_loss: 0.4836\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 349ms/step - accuracy: 0.7354 - loss: 0.4846 - val_accuracy: 0.7312 - val_loss: 0.4724\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 618ms/step - accuracy: 0.7449 - loss: 0.4532 - val_accuracy: 0.7500 - val_loss: 0.4619\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - accuracy: 0.7381 - loss: 0.4676 - val_accuracy: 0.7469 - val_loss: 0.4602\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 345ms/step - accuracy: 0.7368 - loss: 0.4772 - val_accuracy: 0.7531 - val_loss: 0.4564\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.7412 - loss: 0.4653 - val_accuracy: 0.7531 - val_loss: 0.4570\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.7500 - loss: 0.4760 - val_accuracy: 0.7469 - val_loss: 0.4610\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 627ms/step - accuracy: 0.7457 - loss: 0.4619 - val_accuracy: 0.7469 - val_loss: 0.4593\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348ms/step - accuracy: 0.7382 - loss: 0.4509 - val_accuracy: 0.7469 - val_loss: 0.4581\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - accuracy: 0.7357 - loss: 0.4678 - val_accuracy: 0.7500 - val_loss: 0.4575\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - accuracy: 0.7216 - loss: 0.4703 - val_accuracy: 0.7500 - val_loss: 0.4564\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 346ms/step - accuracy: 0.7374 - loss: 0.4796 - val_accuracy: 0.7500 - val_loss: 0.4603\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7461 - loss: 0.4506 - val_accuracy: 0.7500 - val_loss: 0.4589\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348ms/step - accuracy: 0.7454 - loss: 0.4648 - val_accuracy: 0.7531 - val_loss: 0.4594\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - accuracy: 0.7345 - loss: 0.4641 - val_accuracy: 0.7469 - val_loss: 0.4602\n",
            "Epoch 16: early stopping\n",
            "LSTM-Content w2v_cbow Accuracy 0.7650\n",
            "LSTM-Content w2v_cbow Precision 0.7799\n",
            "LSTM-Content w2v_cbow Recall 0.7650\n",
            "Time taken to train: 47.74 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 573ms/step - accuracy: 0.5752 - loss: 0.6073 - val_accuracy: 0.7312 - val_loss: 0.5257\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.7233 - loss: 0.5302 - val_accuracy: 0.7312 - val_loss: 0.4952\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.7305 - loss: 0.5045 - val_accuracy: 0.7312 - val_loss: 0.4817\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - accuracy: 0.7417 - loss: 0.4738 - val_accuracy: 0.7437 - val_loss: 0.4693\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 532ms/step - accuracy: 0.7319 - loss: 0.4747 - val_accuracy: 0.7469 - val_loss: 0.4649\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 393ms/step - accuracy: 0.7408 - loss: 0.4682 - val_accuracy: 0.7563 - val_loss: 0.4604\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - accuracy: 0.7453 - loss: 0.4591 - val_accuracy: 0.7563 - val_loss: 0.4607\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7454 - loss: 0.4609 - val_accuracy: 0.7531 - val_loss: 0.4580\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632ms/step - accuracy: 0.7409 - loss: 0.4726 - val_accuracy: 0.7531 - val_loss: 0.4599\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - accuracy: 0.7225 - loss: 0.4743 - val_accuracy: 0.7500 - val_loss: 0.4608\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7416 - loss: 0.4730 - val_accuracy: 0.7500 - val_loss: 0.4635\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - accuracy: 0.7386 - loss: 0.4453 - val_accuracy: 0.7469 - val_loss: 0.4632\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.7244 - loss: 0.4903 - val_accuracy: 0.7563 - val_loss: 0.4635\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687ms/step - accuracy: 0.7551 - loss: 0.4558 - val_accuracy: 0.7500 - val_loss: 0.4683\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.7479 - loss: 0.4555 - val_accuracy: 0.7500 - val_loss: 0.4670\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.7295 - loss: 0.4636 - val_accuracy: 0.7500 - val_loss: 0.4631\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - accuracy: 0.7369 - loss: 0.4606 - val_accuracy: 0.7500 - val_loss: 0.4638\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - accuracy: 0.7366 - loss: 0.4513 - val_accuracy: 0.7469 - val_loss: 0.4631\n",
            "Epoch 18: early stopping\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7343\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.6889\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7343\n",
            "Time taken to train: 51.50 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 582ms/step - accuracy: 0.5769 - loss: 0.5955 - val_accuracy: 0.7312 - val_loss: 0.5349\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 576ms/step - accuracy: 0.7425 - loss: 0.4887 - val_accuracy: 0.7531 - val_loss: 0.4949\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 485ms/step - accuracy: 0.7231 - loss: 0.5000 - val_accuracy: 0.7375 - val_loss: 0.4761\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 413ms/step - accuracy: 0.7360 - loss: 0.4858 - val_accuracy: 0.7688 - val_loss: 0.4555\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7514 - loss: 0.4624 - val_accuracy: 0.7688 - val_loss: 0.4531\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 636ms/step - accuracy: 0.7491 - loss: 0.4644 - val_accuracy: 0.7625 - val_loss: 0.4565\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365ms/step - accuracy: 0.7341 - loss: 0.4788 - val_accuracy: 0.7688 - val_loss: 0.4536\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7498 - loss: 0.4473 - val_accuracy: 0.7750 - val_loss: 0.4513\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.7411 - loss: 0.4577 - val_accuracy: 0.7906 - val_loss: 0.4490\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 432ms/step - accuracy: 0.7501 - loss: 0.4596 - val_accuracy: 0.7625 - val_loss: 0.4483\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 628ms/step - accuracy: 0.7631 - loss: 0.4469 - val_accuracy: 0.7688 - val_loss: 0.4473\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.7430 - loss: 0.4570 - val_accuracy: 0.7656 - val_loss: 0.4464\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - accuracy: 0.7501 - loss: 0.4554 - val_accuracy: 0.7656 - val_loss: 0.4457\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7559 - loss: 0.4516 - val_accuracy: 0.7656 - val_loss: 0.4454\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 612ms/step - accuracy: 0.7656 - loss: 0.4501 - val_accuracy: 0.7656 - val_loss: 0.4460\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 373ms/step - accuracy: 0.7646 - loss: 0.4553 - val_accuracy: 0.7625 - val_loss: 0.4462\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.7396 - loss: 0.4442 - val_accuracy: 0.7625 - val_loss: 0.4454\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 416ms/step - accuracy: 0.7671 - loss: 0.4380 - val_accuracy: 0.7594 - val_loss: 0.4456\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 529ms/step - accuracy: 0.7440 - loss: 0.4669 - val_accuracy: 0.7656 - val_loss: 0.4453\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - accuracy: 0.7488 - loss: 0.4544 - val_accuracy: 0.7656 - val_loss: 0.4454\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.7353 - loss: 0.4667 - val_accuracy: 0.7625 - val_loss: 0.4464\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7484 - loss: 0.4348 - val_accuracy: 0.7656 - val_loss: 0.4464\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7551 - loss: 0.4386 - val_accuracy: 0.7656 - val_loss: 0.4456\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 807ms/step - accuracy: 0.7622 - loss: 0.4437 - val_accuracy: 0.7594 - val_loss: 0.4443\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7649 - loss: 0.4267 - val_accuracy: 0.7594 - val_loss: 0.4442\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.7611 - loss: 0.4388 - val_accuracy: 0.7594 - val_loss: 0.4443\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7561 - loss: 0.4314 - val_accuracy: 0.7625 - val_loss: 0.4443\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 753ms/step - accuracy: 0.7636 - loss: 0.4370 - val_accuracy: 0.7594 - val_loss: 0.4468\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375ms/step - accuracy: 0.7722 - loss: 0.4235 - val_accuracy: 0.7625 - val_loss: 0.4456\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7504 - loss: 0.4307 - val_accuracy: 0.7625 - val_loss: 0.4445\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 413ms/step - accuracy: 0.7629 - loss: 0.4283 - val_accuracy: 0.7531 - val_loss: 0.4437\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 527ms/step - accuracy: 0.7574 - loss: 0.4323 - val_accuracy: 0.7563 - val_loss: 0.4461\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.7659 - loss: 0.4333 - val_accuracy: 0.7625 - val_loss: 0.4438\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7677 - loss: 0.4255 - val_accuracy: 0.7625 - val_loss: 0.4438\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7572 - loss: 0.4338 - val_accuracy: 0.7594 - val_loss: 0.4465\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.7623 - loss: 0.4249 - val_accuracy: 0.7625 - val_loss: 0.4457\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 596ms/step - accuracy: 0.7650 - loss: 0.4316 - val_accuracy: 0.7656 - val_loss: 0.4464\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7557 - loss: 0.4256 - val_accuracy: 0.7594 - val_loss: 0.4455\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7555 - loss: 0.4399 - val_accuracy: 0.7531 - val_loss: 0.4457\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7625 - loss: 0.4262 - val_accuracy: 0.7594 - val_loss: 0.4462\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7534 - loss: 0.4420 - val_accuracy: 0.7563 - val_loss: 0.4484\n",
            "Epoch 41: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7518\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7235\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7518\n",
            "Time taken to train: 126.14 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 958ms/step - accuracy: 0.6993 - loss: 0.5818 - val_accuracy: 0.7437 - val_loss: 0.4951\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7205 - loss: 0.4966 - val_accuracy: 0.7437 - val_loss: 0.4705\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7324 - loss: 0.4812 - val_accuracy: 0.7563 - val_loss: 0.4575\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7475 - loss: 0.4540 - val_accuracy: 0.7625 - val_loss: 0.4506\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7350 - loss: 0.4557 - val_accuracy: 0.7688 - val_loss: 0.4502\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7326 - loss: 0.4824 - val_accuracy: 0.7625 - val_loss: 0.4469\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 512ms/step - accuracy: 0.7457 - loss: 0.4563 - val_accuracy: 0.7625 - val_loss: 0.4515\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7492 - loss: 0.4551 - val_accuracy: 0.7750 - val_loss: 0.4479\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7396 - loss: 0.4594 - val_accuracy: 0.7594 - val_loss: 0.4458\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7511 - loss: 0.4418 - val_accuracy: 0.7594 - val_loss: 0.4470\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7584 - loss: 0.4506 - val_accuracy: 0.7688 - val_loss: 0.4458\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 614ms/step - accuracy: 0.7544 - loss: 0.4420 - val_accuracy: 0.7594 - val_loss: 0.4455\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - accuracy: 0.7490 - loss: 0.4470 - val_accuracy: 0.7656 - val_loss: 0.4438\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.7541 - loss: 0.4391 - val_accuracy: 0.7688 - val_loss: 0.4433\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7528 - loss: 0.4600 - val_accuracy: 0.7656 - val_loss: 0.4427\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 493ms/step - accuracy: 0.7511 - loss: 0.4477 - val_accuracy: 0.7625 - val_loss: 0.4449\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 543ms/step - accuracy: 0.7582 - loss: 0.4328 - val_accuracy: 0.7625 - val_loss: 0.4429\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.7403 - loss: 0.4293 - val_accuracy: 0.7656 - val_loss: 0.4428\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7499 - loss: 0.4312 - val_accuracy: 0.7688 - val_loss: 0.4422\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - accuracy: 0.7630 - loss: 0.4377 - val_accuracy: 0.7656 - val_loss: 0.4412\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 691ms/step - accuracy: 0.7608 - loss: 0.4409 - val_accuracy: 0.7625 - val_loss: 0.4407\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.7563 - loss: 0.4268 - val_accuracy: 0.7625 - val_loss: 0.4414\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7490 - loss: 0.4423 - val_accuracy: 0.7625 - val_loss: 0.4412\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7586 - loss: 0.4368 - val_accuracy: 0.7656 - val_loss: 0.4408\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 506ms/step - accuracy: 0.7554 - loss: 0.4375 - val_accuracy: 0.7625 - val_loss: 0.4407\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 538ms/step - accuracy: 0.7528 - loss: 0.4375 - val_accuracy: 0.7625 - val_loss: 0.4407\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7602 - loss: 0.4226 - val_accuracy: 0.7625 - val_loss: 0.4408\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 407ms/step - accuracy: 0.7799 - loss: 0.4091 - val_accuracy: 0.7625 - val_loss: 0.4409\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7690 - loss: 0.4194 - val_accuracy: 0.7594 - val_loss: 0.4386\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 472ms/step - accuracy: 0.7658 - loss: 0.4244 - val_accuracy: 0.7563 - val_loss: 0.4395\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 532ms/step - accuracy: 0.7610 - loss: 0.4321 - val_accuracy: 0.7594 - val_loss: 0.4397\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7645 - loss: 0.4316 - val_accuracy: 0.7688 - val_loss: 0.4413\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7259 - loss: 0.4352 - val_accuracy: 0.7594 - val_loss: 0.4424\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7667 - loss: 0.4244 - val_accuracy: 0.7625 - val_loss: 0.4421\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 755ms/step - accuracy: 0.7607 - loss: 0.4265 - val_accuracy: 0.7625 - val_loss: 0.4456\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7605 - loss: 0.4207 - val_accuracy: 0.7594 - val_loss: 0.4472\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.7666 - loss: 0.4236 - val_accuracy: 0.7625 - val_loss: 0.4437\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7493 - loss: 0.4327 - val_accuracy: 0.7688 - val_loss: 0.4413\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7731 - loss: 0.4098 - val_accuracy: 0.7594 - val_loss: 0.4466\n",
            "Epoch 39: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7606\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7375\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7606\n",
            "Time taken to train: 109.36 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 591ms/step - accuracy: 0.7174 - loss: 0.5929 - val_accuracy: 0.7312 - val_loss: 0.4971\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 388ms/step - accuracy: 0.7266 - loss: 0.4879 - val_accuracy: 0.7375 - val_loss: 0.4856\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.7393 - loss: 0.4742 - val_accuracy: 0.7500 - val_loss: 0.4659\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7299 - loss: 0.4787 - val_accuracy: 0.7625 - val_loss: 0.4627\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7455 - loss: 0.4879 - val_accuracy: 0.7625 - val_loss: 0.4535\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 684ms/step - accuracy: 0.7475 - loss: 0.4737 - val_accuracy: 0.7625 - val_loss: 0.4527\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375ms/step - accuracy: 0.7395 - loss: 0.4546 - val_accuracy: 0.7625 - val_loss: 0.4488\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406ms/step - accuracy: 0.7577 - loss: 0.4502 - val_accuracy: 0.7719 - val_loss: 0.4506\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7612 - loss: 0.4505 - val_accuracy: 0.7656 - val_loss: 0.4496\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.7639 - loss: 0.4474 - val_accuracy: 0.7656 - val_loss: 0.4469\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 570ms/step - accuracy: 0.7503 - loss: 0.4431 - val_accuracy: 0.7656 - val_loss: 0.4480\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7549 - loss: 0.4542 - val_accuracy: 0.7656 - val_loss: 0.4499\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7496 - loss: 0.4453 - val_accuracy: 0.7594 - val_loss: 0.4501\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7569 - loss: 0.4470 - val_accuracy: 0.7563 - val_loss: 0.4458\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 685ms/step - accuracy: 0.7606 - loss: 0.4319 - val_accuracy: 0.7656 - val_loss: 0.4464\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 407ms/step - accuracy: 0.7629 - loss: 0.4315 - val_accuracy: 0.7688 - val_loss: 0.4478\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7691 - loss: 0.4341 - val_accuracy: 0.7656 - val_loss: 0.4435\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.7490 - loss: 0.4509 - val_accuracy: 0.7688 - val_loss: 0.4454\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7567 - loss: 0.4337 - val_accuracy: 0.7656 - val_loss: 0.4463\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 686ms/step - accuracy: 0.7494 - loss: 0.4326 - val_accuracy: 0.7594 - val_loss: 0.4476\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365ms/step - accuracy: 0.7565 - loss: 0.4357 - val_accuracy: 0.7594 - val_loss: 0.4488\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.7566 - loss: 0.4407 - val_accuracy: 0.7688 - val_loss: 0.4528\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7758 - loss: 0.4100 - val_accuracy: 0.7563 - val_loss: 0.4550\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7390 - loss: 0.4421 - val_accuracy: 0.7625 - val_loss: 0.4548\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 647ms/step - accuracy: 0.7636 - loss: 0.4221 - val_accuracy: 0.7594 - val_loss: 0.4499\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 373ms/step - accuracy: 0.7628 - loss: 0.4080 - val_accuracy: 0.7563 - val_loss: 0.4570\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7673 - loss: 0.4203 - val_accuracy: 0.7563 - val_loss: 0.4536\n",
            "Epoch 27: early stopping\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7547\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7287\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7547\n",
            "Time taken to train: 81.06 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 617ms/step - accuracy: 0.5621 - loss: 0.6150 - val_accuracy: 0.7312 - val_loss: 0.5331\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 696ms/step - accuracy: 0.7374 - loss: 0.4816 - val_accuracy: 0.7375 - val_loss: 0.5004\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - accuracy: 0.7503 - loss: 0.4844 - val_accuracy: 0.7375 - val_loss: 0.4751\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.7376 - loss: 0.4711 - val_accuracy: 0.8031 - val_loss: 0.4553\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7429 - loss: 0.4572 - val_accuracy: 0.7937 - val_loss: 0.4507\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7521 - loss: 0.4451 - val_accuracy: 0.8031 - val_loss: 0.4471\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 627ms/step - accuracy: 0.7422 - loss: 0.4587 - val_accuracy: 0.7688 - val_loss: 0.4451\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 434ms/step - accuracy: 0.7605 - loss: 0.4404 - val_accuracy: 0.7656 - val_loss: 0.4437\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7560 - loss: 0.4473 - val_accuracy: 0.7625 - val_loss: 0.4460\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7599 - loss: 0.4397 - val_accuracy: 0.7656 - val_loss: 0.4468\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7452 - loss: 0.4624 - val_accuracy: 0.7625 - val_loss: 0.4462\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 370ms/step - accuracy: 0.7670 - loss: 0.4380 - val_accuracy: 0.7688 - val_loss: 0.4446\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7678 - loss: 0.4387 - val_accuracy: 0.7656 - val_loss: 0.4457\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7589 - loss: 0.4421 - val_accuracy: 0.7656 - val_loss: 0.4435\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 485ms/step - accuracy: 0.7601 - loss: 0.4420 - val_accuracy: 0.7594 - val_loss: 0.4449\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 556ms/step - accuracy: 0.7685 - loss: 0.4426 - val_accuracy: 0.7625 - val_loss: 0.4428\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - accuracy: 0.7608 - loss: 0.4541 - val_accuracy: 0.7594 - val_loss: 0.4441\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7525 - loss: 0.4409 - val_accuracy: 0.7656 - val_loss: 0.4477\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7678 - loss: 0.4265 - val_accuracy: 0.7625 - val_loss: 0.4456\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7565 - loss: 0.4335 - val_accuracy: 0.7688 - val_loss: 0.4429\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 718ms/step - accuracy: 0.7553 - loss: 0.4411 - val_accuracy: 0.7688 - val_loss: 0.4422\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7577 - loss: 0.4420 - val_accuracy: 0.7688 - val_loss: 0.4453\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.7376 - loss: 0.4371 - val_accuracy: 0.7625 - val_loss: 0.4424\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7563 - loss: 0.4417 - val_accuracy: 0.7688 - val_loss: 0.4406\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 524ms/step - accuracy: 0.7459 - loss: 0.4353 - val_accuracy: 0.7656 - val_loss: 0.4412\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - accuracy: 0.7587 - loss: 0.4260 - val_accuracy: 0.7750 - val_loss: 0.4421\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7618 - loss: 0.4294 - val_accuracy: 0.7688 - val_loss: 0.4401\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7602 - loss: 0.4299 - val_accuracy: 0.7688 - val_loss: 0.4454\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7453 - loss: 0.4203 - val_accuracy: 0.7719 - val_loss: 0.4432\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7584 - loss: 0.4365 - val_accuracy: 0.7688 - val_loss: 0.4383\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 737ms/step - accuracy: 0.7420 - loss: 0.4281 - val_accuracy: 0.7719 - val_loss: 0.4413\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379ms/step - accuracy: 0.7657 - loss: 0.4126 - val_accuracy: 0.7594 - val_loss: 0.4486\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7688 - loss: 0.4164 - val_accuracy: 0.7656 - val_loss: 0.4471\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7687 - loss: 0.4078 - val_accuracy: 0.7750 - val_loss: 0.4418\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.7849 - loss: 0.4009 - val_accuracy: 0.7750 - val_loss: 0.4464\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 531ms/step - accuracy: 0.7662 - loss: 0.4246 - val_accuracy: 0.7750 - val_loss: 0.4436\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7685 - loss: 0.4110 - val_accuracy: 0.7656 - val_loss: 0.4461\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7693 - loss: 0.4057 - val_accuracy: 0.7625 - val_loss: 0.4503\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7683 - loss: 0.4015 - val_accuracy: 0.7656 - val_loss: 0.4499\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7667 - loss: 0.4149 - val_accuracy: 0.7656 - val_loss: 0.4506\n",
            "Epoch 40: early stopping\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7606\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7370\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7606\n",
            "Time taken to train: 116.49 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 860ms/step - accuracy: 0.6715 - loss: 0.5830 - val_accuracy: 0.7437 - val_loss: 0.4867\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683ms/step - accuracy: 0.7259 - loss: 0.5073 - val_accuracy: 0.7312 - val_loss: 0.4904\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 775ms/step - accuracy: 0.7278 - loss: 0.4846 - val_accuracy: 0.7531 - val_loss: 0.4671\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7402 - loss: 0.4828 - val_accuracy: 0.7437 - val_loss: 0.4734\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 980ms/step - accuracy: 0.7333 - loss: 0.4637 - val_accuracy: 0.7531 - val_loss: 0.4584\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 667ms/step - accuracy: 0.7537 - loss: 0.4579 - val_accuracy: 0.7531 - val_loss: 0.4583\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 678ms/step - accuracy: 0.7238 - loss: 0.4725 - val_accuracy: 0.7437 - val_loss: 0.4603\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 695ms/step - accuracy: 0.7421 - loss: 0.4550 - val_accuracy: 0.7500 - val_loss: 0.4609\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 672ms/step - accuracy: 0.7466 - loss: 0.4573 - val_accuracy: 0.7469 - val_loss: 0.4610\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 988ms/step - accuracy: 0.7328 - loss: 0.4656 - val_accuracy: 0.7531 - val_loss: 0.4594\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 666ms/step - accuracy: 0.7501 - loss: 0.4574 - val_accuracy: 0.7563 - val_loss: 0.4583\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 666ms/step - accuracy: 0.7514 - loss: 0.4558 - val_accuracy: 0.7531 - val_loss: 0.4576\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 731ms/step - accuracy: 0.7414 - loss: 0.4539 - val_accuracy: 0.7531 - val_loss: 0.4571\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 678ms/step - accuracy: 0.7447 - loss: 0.4620 - val_accuracy: 0.7469 - val_loss: 0.4589\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7357 - loss: 0.4462 - val_accuracy: 0.7500 - val_loss: 0.4585\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 674ms/step - accuracy: 0.7283 - loss: 0.4736 - val_accuracy: 0.7437 - val_loss: 0.4671\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 688ms/step - accuracy: 0.7421 - loss: 0.4460 - val_accuracy: 0.7500 - val_loss: 0.4595\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.7310 - loss: 0.4605 - val_accuracy: 0.7531 - val_loss: 0.4604\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 689ms/step - accuracy: 0.7225 - loss: 0.4545 - val_accuracy: 0.7531 - val_loss: 0.4616\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 671ms/step - accuracy: 0.7379 - loss: 0.4555 - val_accuracy: 0.7437 - val_loss: 0.4639\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 670ms/step - accuracy: 0.7352 - loss: 0.4604 - val_accuracy: 0.7469 - val_loss: 0.4657\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7395 - loss: 0.4578 - val_accuracy: 0.7500 - val_loss: 0.4639\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.7558 - loss: 0.4308 - val_accuracy: 0.7500 - val_loss: 0.4642\n",
            "Epoch 23: early stopping\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7664\n",
            "BiLSTM-Content w2v_cbow Precision 0.7828\n",
            "BiLSTM-Content w2v_cbow Recall 0.7664\n",
            "Time taken to train: 117.17 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5535 - loss: 0.6096 - val_accuracy: 0.7312 - val_loss: 0.4936\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 804ms/step - accuracy: 0.7436 - loss: 0.4751 - val_accuracy: 0.7312 - val_loss: 0.4695\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 675ms/step - accuracy: 0.7400 - loss: 0.4680 - val_accuracy: 0.7531 - val_loss: 0.4573\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 675ms/step - accuracy: 0.7420 - loss: 0.4678 - val_accuracy: 0.7594 - val_loss: 0.4537\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669ms/step - accuracy: 0.7456 - loss: 0.4574 - val_accuracy: 0.7563 - val_loss: 0.4565\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 880ms/step - accuracy: 0.7493 - loss: 0.4519 - val_accuracy: 0.7500 - val_loss: 0.4564\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 664ms/step - accuracy: 0.7461 - loss: 0.4685 - val_accuracy: 0.7469 - val_loss: 0.4587\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 674ms/step - accuracy: 0.7419 - loss: 0.4511 - val_accuracy: 0.7437 - val_loss: 0.4628\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7490 - loss: 0.4599 - val_accuracy: 0.7437 - val_loss: 0.4635\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676ms/step - accuracy: 0.7385 - loss: 0.4612 - val_accuracy: 0.7437 - val_loss: 0.4620\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 677ms/step - accuracy: 0.7272 - loss: 0.4582 - val_accuracy: 0.7469 - val_loss: 0.4605\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 990ms/step - accuracy: 0.7513 - loss: 0.4445 - val_accuracy: 0.7469 - val_loss: 0.4589\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 673ms/step - accuracy: 0.7434 - loss: 0.4372 - val_accuracy: 0.7500 - val_loss: 0.4592\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 686ms/step - accuracy: 0.7276 - loss: 0.4442 - val_accuracy: 0.7500 - val_loss: 0.4612\n",
            "Epoch 14: early stopping\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7343\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.6898\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7343\n",
            "Time taken to train: 69.50 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6603 - loss: 0.5842 - val_accuracy: 0.7437 - val_loss: 0.4882\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692ms/step - accuracy: 0.7343 - loss: 0.4784 - val_accuracy: 0.7406 - val_loss: 0.4618\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 969ms/step - accuracy: 0.7541 - loss: 0.4720 - val_accuracy: 0.7656 - val_loss: 0.4483\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 686ms/step - accuracy: 0.7325 - loss: 0.4783 - val_accuracy: 0.7563 - val_loss: 0.4622\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7682 - loss: 0.4554 - val_accuracy: 0.7656 - val_loss: 0.4541\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 901ms/step - accuracy: 0.7471 - loss: 0.4584 - val_accuracy: 0.7625 - val_loss: 0.4562\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 681ms/step - accuracy: 0.7399 - loss: 0.4642 - val_accuracy: 0.7937 - val_loss: 0.4502\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 675ms/step - accuracy: 0.7619 - loss: 0.4494 - val_accuracy: 0.7625 - val_loss: 0.4490\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.7559 - loss: 0.4419 - val_accuracy: 0.7594 - val_loss: 0.4477\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692ms/step - accuracy: 0.7571 - loss: 0.4491 - val_accuracy: 0.7594 - val_loss: 0.4457\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 966ms/step - accuracy: 0.7593 - loss: 0.4498 - val_accuracy: 0.7625 - val_loss: 0.4437\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 706ms/step - accuracy: 0.7525 - loss: 0.4519 - val_accuracy: 0.7719 - val_loss: 0.4434\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 691ms/step - accuracy: 0.7609 - loss: 0.4447 - val_accuracy: 0.7656 - val_loss: 0.4434\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 827ms/step - accuracy: 0.7680 - loss: 0.4410 - val_accuracy: 0.7625 - val_loss: 0.4465\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 694ms/step - accuracy: 0.7621 - loss: 0.4450 - val_accuracy: 0.7656 - val_loss: 0.4477\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 700ms/step - accuracy: 0.7373 - loss: 0.4687 - val_accuracy: 0.7563 - val_loss: 0.4513\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7599 - loss: 0.4274 - val_accuracy: 0.7625 - val_loss: 0.4522\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692ms/step - accuracy: 0.7609 - loss: 0.4534 - val_accuracy: 0.7594 - val_loss: 0.4525\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 720ms/step - accuracy: 0.7498 - loss: 0.4553 - val_accuracy: 0.7656 - val_loss: 0.4477\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7659 - loss: 0.4346 - val_accuracy: 0.7594 - val_loss: 0.4455\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 700ms/step - accuracy: 0.7606 - loss: 0.4244 - val_accuracy: 0.7625 - val_loss: 0.4487\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7520 - loss: 0.4479 - val_accuracy: 0.7563 - val_loss: 0.4515\n",
            "Epoch 22: early stopping\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7577\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7389\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7577\n",
            "Time taken to train: 108.27 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5794 - loss: 0.5945 - val_accuracy: 0.7437 - val_loss: 0.4903\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7135 - loss: 0.5007 - val_accuracy: 0.7500 - val_loss: 0.4780\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7471 - loss: 0.4907 - val_accuracy: 0.7656 - val_loss: 0.4512\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686ms/step - accuracy: 0.7444 - loss: 0.4569 - val_accuracy: 0.7750 - val_loss: 0.4459\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7432 - loss: 0.4607 - val_accuracy: 0.7625 - val_loss: 0.4428\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 855ms/step - accuracy: 0.7466 - loss: 0.4453 - val_accuracy: 0.7625 - val_loss: 0.4435\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 710ms/step - accuracy: 0.7518 - loss: 0.4576 - val_accuracy: 0.7625 - val_loss: 0.4418\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709ms/step - accuracy: 0.7502 - loss: 0.4409 - val_accuracy: 0.7656 - val_loss: 0.4424\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7636 - loss: 0.4431 - val_accuracy: 0.7594 - val_loss: 0.4422\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 704ms/step - accuracy: 0.7592 - loss: 0.4431 - val_accuracy: 0.7625 - val_loss: 0.4418\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951ms/step - accuracy: 0.7498 - loss: 0.4488 - val_accuracy: 0.7688 - val_loss: 0.4399\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.7638 - loss: 0.4518 - val_accuracy: 0.7688 - val_loss: 0.4388\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7534 - loss: 0.4452 - val_accuracy: 0.7625 - val_loss: 0.4378\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7636 - loss: 0.4377 - val_accuracy: 0.7688 - val_loss: 0.4377\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675ms/step - accuracy: 0.7514 - loss: 0.4585 - val_accuracy: 0.7688 - val_loss: 0.4385\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7505 - loss: 0.4535 - val_accuracy: 0.7719 - val_loss: 0.4386\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 710ms/step - accuracy: 0.7525 - loss: 0.4399 - val_accuracy: 0.7656 - val_loss: 0.4384\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7606 - loss: 0.4350 - val_accuracy: 0.7625 - val_loss: 0.4378\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7642 - loss: 0.4339 - val_accuracy: 0.7656 - val_loss: 0.4375\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7499 - loss: 0.4408 - val_accuracy: 0.7719 - val_loss: 0.4392\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7703 - loss: 0.4327 - val_accuracy: 0.7656 - val_loss: 0.4395\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7598 - loss: 0.4359 - val_accuracy: 0.7625 - val_loss: 0.4396\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683ms/step - accuracy: 0.7619 - loss: 0.4271 - val_accuracy: 0.7656 - val_loss: 0.4428\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7654 - loss: 0.4357 - val_accuracy: 0.7563 - val_loss: 0.4589\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 989ms/step - accuracy: 0.7668 - loss: 0.4206 - val_accuracy: 0.7656 - val_loss: 0.4578\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 710ms/step - accuracy: 0.7755 - loss: 0.4274 - val_accuracy: 0.7625 - val_loss: 0.4476\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.7526 - loss: 0.4328 - val_accuracy: 0.7563 - val_loss: 0.4432\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 828ms/step - accuracy: 0.7493 - loss: 0.4347 - val_accuracy: 0.7719 - val_loss: 0.4465\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7633 - loss: 0.4200 - val_accuracy: 0.7594 - val_loss: 0.4480\n",
            "Epoch 29: early stopping\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7606\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7375\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7606\n",
            "Time taken to train: 144.03 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6022 - loss: 0.6023 - val_accuracy: 0.7406 - val_loss: 0.4892\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 955ms/step - accuracy: 0.7276 - loss: 0.4884 - val_accuracy: 0.7437 - val_loss: 0.4824\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7469 - loss: 0.4679 - val_accuracy: 0.7656 - val_loss: 0.4558\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7500 - loss: 0.4630 - val_accuracy: 0.7656 - val_loss: 0.4542\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 944ms/step - accuracy: 0.7617 - loss: 0.4695 - val_accuracy: 0.7625 - val_loss: 0.4467\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 710ms/step - accuracy: 0.7692 - loss: 0.4391 - val_accuracy: 0.7688 - val_loss: 0.4512\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 690ms/step - accuracy: 0.7591 - loss: 0.4488 - val_accuracy: 0.7656 - val_loss: 0.4520\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7604 - loss: 0.4425 - val_accuracy: 0.7625 - val_loss: 0.4549\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687ms/step - accuracy: 0.7505 - loss: 0.4541 - val_accuracy: 0.7719 - val_loss: 0.4471\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - accuracy: 0.7613 - loss: 0.4487 - val_accuracy: 0.7625 - val_loss: 0.4456\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7631 - loss: 0.4386 - val_accuracy: 0.7625 - val_loss: 0.4457\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.7528 - loss: 0.4541 - val_accuracy: 0.7594 - val_loss: 0.4471\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 696ms/step - accuracy: 0.7671 - loss: 0.4382 - val_accuracy: 0.7688 - val_loss: 0.4465\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7691 - loss: 0.4312 - val_accuracy: 0.7625 - val_loss: 0.4464\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7597 - loss: 0.4332 - val_accuracy: 0.7594 - val_loss: 0.4437\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 912ms/step - accuracy: 0.7616 - loss: 0.4409 - val_accuracy: 0.7656 - val_loss: 0.4461\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7454 - loss: 0.4483 - val_accuracy: 0.7688 - val_loss: 0.4484\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7572 - loss: 0.4356 - val_accuracy: 0.7656 - val_loss: 0.4469\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 753ms/step - accuracy: 0.7618 - loss: 0.4342 - val_accuracy: 0.7625 - val_loss: 0.4469\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7425 - loss: 0.4456 - val_accuracy: 0.7656 - val_loss: 0.4470\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 788ms/step - accuracy: 0.7621 - loss: 0.4233 - val_accuracy: 0.7719 - val_loss: 0.4443\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7507 - loss: 0.4310 - val_accuracy: 0.7594 - val_loss: 0.4503\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7581 - loss: 0.4323 - val_accuracy: 0.7625 - val_loss: 0.4504\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.7792 - loss: 0.4170 - val_accuracy: 0.7688 - val_loss: 0.4521\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7697 - loss: 0.4113 - val_accuracy: 0.7563 - val_loss: 0.4561\n",
            "Epoch 25: early stopping\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7635\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7428\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7635\n",
            "Time taken to train: 127.80 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6863 - loss: 0.6001 - val_accuracy: 0.7469 - val_loss: 0.4906\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 737ms/step - accuracy: 0.7288 - loss: 0.5067 - val_accuracy: 0.7531 - val_loss: 0.4703\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 850ms/step - accuracy: 0.7433 - loss: 0.4720 - val_accuracy: 0.7563 - val_loss: 0.4574\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 689ms/step - accuracy: 0.7467 - loss: 0.4590 - val_accuracy: 0.7563 - val_loss: 0.4486\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.7581 - loss: 0.4442 - val_accuracy: 0.7625 - val_loss: 0.4485\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7549 - loss: 0.4483 - val_accuracy: 0.7563 - val_loss: 0.4465\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693ms/step - accuracy: 0.7575 - loss: 0.4508 - val_accuracy: 0.7656 - val_loss: 0.4447\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7607 - loss: 0.4385 - val_accuracy: 0.7625 - val_loss: 0.4440\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 689ms/step - accuracy: 0.7444 - loss: 0.4711 - val_accuracy: 0.7625 - val_loss: 0.4437\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 696ms/step - accuracy: 0.7574 - loss: 0.4537 - val_accuracy: 0.7625 - val_loss: 0.4443\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7664 - loss: 0.4419 - val_accuracy: 0.7656 - val_loss: 0.4416\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7524 - loss: 0.4523 - val_accuracy: 0.7688 - val_loss: 0.4430\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 696ms/step - accuracy: 0.7566 - loss: 0.4455 - val_accuracy: 0.7719 - val_loss: 0.4424\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 902ms/step - accuracy: 0.7507 - loss: 0.4447 - val_accuracy: 0.7688 - val_loss: 0.4402\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 712ms/step - accuracy: 0.7670 - loss: 0.4396 - val_accuracy: 0.7656 - val_loss: 0.4402\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 703ms/step - accuracy: 0.7498 - loss: 0.4529 - val_accuracy: 0.7594 - val_loss: 0.4456\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.7590 - loss: 0.4461 - val_accuracy: 0.7750 - val_loss: 0.4432\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7630 - loss: 0.4408 - val_accuracy: 0.7688 - val_loss: 0.4426\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.7530 - loss: 0.4429 - val_accuracy: 0.7719 - val_loss: 0.4412\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7548 - loss: 0.4409 - val_accuracy: 0.7625 - val_loss: 0.4423\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7596 - loss: 0.4351 - val_accuracy: 0.7656 - val_loss: 0.4435\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7557 - loss: 0.4408 - val_accuracy: 0.7688 - val_loss: 0.4451\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7674 - loss: 0.4383 - val_accuracy: 0.7594 - val_loss: 0.4458\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 683ms/step - accuracy: 0.7482 - loss: 0.4303 - val_accuracy: 0.7656 - val_loss: 0.4496\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7654 - loss: 0.4301 - val_accuracy: 0.7719 - val_loss: 0.4460\n",
            "Epoch 25: early stopping\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7679\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7498\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7679\n",
            "Time taken to train: 125.65 seconds\n",
            "\n",
            "Iteration 2 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 531ms/step - accuracy: 0.6297 - loss: 0.5837 - val_accuracy: 0.7344 - val_loss: 0.5045\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7420 - loss: 0.4720 - val_accuracy: 0.7375 - val_loss: 0.4817\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - accuracy: 0.7587 - loss: 0.4682 - val_accuracy: 0.7344 - val_loss: 0.4832\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7499 - loss: 0.4602 - val_accuracy: 0.7375 - val_loss: 0.4778\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7732 - loss: 0.4608 - val_accuracy: 0.7312 - val_loss: 0.4918\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7550 - loss: 0.4490 - val_accuracy: 0.7406 - val_loss: 0.4828\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7632 - loss: 0.4503 - val_accuracy: 0.7375 - val_loss: 0.4820\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.7582 - loss: 0.4471 - val_accuracy: 0.7406 - val_loss: 0.4762\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.7554 - loss: 0.4587 - val_accuracy: 0.7375 - val_loss: 0.4767\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 638ms/step - accuracy: 0.7556 - loss: 0.4513 - val_accuracy: 0.7406 - val_loss: 0.4739\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361ms/step - accuracy: 0.7567 - loss: 0.4537 - val_accuracy: 0.7406 - val_loss: 0.4754\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.7621 - loss: 0.4466 - val_accuracy: 0.7406 - val_loss: 0.4752\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7489 - loss: 0.4595 - val_accuracy: 0.7406 - val_loss: 0.4766\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 755ms/step - accuracy: 0.7651 - loss: 0.4374 - val_accuracy: 0.7344 - val_loss: 0.4761\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.7565 - loss: 0.4507 - val_accuracy: 0.7375 - val_loss: 0.4755\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.7509 - loss: 0.4521 - val_accuracy: 0.7375 - val_loss: 0.4753\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.7492 - loss: 0.4538 - val_accuracy: 0.7344 - val_loss: 0.4753\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 665ms/step - accuracy: 0.7620 - loss: 0.4394 - val_accuracy: 0.7375 - val_loss: 0.4760\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7607 - loss: 0.4538 - val_accuracy: 0.7375 - val_loss: 0.4787\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7616 - loss: 0.4503 - val_accuracy: 0.7375 - val_loss: 0.4751\n",
            "Epoch 20: early stopping\n",
            "LSTM-Content w2v_cbow Accuracy 0.7416\n",
            "LSTM-Content w2v_cbow Precision 0.7768\n",
            "LSTM-Content w2v_cbow Recall 0.7416\n",
            "Time taken to train: 58.03 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 544ms/step - accuracy: 0.6946 - loss: 0.5836 - val_accuracy: 0.7312 - val_loss: 0.4998\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - accuracy: 0.7290 - loss: 0.5007 - val_accuracy: 0.7312 - val_loss: 0.4869\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 728ms/step - accuracy: 0.7211 - loss: 0.4865 - val_accuracy: 0.7312 - val_loss: 0.4803\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7557 - loss: 0.4564 - val_accuracy: 0.7406 - val_loss: 0.4744\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7611 - loss: 0.4541 - val_accuracy: 0.7375 - val_loss: 0.4843\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - accuracy: 0.7570 - loss: 0.4461 - val_accuracy: 0.7375 - val_loss: 0.4781\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7663 - loss: 0.4342 - val_accuracy: 0.7375 - val_loss: 0.4743\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687ms/step - accuracy: 0.7694 - loss: 0.4491 - val_accuracy: 0.7406 - val_loss: 0.4753\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412ms/step - accuracy: 0.7697 - loss: 0.4435 - val_accuracy: 0.7375 - val_loss: 0.4761\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7607 - loss: 0.4451 - val_accuracy: 0.7375 - val_loss: 0.4768\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7655 - loss: 0.4515 - val_accuracy: 0.7344 - val_loss: 0.4802\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 493ms/step - accuracy: 0.7523 - loss: 0.4699 - val_accuracy: 0.7375 - val_loss: 0.4780\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - accuracy: 0.7690 - loss: 0.4559 - val_accuracy: 0.7375 - val_loss: 0.4768\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 414ms/step - accuracy: 0.7556 - loss: 0.4467 - val_accuracy: 0.7375 - val_loss: 0.4756\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7646 - loss: 0.4368 - val_accuracy: 0.7375 - val_loss: 0.4773\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.7609 - loss: 0.4466 - val_accuracy: 0.7344 - val_loss: 0.4785\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 556ms/step - accuracy: 0.7549 - loss: 0.4609 - val_accuracy: 0.7375 - val_loss: 0.4781\n",
            "Epoch 17: early stopping\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7416\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7743\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7416\n",
            "Time taken to train: 55.63 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 893ms/step - accuracy: 0.5588 - loss: 0.5963 - val_accuracy: 0.7344 - val_loss: 0.5628\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7511 - loss: 0.5188 - val_accuracy: 0.7375 - val_loss: 0.5007\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.7530 - loss: 0.4763 - val_accuracy: 0.7406 - val_loss: 0.4946\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.7439 - loss: 0.4722 - val_accuracy: 0.7469 - val_loss: 0.4746\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 530ms/step - accuracy: 0.7556 - loss: 0.4481 - val_accuracy: 0.7375 - val_loss: 0.4732\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.7722 - loss: 0.4361 - val_accuracy: 0.7375 - val_loss: 0.4788\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374ms/step - accuracy: 0.7614 - loss: 0.4515 - val_accuracy: 0.7469 - val_loss: 0.4756\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7631 - loss: 0.4463 - val_accuracy: 0.7437 - val_loss: 0.4756\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.7682 - loss: 0.4390 - val_accuracy: 0.7469 - val_loss: 0.4719\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 795ms/step - accuracy: 0.7721 - loss: 0.4239 - val_accuracy: 0.7469 - val_loss: 0.4695\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419ms/step - accuracy: 0.7566 - loss: 0.4325 - val_accuracy: 0.7531 - val_loss: 0.4702\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7573 - loss: 0.4430 - val_accuracy: 0.7437 - val_loss: 0.4712\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7578 - loss: 0.4457 - val_accuracy: 0.7531 - val_loss: 0.4699\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7740 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.4700\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 542ms/step - accuracy: 0.7743 - loss: 0.4371 - val_accuracy: 0.7656 - val_loss: 0.4699\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.7679 - loss: 0.4456 - val_accuracy: 0.7688 - val_loss: 0.4703\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7458 - loss: 0.4471 - val_accuracy: 0.7469 - val_loss: 0.4690\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7688 - loss: 0.4315 - val_accuracy: 0.7469 - val_loss: 0.4690\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 496ms/step - accuracy: 0.7780 - loss: 0.4211 - val_accuracy: 0.7437 - val_loss: 0.4704\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 541ms/step - accuracy: 0.7715 - loss: 0.4275 - val_accuracy: 0.7625 - val_loss: 0.4700\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.7602 - loss: 0.4291 - val_accuracy: 0.7531 - val_loss: 0.4718\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7645 - loss: 0.4423 - val_accuracy: 0.7531 - val_loss: 0.4703\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.7667 - loss: 0.4374 - val_accuracy: 0.7563 - val_loss: 0.4742\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 761ms/step - accuracy: 0.7574 - loss: 0.4426 - val_accuracy: 0.7750 - val_loss: 0.4694\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7718 - loss: 0.4306 - val_accuracy: 0.7531 - val_loss: 0.4713\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.7700 - loss: 0.4294 - val_accuracy: 0.7531 - val_loss: 0.4684\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.7906 - loss: 0.4227 - val_accuracy: 0.7656 - val_loss: 0.4702\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7608 - loss: 0.4320 - val_accuracy: 0.7531 - val_loss: 0.4704\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 662ms/step - accuracy: 0.7640 - loss: 0.4316 - val_accuracy: 0.7594 - val_loss: 0.4723\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7794 - loss: 0.4117 - val_accuracy: 0.7625 - val_loss: 0.4704\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - accuracy: 0.7637 - loss: 0.4384 - val_accuracy: 0.7531 - val_loss: 0.4693\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7503 - loss: 0.4315 - val_accuracy: 0.7500 - val_loss: 0.4700\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658ms/step - accuracy: 0.7584 - loss: 0.4159 - val_accuracy: 0.7531 - val_loss: 0.4677\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7619 - loss: 0.4264 - val_accuracy: 0.7563 - val_loss: 0.4700\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7616 - loss: 0.4348 - val_accuracy: 0.7625 - val_loss: 0.4711\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7580 - loss: 0.4278 - val_accuracy: 0.7594 - val_loss: 0.4703\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7639 - loss: 0.4246 - val_accuracy: 0.7750 - val_loss: 0.4699\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 596ms/step - accuracy: 0.7639 - loss: 0.4268 - val_accuracy: 0.7719 - val_loss: 0.4690\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 373ms/step - accuracy: 0.7649 - loss: 0.4437 - val_accuracy: 0.7625 - val_loss: 0.4720\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7495 - loss: 0.4296 - val_accuracy: 0.7469 - val_loss: 0.4685\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7485 - loss: 0.4285 - val_accuracy: 0.7500 - val_loss: 0.4730\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7484 - loss: 0.4348 - val_accuracy: 0.7563 - val_loss: 0.4766\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 720ms/step - accuracy: 0.7616 - loss: 0.4431 - val_accuracy: 0.7563 - val_loss: 0.4720\n",
            "Epoch 43: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7635\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7422\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7635\n",
            "Time taken to train: 127.02 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 639ms/step - accuracy: 0.5672 - loss: 0.5927 - val_accuracy: 0.7406 - val_loss: 0.5298\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7349 - loss: 0.4974 - val_accuracy: 0.7469 - val_loss: 0.4858\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - accuracy: 0.7368 - loss: 0.4740 - val_accuracy: 0.7406 - val_loss: 0.4889\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 507ms/step - accuracy: 0.7419 - loss: 0.4375 - val_accuracy: 0.7437 - val_loss: 0.4774\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 531ms/step - accuracy: 0.7575 - loss: 0.4518 - val_accuracy: 0.7469 - val_loss: 0.4830\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7712 - loss: 0.4390 - val_accuracy: 0.7437 - val_loss: 0.4777\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 388ms/step - accuracy: 0.7612 - loss: 0.4469 - val_accuracy: 0.7688 - val_loss: 0.4752\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7577 - loss: 0.4308 - val_accuracy: 0.7531 - val_loss: 0.4761\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7652 - loss: 0.4460 - val_accuracy: 0.7437 - val_loss: 0.4723\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676ms/step - accuracy: 0.7705 - loss: 0.4224 - val_accuracy: 0.7531 - val_loss: 0.4759\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 427ms/step - accuracy: 0.7588 - loss: 0.4382 - val_accuracy: 0.7531 - val_loss: 0.4721\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7600 - loss: 0.4412 - val_accuracy: 0.7625 - val_loss: 0.4713\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7476 - loss: 0.4384 - val_accuracy: 0.7563 - val_loss: 0.4692\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 486ms/step - accuracy: 0.7530 - loss: 0.4404 - val_accuracy: 0.7656 - val_loss: 0.4687\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 568ms/step - accuracy: 0.7529 - loss: 0.4536 - val_accuracy: 0.7594 - val_loss: 0.4718\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 409ms/step - accuracy: 0.7701 - loss: 0.4309 - val_accuracy: 0.7594 - val_loss: 0.4699\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7599 - loss: 0.4440 - val_accuracy: 0.7594 - val_loss: 0.4674\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7745 - loss: 0.4366 - val_accuracy: 0.7563 - val_loss: 0.4736\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 651ms/step - accuracy: 0.7756 - loss: 0.4100 - val_accuracy: 0.7625 - val_loss: 0.4688\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.7534 - loss: 0.4358 - val_accuracy: 0.7531 - val_loss: 0.4684\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7709 - loss: 0.4093 - val_accuracy: 0.7625 - val_loss: 0.4720\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7702 - loss: 0.4440 - val_accuracy: 0.7594 - val_loss: 0.4677\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7561 - loss: 0.4343 - val_accuracy: 0.7625 - val_loss: 0.4737\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 576ms/step - accuracy: 0.7495 - loss: 0.4299 - val_accuracy: 0.7500 - val_loss: 0.4673\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374ms/step - accuracy: 0.7615 - loss: 0.4286 - val_accuracy: 0.7531 - val_loss: 0.4679\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7710 - loss: 0.4174 - val_accuracy: 0.7531 - val_loss: 0.4739\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7717 - loss: 0.4209 - val_accuracy: 0.7531 - val_loss: 0.4706\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 739ms/step - accuracy: 0.7617 - loss: 0.4350 - val_accuracy: 0.7625 - val_loss: 0.4691\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7520 - loss: 0.4440 - val_accuracy: 0.7594 - val_loss: 0.4657\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7734 - loss: 0.4202 - val_accuracy: 0.7563 - val_loss: 0.4655\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7581 - loss: 0.4318 - val_accuracy: 0.7656 - val_loss: 0.4670\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7499 - loss: 0.4325 - val_accuracy: 0.7500 - val_loss: 0.4684\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.7516 - loss: 0.4422 - val_accuracy: 0.7563 - val_loss: 0.4665\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 589ms/step - accuracy: 0.7652 - loss: 0.4199 - val_accuracy: 0.7688 - val_loss: 0.4682\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.7520 - loss: 0.4194 - val_accuracy: 0.7563 - val_loss: 0.4671\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7792 - loss: 0.4041 - val_accuracy: 0.7594 - val_loss: 0.4682\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7728 - loss: 0.4222 - val_accuracy: 0.7594 - val_loss: 0.4680\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 771ms/step - accuracy: 0.7605 - loss: 0.4354 - val_accuracy: 0.7656 - val_loss: 0.4701\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7574 - loss: 0.4209 - val_accuracy: 0.7563 - val_loss: 0.4670\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.7633 - loss: 0.4027 - val_accuracy: 0.7531 - val_loss: 0.4684\n",
            "Epoch 40: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7620\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7411\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7620\n",
            "Time taken to train: 114.52 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 632ms/step - accuracy: 0.6010 - loss: 0.6061 - val_accuracy: 0.7344 - val_loss: 0.5303\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7372 - loss: 0.4810 - val_accuracy: 0.7406 - val_loss: 0.4989\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 729ms/step - accuracy: 0.7456 - loss: 0.4754 - val_accuracy: 0.7406 - val_loss: 0.4935\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7503 - loss: 0.4746 - val_accuracy: 0.7531 - val_loss: 0.4733\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7487 - loss: 0.4542 - val_accuracy: 0.7500 - val_loss: 0.4742\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7627 - loss: 0.4434 - val_accuracy: 0.7375 - val_loss: 0.4787\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7693 - loss: 0.4623 - val_accuracy: 0.7469 - val_loss: 0.4713\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7589 - loss: 0.4494 - val_accuracy: 0.7563 - val_loss: 0.4771\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 515ms/step - accuracy: 0.7630 - loss: 0.4411 - val_accuracy: 0.7688 - val_loss: 0.4684\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365ms/step - accuracy: 0.7586 - loss: 0.4347 - val_accuracy: 0.7719 - val_loss: 0.4718\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.7392 - loss: 0.4496 - val_accuracy: 0.7531 - val_loss: 0.4687\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 413ms/step - accuracy: 0.7710 - loss: 0.4313 - val_accuracy: 0.7781 - val_loss: 0.4724\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 602ms/step - accuracy: 0.7547 - loss: 0.4411 - val_accuracy: 0.7437 - val_loss: 0.4711\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366ms/step - accuracy: 0.7775 - loss: 0.4296 - val_accuracy: 0.7437 - val_loss: 0.4721\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 413ms/step - accuracy: 0.7692 - loss: 0.4339 - val_accuracy: 0.7594 - val_loss: 0.4688\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.7644 - loss: 0.4312 - val_accuracy: 0.7594 - val_loss: 0.4702\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 480ms/step - accuracy: 0.7552 - loss: 0.4395 - val_accuracy: 0.7500 - val_loss: 0.4700\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 473ms/step - accuracy: 0.7729 - loss: 0.4158 - val_accuracy: 0.7531 - val_loss: 0.4709\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7909 - loss: 0.4365 - val_accuracy: 0.7563 - val_loss: 0.4697\n",
            "Epoch 19: early stopping\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7620\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7414\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7620\n",
            "Time taken to train: 55.54 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 638ms/step - accuracy: 0.6429 - loss: 0.6018 - val_accuracy: 0.7344 - val_loss: 0.5613\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.7403 - loss: 0.5084 - val_accuracy: 0.7437 - val_loss: 0.4960\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 419ms/step - accuracy: 0.7477 - loss: 0.4770 - val_accuracy: 0.7375 - val_loss: 0.4904\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.7594 - loss: 0.4661 - val_accuracy: 0.7375 - val_loss: 0.4698\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 508ms/step - accuracy: 0.7654 - loss: 0.4457 - val_accuracy: 0.7406 - val_loss: 0.4826\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7603 - loss: 0.4485 - val_accuracy: 0.7406 - val_loss: 0.4756\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7768 - loss: 0.4310 - val_accuracy: 0.7500 - val_loss: 0.4786\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - accuracy: 0.7591 - loss: 0.4382 - val_accuracy: 0.7625 - val_loss: 0.4751\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7608 - loss: 0.4215 - val_accuracy: 0.7594 - val_loss: 0.4714\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 645ms/step - accuracy: 0.7452 - loss: 0.4355 - val_accuracy: 0.7594 - val_loss: 0.4720\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7628 - loss: 0.4444 - val_accuracy: 0.7531 - val_loss: 0.4736\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7727 - loss: 0.4350 - val_accuracy: 0.7594 - val_loss: 0.4751\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7640 - loss: 0.4330 - val_accuracy: 0.7531 - val_loss: 0.4719\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7721 - loss: 0.4221 - val_accuracy: 0.7625 - val_loss: 0.4729\n",
            "Epoch 14: early stopping\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7591\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7351\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7591\n",
            "Time taken to train: 41.92 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5947 - loss: 0.5904 - val_accuracy: 0.7375 - val_loss: 0.4973\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 692ms/step - accuracy: 0.7524 - loss: 0.5067 - val_accuracy: 0.7344 - val_loss: 0.4975\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7484 - loss: 0.4947 - val_accuracy: 0.7281 - val_loss: 0.4885\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694ms/step - accuracy: 0.7380 - loss: 0.4771 - val_accuracy: 0.7406 - val_loss: 0.4844\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.7664 - loss: 0.4548 - val_accuracy: 0.7344 - val_loss: 0.4904\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 700ms/step - accuracy: 0.7499 - loss: 0.4714 - val_accuracy: 0.7344 - val_loss: 0.4776\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7523 - loss: 0.4656 - val_accuracy: 0.7406 - val_loss: 0.4776\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 937ms/step - accuracy: 0.7519 - loss: 0.4694 - val_accuracy: 0.7406 - val_loss: 0.4812\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 684ms/step - accuracy: 0.7634 - loss: 0.4552 - val_accuracy: 0.7406 - val_loss: 0.4786\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7492 - loss: 0.4648 - val_accuracy: 0.7406 - val_loss: 0.4783\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7650 - loss: 0.4476 - val_accuracy: 0.7406 - val_loss: 0.4771\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 690ms/step - accuracy: 0.7693 - loss: 0.4332 - val_accuracy: 0.7375 - val_loss: 0.4785\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 680ms/step - accuracy: 0.7640 - loss: 0.4310 - val_accuracy: 0.7406 - val_loss: 0.4786\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 696ms/step - accuracy: 0.7536 - loss: 0.4618 - val_accuracy: 0.7406 - val_loss: 0.4755\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 682ms/step - accuracy: 0.7577 - loss: 0.4472 - val_accuracy: 0.7406 - val_loss: 0.4800\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 998ms/step - accuracy: 0.7461 - loss: 0.4567 - val_accuracy: 0.7344 - val_loss: 0.4772\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683ms/step - accuracy: 0.7532 - loss: 0.4443 - val_accuracy: 0.7406 - val_loss: 0.4795\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7459 - loss: 0.4540 - val_accuracy: 0.7406 - val_loss: 0.4765\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 677ms/step - accuracy: 0.7502 - loss: 0.4608 - val_accuracy: 0.7406 - val_loss: 0.4803\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7747 - loss: 0.4417 - val_accuracy: 0.7344 - val_loss: 0.4796\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 981ms/step - accuracy: 0.7611 - loss: 0.4417 - val_accuracy: 0.7375 - val_loss: 0.4774\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675ms/step - accuracy: 0.7557 - loss: 0.4441 - val_accuracy: 0.7375 - val_loss: 0.4788\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 703ms/step - accuracy: 0.7639 - loss: 0.4232 - val_accuracy: 0.7375 - val_loss: 0.4803\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7618 - loss: 0.4621 - val_accuracy: 0.7406 - val_loss: 0.4856\n",
            "Epoch 24: early stopping\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7416\n",
            "BiLSTM-Content w2v_cbow Precision 0.7708\n",
            "BiLSTM-Content w2v_cbow Recall 0.7416\n",
            "Time taken to train: 126.82 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 940ms/step - accuracy: 0.5967 - loss: 0.5933 - val_accuracy: 0.7344 - val_loss: 0.4975\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 697ms/step - accuracy: 0.7385 - loss: 0.4981 - val_accuracy: 0.7344 - val_loss: 0.4941\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7489 - loss: 0.4815 - val_accuracy: 0.7406 - val_loss: 0.4754\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7582 - loss: 0.4651 - val_accuracy: 0.7375 - val_loss: 0.4849\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 711ms/step - accuracy: 0.7510 - loss: 0.4500 - val_accuracy: 0.7375 - val_loss: 0.4786\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 686ms/step - accuracy: 0.7644 - loss: 0.4612 - val_accuracy: 0.7406 - val_loss: 0.4868\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 695ms/step - accuracy: 0.7633 - loss: 0.4470 - val_accuracy: 0.7344 - val_loss: 0.4776\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 850ms/step - accuracy: 0.7623 - loss: 0.4557 - val_accuracy: 0.7375 - val_loss: 0.4833\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.7715 - loss: 0.4415 - val_accuracy: 0.7344 - val_loss: 0.4771\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7698 - loss: 0.4448 - val_accuracy: 0.7375 - val_loss: 0.4810\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.7644 - loss: 0.4333 - val_accuracy: 0.7375 - val_loss: 0.4794\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 0.7700 - loss: 0.4441 - val_accuracy: 0.7344 - val_loss: 0.4818\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.7644 - loss: 0.4358 - val_accuracy: 0.7406 - val_loss: 0.4782\n",
            "Epoch 13: early stopping\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7460\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7767\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7460\n",
            "Time taken to train: 70.83 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5789 - loss: 0.5904 - val_accuracy: 0.7375 - val_loss: 0.4957\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 856ms/step - accuracy: 0.7482 - loss: 0.4868 - val_accuracy: 0.7500 - val_loss: 0.4863\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 737ms/step - accuracy: 0.7324 - loss: 0.4740 - val_accuracy: 0.7437 - val_loss: 0.4742\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 693ms/step - accuracy: 0.7655 - loss: 0.4516 - val_accuracy: 0.7437 - val_loss: 0.4837\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953ms/step - accuracy: 0.7597 - loss: 0.4774 - val_accuracy: 0.7469 - val_loss: 0.4758\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.7778 - loss: 0.4385 - val_accuracy: 0.7437 - val_loss: 0.4758\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7635 - loss: 0.4261 - val_accuracy: 0.7531 - val_loss: 0.4712\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7696 - loss: 0.4341 - val_accuracy: 0.7844 - val_loss: 0.4723\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.7539 - loss: 0.4532 - val_accuracy: 0.7594 - val_loss: 0.4713\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7458 - loss: 0.4455 - val_accuracy: 0.7563 - val_loss: 0.4745\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 691ms/step - accuracy: 0.7625 - loss: 0.4362 - val_accuracy: 0.7656 - val_loss: 0.4707\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7647 - loss: 0.4302 - val_accuracy: 0.7563 - val_loss: 0.4700\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 757ms/step - accuracy: 0.7569 - loss: 0.4277 - val_accuracy: 0.7531 - val_loss: 0.4715\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688ms/step - accuracy: 0.7705 - loss: 0.4435 - val_accuracy: 0.7656 - val_loss: 0.4728\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7599 - loss: 0.4408 - val_accuracy: 0.7594 - val_loss: 0.4707\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 703ms/step - accuracy: 0.7706 - loss: 0.4309 - val_accuracy: 0.7594 - val_loss: 0.4730\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 700ms/step - accuracy: 0.7520 - loss: 0.4478 - val_accuracy: 0.7563 - val_loss: 0.4751\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7705 - loss: 0.4364 - val_accuracy: 0.7625 - val_loss: 0.4701\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694ms/step - accuracy: 0.7761 - loss: 0.4247 - val_accuracy: 0.7656 - val_loss: 0.4728\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7685 - loss: 0.4224 - val_accuracy: 0.7625 - val_loss: 0.4717\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 708ms/step - accuracy: 0.7692 - loss: 0.4299 - val_accuracy: 0.7625 - val_loss: 0.4829\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7649 - loss: 0.4276 - val_accuracy: 0.7437 - val_loss: 0.4724\n",
            "Epoch 22: early stopping\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7401\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7772\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7401\n",
            "Time taken to train: 118.72 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5140 - loss: 0.6078 - val_accuracy: 0.7344 - val_loss: 0.5006\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7478 - loss: 0.4838 - val_accuracy: 0.7375 - val_loss: 0.4862\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 673ms/step - accuracy: 0.7658 - loss: 0.4531 - val_accuracy: 0.7469 - val_loss: 0.4785\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7600 - loss: 0.4563 - val_accuracy: 0.7437 - val_loss: 0.4917\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 995ms/step - accuracy: 0.7651 - loss: 0.4359 - val_accuracy: 0.7437 - val_loss: 0.4861\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7686 - loss: 0.4490 - val_accuracy: 0.7688 - val_loss: 0.4892\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7673 - loss: 0.4337 - val_accuracy: 0.7563 - val_loss: 0.4774\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 776ms/step - accuracy: 0.7562 - loss: 0.4489 - val_accuracy: 0.7688 - val_loss: 0.4779\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 789ms/step - accuracy: 0.7553 - loss: 0.4284 - val_accuracy: 0.7719 - val_loss: 0.4716\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.7649 - loss: 0.4343 - val_accuracy: 0.7531 - val_loss: 0.4749\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.7559 - loss: 0.4345 - val_accuracy: 0.7500 - val_loss: 0.4710\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7513 - loss: 0.4217 - val_accuracy: 0.7656 - val_loss: 0.4688\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 677ms/step - accuracy: 0.7517 - loss: 0.4454 - val_accuracy: 0.7688 - val_loss: 0.4674\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7524 - loss: 0.4327 - val_accuracy: 0.7531 - val_loss: 0.4698\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.7684 - loss: 0.4292 - val_accuracy: 0.7750 - val_loss: 0.4710\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 686ms/step - accuracy: 0.7725 - loss: 0.4322 - val_accuracy: 0.7688 - val_loss: 0.4712\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7613 - loss: 0.4430 - val_accuracy: 0.7688 - val_loss: 0.4678\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 691ms/step - accuracy: 0.7612 - loss: 0.4231 - val_accuracy: 0.7563 - val_loss: 0.4675\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7664 - loss: 0.4315 - val_accuracy: 0.7531 - val_loss: 0.4662\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7489 - loss: 0.4368 - val_accuracy: 0.7594 - val_loss: 0.4709\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7909 - loss: 0.3957 - val_accuracy: 0.7594 - val_loss: 0.4690\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.7639 - loss: 0.4178 - val_accuracy: 0.7656 - val_loss: 0.4736\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 675ms/step - accuracy: 0.7628 - loss: 0.4314 - val_accuracy: 0.7625 - val_loss: 0.4670\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 783ms/step - accuracy: 0.7700 - loss: 0.4117 - val_accuracy: 0.7656 - val_loss: 0.4678\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 810ms/step - accuracy: 0.7815 - loss: 0.4196 - val_accuracy: 0.7688 - val_loss: 0.4651\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7619 - loss: 0.4303 - val_accuracy: 0.7656 - val_loss: 0.4745\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.7707 - loss: 0.4230 - val_accuracy: 0.7531 - val_loss: 0.4669\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 730ms/step - accuracy: 0.7638 - loss: 0.4283 - val_accuracy: 0.7625 - val_loss: 0.4747\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 706ms/step - accuracy: 0.7545 - loss: 0.4259 - val_accuracy: 0.7594 - val_loss: 0.4679\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.7803 - loss: 0.4131 - val_accuracy: 0.7625 - val_loss: 0.4718\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7552 - loss: 0.4179 - val_accuracy: 0.7625 - val_loss: 0.4697\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7717 - loss: 0.4197 - val_accuracy: 0.7625 - val_loss: 0.4717\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.7730 - loss: 0.4326 - val_accuracy: 0.7625 - val_loss: 0.4759\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.7720 - loss: 0.3875 - val_accuracy: 0.7719 - val_loss: 0.4765\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951ms/step - accuracy: 0.7722 - loss: 0.4110 - val_accuracy: 0.7656 - val_loss: 0.4812\n",
            "Epoch 35: early stopping\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7635\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7422\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7635\n",
            "Time taken to train: 171.54 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.7277 - loss: 0.5681 - val_accuracy: 0.7437 - val_loss: 0.4911\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 701ms/step - accuracy: 0.7364 - loss: 0.5135 - val_accuracy: 0.7344 - val_loss: 0.5051\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 758ms/step - accuracy: 0.7363 - loss: 0.4873 - val_accuracy: 0.7594 - val_loss: 0.4704\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 805ms/step - accuracy: 0.7577 - loss: 0.4512 - val_accuracy: 0.7594 - val_loss: 0.4710\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 686ms/step - accuracy: 0.7614 - loss: 0.4360 - val_accuracy: 0.7625 - val_loss: 0.4699\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 720ms/step - accuracy: 0.7481 - loss: 0.4396 - val_accuracy: 0.7594 - val_loss: 0.4713\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 791ms/step - accuracy: 0.7620 - loss: 0.4417 - val_accuracy: 0.7656 - val_loss: 0.4720\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.7595 - loss: 0.4547 - val_accuracy: 0.7531 - val_loss: 0.4715\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7604 - loss: 0.4377 - val_accuracy: 0.7625 - val_loss: 0.4772\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 713ms/step - accuracy: 0.7580 - loss: 0.4321 - val_accuracy: 0.7500 - val_loss: 0.4716\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7684 - loss: 0.4256 - val_accuracy: 0.7625 - val_loss: 0.4779\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7522 - loss: 0.4235 - val_accuracy: 0.7531 - val_loss: 0.4724\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7614 - loss: 0.4340 - val_accuracy: 0.7625 - val_loss: 0.4761\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7543 - loss: 0.4325 - val_accuracy: 0.7625 - val_loss: 0.4720\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 963ms/step - accuracy: 0.7568 - loss: 0.4411 - val_accuracy: 0.7656 - val_loss: 0.4717\n",
            "Epoch 15: early stopping\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7577\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7334\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7577\n",
            "Time taken to train: 83.71 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7409 - loss: 0.5845 - val_accuracy: 0.7563 - val_loss: 0.4914\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7568 - loss: 0.4736 - val_accuracy: 0.7469 - val_loss: 0.4746\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.7524 - loss: 0.4482 - val_accuracy: 0.7437 - val_loss: 0.4703\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 723ms/step - accuracy: 0.7529 - loss: 0.4464 - val_accuracy: 0.7563 - val_loss: 0.4952\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 690ms/step - accuracy: 0.7735 - loss: 0.4381 - val_accuracy: 0.7719 - val_loss: 0.4796\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 779ms/step - accuracy: 0.7649 - loss: 0.4393 - val_accuracy: 0.7625 - val_loss: 0.4821\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 705ms/step - accuracy: 0.7489 - loss: 0.4430 - val_accuracy: 0.7656 - val_loss: 0.4721\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 696ms/step - accuracy: 0.7652 - loss: 0.4380 - val_accuracy: 0.7625 - val_loss: 0.4737\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 797ms/step - accuracy: 0.7421 - loss: 0.4565 - val_accuracy: 0.7688 - val_loss: 0.4694\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 697ms/step - accuracy: 0.7737 - loss: 0.4404 - val_accuracy: 0.7594 - val_loss: 0.4734\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7652 - loss: 0.4184 - val_accuracy: 0.7563 - val_loss: 0.4699\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7546 - loss: 0.4477 - val_accuracy: 0.7688 - val_loss: 0.4748\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7631 - loss: 0.4166 - val_accuracy: 0.7688 - val_loss: 0.4719\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.7587 - loss: 0.4416 - val_accuracy: 0.7656 - val_loss: 0.4687\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688ms/step - accuracy: 0.7574 - loss: 0.4452 - val_accuracy: 0.7563 - val_loss: 0.4754\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7510 - loss: 0.4327 - val_accuracy: 0.7531 - val_loss: 0.4688\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 811ms/step - accuracy: 0.7688 - loss: 0.4352 - val_accuracy: 0.7625 - val_loss: 0.4710\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7572 - loss: 0.4323 - val_accuracy: 0.7563 - val_loss: 0.4704\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 992ms/step - accuracy: 0.7734 - loss: 0.4239 - val_accuracy: 0.7656 - val_loss: 0.4709\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - accuracy: 0.7685 - loss: 0.4274 - val_accuracy: 0.7563 - val_loss: 0.4711\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693ms/step - accuracy: 0.7693 - loss: 0.4247 - val_accuracy: 0.7563 - val_loss: 0.4699\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7634 - loss: 0.4287 - val_accuracy: 0.7656 - val_loss: 0.4687\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7746 - loss: 0.4187 - val_accuracy: 0.7594 - val_loss: 0.4693\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7685 - loss: 0.4268 - val_accuracy: 0.7656 - val_loss: 0.4703\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 704ms/step - accuracy: 0.7560 - loss: 0.4298 - val_accuracy: 0.7656 - val_loss: 0.4702\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702ms/step - accuracy: 0.7761 - loss: 0.4183 - val_accuracy: 0.7500 - val_loss: 0.4672\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7571 - loss: 0.4362 - val_accuracy: 0.7688 - val_loss: 0.4741\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7594 - loss: 0.4242 - val_accuracy: 0.7563 - val_loss: 0.4696\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7616 - loss: 0.4166 - val_accuracy: 0.7625 - val_loss: 0.4743\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 719ms/step - accuracy: 0.7803 - loss: 0.4128 - val_accuracy: 0.7781 - val_loss: 0.4757\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.7841 - loss: 0.4124 - val_accuracy: 0.7719 - val_loss: 0.4805\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7813 - loss: 0.4048 - val_accuracy: 0.7531 - val_loss: 0.4755\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.7824 - loss: 0.4013 - val_accuracy: 0.7594 - val_loss: 0.4782\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 708ms/step - accuracy: 0.7741 - loss: 0.4078 - val_accuracy: 0.7531 - val_loss: 0.4765\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 963ms/step - accuracy: 0.7700 - loss: 0.4193 - val_accuracy: 0.7531 - val_loss: 0.4866\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7522 - loss: 0.4237 - val_accuracy: 0.7469 - val_loss: 0.4833\n",
            "Epoch 36: early stopping\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7489\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7714\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7489\n",
            "Time taken to train: 185.25 seconds\n",
            "\n",
            "Iteration 3 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 525ms/step - accuracy: 0.6162 - loss: 0.5917 - val_accuracy: 0.7312 - val_loss: 0.4673\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 798ms/step - accuracy: 0.7293 - loss: 0.4787 - val_accuracy: 0.7406 - val_loss: 0.4535\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - accuracy: 0.7415 - loss: 0.4746 - val_accuracy: 0.7312 - val_loss: 0.4433\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - accuracy: 0.7370 - loss: 0.4826 - val_accuracy: 0.7469 - val_loss: 0.4391\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.7508 - loss: 0.4679 - val_accuracy: 0.7469 - val_loss: 0.4367\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7292 - loss: 0.4733 - val_accuracy: 0.7469 - val_loss: 0.4357\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 567ms/step - accuracy: 0.7435 - loss: 0.4579 - val_accuracy: 0.7500 - val_loss: 0.4349\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366ms/step - accuracy: 0.7397 - loss: 0.4705 - val_accuracy: 0.7500 - val_loss: 0.4348\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371ms/step - accuracy: 0.7381 - loss: 0.4635 - val_accuracy: 0.7469 - val_loss: 0.4362\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7503 - loss: 0.4547 - val_accuracy: 0.7469 - val_loss: 0.4391\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.7425 - loss: 0.4662 - val_accuracy: 0.7469 - val_loss: 0.4345\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 810ms/step - accuracy: 0.7538 - loss: 0.4481 - val_accuracy: 0.7437 - val_loss: 0.4350\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.7470 - loss: 0.4744 - val_accuracy: 0.7406 - val_loss: 0.4338\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7292 - loss: 0.4867 - val_accuracy: 0.7469 - val_loss: 0.4343\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7340 - loss: 0.4763 - val_accuracy: 0.7469 - val_loss: 0.4375\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 467ms/step - accuracy: 0.7471 - loss: 0.4656 - val_accuracy: 0.7406 - val_loss: 0.4330\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 495ms/step - accuracy: 0.7468 - loss: 0.4625 - val_accuracy: 0.7469 - val_loss: 0.4329\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 389ms/step - accuracy: 0.7532 - loss: 0.4379 - val_accuracy: 0.7500 - val_loss: 0.4352\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7345 - loss: 0.4668 - val_accuracy: 0.7469 - val_loss: 0.4331\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7481 - loss: 0.4612 - val_accuracy: 0.7469 - val_loss: 0.4333\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 851ms/step - accuracy: 0.7364 - loss: 0.4622 - val_accuracy: 0.7500 - val_loss: 0.4365\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7461 - loss: 0.4596 - val_accuracy: 0.7437 - val_loss: 0.4329\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7452 - loss: 0.4678 - val_accuracy: 0.7469 - val_loss: 0.4355\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.7492 - loss: 0.4577 - val_accuracy: 0.7469 - val_loss: 0.4350\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7387 - loss: 0.4610 - val_accuracy: 0.7469 - val_loss: 0.4356\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7426 - loss: 0.4493 - val_accuracy: 0.7469 - val_loss: 0.4354\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 538ms/step - accuracy: 0.7442 - loss: 0.4571 - val_accuracy: 0.7437 - val_loss: 0.4357\n",
            "Epoch 27: early stopping\n",
            "LSTM-Content w2v_cbow Accuracy 0.7474\n",
            "LSTM-Content w2v_cbow Precision 0.7717\n",
            "LSTM-Content w2v_cbow Recall 0.7474\n",
            "Time taken to train: 73.97 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 546ms/step - accuracy: 0.5645 - loss: 0.6284 - val_accuracy: 0.7312 - val_loss: 0.4756\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 753ms/step - accuracy: 0.7159 - loss: 0.5096 - val_accuracy: 0.7312 - val_loss: 0.4637\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - accuracy: 0.7223 - loss: 0.4855 - val_accuracy: 0.7312 - val_loss: 0.4521\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7288 - loss: 0.4885 - val_accuracy: 0.7312 - val_loss: 0.4493\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - accuracy: 0.7252 - loss: 0.4688 - val_accuracy: 0.7344 - val_loss: 0.4380\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.7285 - loss: 0.4702 - val_accuracy: 0.7344 - val_loss: 0.4366\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7413 - loss: 0.4625 - val_accuracy: 0.7344 - val_loss: 0.4384\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359ms/step - accuracy: 0.7365 - loss: 0.4599 - val_accuracy: 0.7469 - val_loss: 0.4382\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7491 - loss: 0.4581 - val_accuracy: 0.7625 - val_loss: 0.4407\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.7459 - loss: 0.4662 - val_accuracy: 0.7437 - val_loss: 0.4357\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7430 - loss: 0.4693 - val_accuracy: 0.7531 - val_loss: 0.4378\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.7599 - loss: 0.4513 - val_accuracy: 0.7531 - val_loss: 0.4356\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 624ms/step - accuracy: 0.7520 - loss: 0.4581 - val_accuracy: 0.7594 - val_loss: 0.4345\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7372 - loss: 0.4698 - val_accuracy: 0.7531 - val_loss: 0.4335\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - accuracy: 0.7474 - loss: 0.4524 - val_accuracy: 0.7594 - val_loss: 0.4328\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 360ms/step - accuracy: 0.7378 - loss: 0.4766 - val_accuracy: 0.7563 - val_loss: 0.4350\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 708ms/step - accuracy: 0.7508 - loss: 0.4638 - val_accuracy: 0.7563 - val_loss: 0.4379\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - accuracy: 0.7381 - loss: 0.4659 - val_accuracy: 0.7594 - val_loss: 0.4353\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 407ms/step - accuracy: 0.7479 - loss: 0.4580 - val_accuracy: 0.7563 - val_loss: 0.4332\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7393 - loss: 0.4603 - val_accuracy: 0.7594 - val_loss: 0.4362\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 506ms/step - accuracy: 0.7474 - loss: 0.4598 - val_accuracy: 0.7594 - val_loss: 0.4346\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 517ms/step - accuracy: 0.7348 - loss: 0.4759 - val_accuracy: 0.7656 - val_loss: 0.4359\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7432 - loss: 0.4654 - val_accuracy: 0.7563 - val_loss: 0.4335\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7440 - loss: 0.4530 - val_accuracy: 0.7563 - val_loss: 0.4394\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7468 - loss: 0.4505 - val_accuracy: 0.7500 - val_loss: 0.4339\n",
            "Epoch 25: early stopping\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7547\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7759\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7547\n",
            "Time taken to train: 67.64 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 589ms/step - accuracy: 0.6141 - loss: 0.5867 - val_accuracy: 0.7344 - val_loss: 0.4823\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7215 - loss: 0.4892 - val_accuracy: 0.7563 - val_loss: 0.4619\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7686 - loss: 0.4737 - val_accuracy: 0.7469 - val_loss: 0.4417\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 748ms/step - accuracy: 0.7355 - loss: 0.4708 - val_accuracy: 0.7594 - val_loss: 0.4411\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7407 - loss: 0.4702 - val_accuracy: 0.7531 - val_loss: 0.4330\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7423 - loss: 0.4699 - val_accuracy: 0.7625 - val_loss: 0.4309\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7388 - loss: 0.4587 - val_accuracy: 0.7594 - val_loss: 0.4267\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.7532 - loss: 0.4544 - val_accuracy: 0.7625 - val_loss: 0.4244\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 750ms/step - accuracy: 0.7526 - loss: 0.4507 - val_accuracy: 0.7594 - val_loss: 0.4237\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step - accuracy: 0.7529 - loss: 0.4651 - val_accuracy: 0.7688 - val_loss: 0.4219\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.7422 - loss: 0.4541 - val_accuracy: 0.7625 - val_loss: 0.4206\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7663 - loss: 0.4546 - val_accuracy: 0.7563 - val_loss: 0.4202\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7596 - loss: 0.4413 - val_accuracy: 0.7750 - val_loss: 0.4192\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 648ms/step - accuracy: 0.7599 - loss: 0.4478 - val_accuracy: 0.7594 - val_loss: 0.4235\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7504 - loss: 0.4479 - val_accuracy: 0.7750 - val_loss: 0.4190\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409ms/step - accuracy: 0.7492 - loss: 0.4456 - val_accuracy: 0.7594 - val_loss: 0.4196\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7458 - loss: 0.4502 - val_accuracy: 0.7625 - val_loss: 0.4196\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - accuracy: 0.7547 - loss: 0.4331 - val_accuracy: 0.7625 - val_loss: 0.4179\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 611ms/step - accuracy: 0.7624 - loss: 0.4484 - val_accuracy: 0.7594 - val_loss: 0.4222\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.7571 - loss: 0.4410 - val_accuracy: 0.7719 - val_loss: 0.4177\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7568 - loss: 0.4425 - val_accuracy: 0.7594 - val_loss: 0.4210\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.7515 - loss: 0.4391 - val_accuracy: 0.7594 - val_loss: 0.4186\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.7409 - loss: 0.4505 - val_accuracy: 0.7563 - val_loss: 0.4195\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 508ms/step - accuracy: 0.7565 - loss: 0.4470 - val_accuracy: 0.7625 - val_loss: 0.4202\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.7495 - loss: 0.4537 - val_accuracy: 0.7656 - val_loss: 0.4193\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7500 - loss: 0.4459 - val_accuracy: 0.7625 - val_loss: 0.4207\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7565 - loss: 0.4444 - val_accuracy: 0.7656 - val_loss: 0.4193\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 773ms/step - accuracy: 0.7421 - loss: 0.4515 - val_accuracy: 0.7656 - val_loss: 0.4200\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7404 - loss: 0.4381 - val_accuracy: 0.7594 - val_loss: 0.4215\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7370 - loss: 0.4550 - val_accuracy: 0.7594 - val_loss: 0.4206\n",
            "Epoch 30: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7752\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7576\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7752\n",
            "Time taken to train: 86.97 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 591ms/step - accuracy: 0.7589 - loss: 0.5584 - val_accuracy: 0.7406 - val_loss: 0.4593\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 641ms/step - accuracy: 0.7250 - loss: 0.4961 - val_accuracy: 0.7500 - val_loss: 0.4451\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7374 - loss: 0.4681 - val_accuracy: 0.7469 - val_loss: 0.4371\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7594 - loss: 0.4690 - val_accuracy: 0.7625 - val_loss: 0.4358\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7383 - loss: 0.4792 - val_accuracy: 0.7656 - val_loss: 0.4244\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7484 - loss: 0.4637 - val_accuracy: 0.7656 - val_loss: 0.4208\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 649ms/step - accuracy: 0.7356 - loss: 0.4554 - val_accuracy: 0.7563 - val_loss: 0.4214\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7382 - loss: 0.4598 - val_accuracy: 0.7656 - val_loss: 0.4187\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7538 - loss: 0.4425 - val_accuracy: 0.7594 - val_loss: 0.4181\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7373 - loss: 0.4587 - val_accuracy: 0.7563 - val_loss: 0.4192\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7510 - loss: 0.4568 - val_accuracy: 0.7688 - val_loss: 0.4177\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 0.7560 - loss: 0.4420 - val_accuracy: 0.7594 - val_loss: 0.4172\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 519ms/step - accuracy: 0.7567 - loss: 0.4361 - val_accuracy: 0.7625 - val_loss: 0.4182\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7528 - loss: 0.4513 - val_accuracy: 0.7563 - val_loss: 0.4173\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7439 - loss: 0.4421 - val_accuracy: 0.7656 - val_loss: 0.4166\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7544 - loss: 0.4441 - val_accuracy: 0.7656 - val_loss: 0.4167\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7509 - loss: 0.4477 - val_accuracy: 0.7656 - val_loss: 0.4196\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 548ms/step - accuracy: 0.7646 - loss: 0.4282 - val_accuracy: 0.7625 - val_loss: 0.4173\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 388ms/step - accuracy: 0.7546 - loss: 0.4295 - val_accuracy: 0.7625 - val_loss: 0.4196\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.7567 - loss: 0.4487 - val_accuracy: 0.7656 - val_loss: 0.4173\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7439 - loss: 0.4550 - val_accuracy: 0.7656 - val_loss: 0.4178\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7228 - loss: 0.4609 - val_accuracy: 0.7656 - val_loss: 0.4218\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 565ms/step - accuracy: 0.7383 - loss: 0.4586 - val_accuracy: 0.7625 - val_loss: 0.4189\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7542 - loss: 0.4440 - val_accuracy: 0.7656 - val_loss: 0.4189\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7631 - loss: 0.4302 - val_accuracy: 0.7656 - val_loss: 0.4227\n",
            "Epoch 25: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7810\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7648\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7810\n",
            "Time taken to train: 68.16 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 654ms/step - accuracy: 0.7457 - loss: 0.5719 - val_accuracy: 0.7563 - val_loss: 0.4584\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 593ms/step - accuracy: 0.7397 - loss: 0.4749 - val_accuracy: 0.7469 - val_loss: 0.4454\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7417 - loss: 0.4627 - val_accuracy: 0.7500 - val_loss: 0.4353\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.7483 - loss: 0.4606 - val_accuracy: 0.7625 - val_loss: 0.4325\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7435 - loss: 0.4591 - val_accuracy: 0.7500 - val_loss: 0.4269\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 768ms/step - accuracy: 0.7378 - loss: 0.4583 - val_accuracy: 0.7594 - val_loss: 0.4302\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.7631 - loss: 0.4545 - val_accuracy: 0.7656 - val_loss: 0.4243\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - accuracy: 0.7533 - loss: 0.4615 - val_accuracy: 0.7563 - val_loss: 0.4237\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7577 - loss: 0.4585 - val_accuracy: 0.7625 - val_loss: 0.4215\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 495ms/step - accuracy: 0.7572 - loss: 0.4407 - val_accuracy: 0.7625 - val_loss: 0.4218\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - accuracy: 0.7691 - loss: 0.4437 - val_accuracy: 0.7563 - val_loss: 0.4214\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7394 - loss: 0.4571 - val_accuracy: 0.7625 - val_loss: 0.4206\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7526 - loss: 0.4620 - val_accuracy: 0.7625 - val_loss: 0.4200\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389ms/step - accuracy: 0.7318 - loss: 0.4488 - val_accuracy: 0.7656 - val_loss: 0.4197\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 551ms/step - accuracy: 0.7510 - loss: 0.4546 - val_accuracy: 0.7656 - val_loss: 0.4257\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378ms/step - accuracy: 0.7505 - loss: 0.4497 - val_accuracy: 0.7656 - val_loss: 0.4205\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 425ms/step - accuracy: 0.7458 - loss: 0.4538 - val_accuracy: 0.7563 - val_loss: 0.4194\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7400 - loss: 0.4555 - val_accuracy: 0.7563 - val_loss: 0.4172\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.7547 - loss: 0.4373 - val_accuracy: 0.7563 - val_loss: 0.4210\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 551ms/step - accuracy: 0.7542 - loss: 0.4462 - val_accuracy: 0.7625 - val_loss: 0.4193\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 400ms/step - accuracy: 0.7341 - loss: 0.4637 - val_accuracy: 0.7688 - val_loss: 0.4180\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.7689 - loss: 0.4406 - val_accuracy: 0.7594 - val_loss: 0.4244\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7629 - loss: 0.4492 - val_accuracy: 0.7656 - val_loss: 0.4202\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 832ms/step - accuracy: 0.7393 - loss: 0.4524 - val_accuracy: 0.7594 - val_loss: 0.4197\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7428 - loss: 0.4455 - val_accuracy: 0.7594 - val_loss: 0.4165\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.7639 - loss: 0.4497 - val_accuracy: 0.7625 - val_loss: 0.4193\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7452 - loss: 0.4552 - val_accuracy: 0.7594 - val_loss: 0.4209\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7356 - loss: 0.4568 - val_accuracy: 0.7688 - val_loss: 0.4233\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 592ms/step - accuracy: 0.7587 - loss: 0.4377 - val_accuracy: 0.7719 - val_loss: 0.4185\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419ms/step - accuracy: 0.7503 - loss: 0.4360 - val_accuracy: 0.7719 - val_loss: 0.4212\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7728 - loss: 0.4180 - val_accuracy: 0.7750 - val_loss: 0.4257\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 438ms/step - accuracy: 0.7560 - loss: 0.4211 - val_accuracy: 0.7750 - val_loss: 0.4228\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653ms/step - accuracy: 0.7536 - loss: 0.4349 - val_accuracy: 0.7656 - val_loss: 0.4200\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.7451 - loss: 0.4484 - val_accuracy: 0.7750 - val_loss: 0.4222\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.7608 - loss: 0.4262 - val_accuracy: 0.7719 - val_loss: 0.4223\n",
            "Epoch 35: early stopping\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7530\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 111.76 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 621ms/step - accuracy: 0.6784 - loss: 0.5964 - val_accuracy: 0.7406 - val_loss: 0.4599\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 596ms/step - accuracy: 0.7317 - loss: 0.4814 - val_accuracy: 0.7437 - val_loss: 0.4418\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 449ms/step - accuracy: 0.7469 - loss: 0.4649 - val_accuracy: 0.7625 - val_loss: 0.4296\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.7540 - loss: 0.4540 - val_accuracy: 0.7563 - val_loss: 0.4243\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.7430 - loss: 0.4726 - val_accuracy: 0.7656 - val_loss: 0.4194\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step - accuracy: 0.7462 - loss: 0.4452 - val_accuracy: 0.7594 - val_loss: 0.4174\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 764ms/step - accuracy: 0.7519 - loss: 0.4477 - val_accuracy: 0.7594 - val_loss: 0.4215\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7301 - loss: 0.4566 - val_accuracy: 0.7594 - val_loss: 0.4204\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7326 - loss: 0.4624 - val_accuracy: 0.7563 - val_loss: 0.4210\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - accuracy: 0.7493 - loss: 0.4321 - val_accuracy: 0.7625 - val_loss: 0.4195\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 608ms/step - accuracy: 0.7493 - loss: 0.4586 - val_accuracy: 0.7688 - val_loss: 0.4179\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 465ms/step - accuracy: 0.7608 - loss: 0.4421 - val_accuracy: 0.7563 - val_loss: 0.4201\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7528 - loss: 0.4683 - val_accuracy: 0.7594 - val_loss: 0.4197\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - accuracy: 0.7450 - loss: 0.4565 - val_accuracy: 0.7594 - val_loss: 0.4182\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.7579 - loss: 0.4534 - val_accuracy: 0.7656 - val_loss: 0.4196\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 645ms/step - accuracy: 0.7476 - loss: 0.4463 - val_accuracy: 0.7563 - val_loss: 0.4197\n",
            "Epoch 16: early stopping\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7766\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7597\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7766\n",
            "Time taken to train: 55.74 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5588 - loss: 0.5922 - val_accuracy: 0.7531 - val_loss: 0.4555\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 684ms/step - accuracy: 0.7529 - loss: 0.4768 - val_accuracy: 0.7406 - val_loss: 0.4409\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7392 - loss: 0.4639 - val_accuracy: 0.7437 - val_loss: 0.4428\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7490 - loss: 0.4720 - val_accuracy: 0.7437 - val_loss: 0.4406\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 689ms/step - accuracy: 0.7495 - loss: 0.4747 - val_accuracy: 0.7469 - val_loss: 0.4390\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - accuracy: 0.7510 - loss: 0.4582 - val_accuracy: 0.7500 - val_loss: 0.4350\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 685ms/step - accuracy: 0.7420 - loss: 0.4632 - val_accuracy: 0.7500 - val_loss: 0.4346\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 699ms/step - accuracy: 0.7372 - loss: 0.4649 - val_accuracy: 0.7469 - val_loss: 0.4358\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 811ms/step - accuracy: 0.7483 - loss: 0.4667 - val_accuracy: 0.7469 - val_loss: 0.4351\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 700ms/step - accuracy: 0.7432 - loss: 0.4784 - val_accuracy: 0.7406 - val_loss: 0.4346\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 699ms/step - accuracy: 0.7550 - loss: 0.4608 - val_accuracy: 0.7469 - val_loss: 0.4341\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7442 - loss: 0.4556 - val_accuracy: 0.7500 - val_loss: 0.4346\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 700ms/step - accuracy: 0.7471 - loss: 0.4649 - val_accuracy: 0.7437 - val_loss: 0.4352\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - accuracy: 0.7354 - loss: 0.4533 - val_accuracy: 0.7469 - val_loss: 0.4424\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 751ms/step - accuracy: 0.7453 - loss: 0.4531 - val_accuracy: 0.7500 - val_loss: 0.4345\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687ms/step - accuracy: 0.7296 - loss: 0.4819 - val_accuracy: 0.7500 - val_loss: 0.4343\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7580 - loss: 0.4527 - val_accuracy: 0.7437 - val_loss: 0.4368\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7541 - loss: 0.4445 - val_accuracy: 0.7437 - val_loss: 0.4388\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 685ms/step - accuracy: 0.7451 - loss: 0.4673 - val_accuracy: 0.7500 - val_loss: 0.4389\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 686ms/step - accuracy: 0.7435 - loss: 0.4615 - val_accuracy: 0.7469 - val_loss: 0.4402\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 678ms/step - accuracy: 0.7467 - loss: 0.4616 - val_accuracy: 0.7437 - val_loss: 0.4381\n",
            "Epoch 21: early stopping\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7533\n",
            "BiLSTM-Content w2v_cbow Precision 0.7729\n",
            "BiLSTM-Content w2v_cbow Recall 0.7533\n",
            "Time taken to train: 105.43 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5290 - loss: 0.5921 - val_accuracy: 0.7406 - val_loss: 0.4585\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694ms/step - accuracy: 0.7341 - loss: 0.4880 - val_accuracy: 0.7312 - val_loss: 0.4413\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7265 - loss: 0.4623 - val_accuracy: 0.7531 - val_loss: 0.4465\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 773ms/step - accuracy: 0.7384 - loss: 0.4619 - val_accuracy: 0.7469 - val_loss: 0.4299\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 677ms/step - accuracy: 0.7406 - loss: 0.5020 - val_accuracy: 0.7531 - val_loss: 0.4320\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7398 - loss: 0.4901 - val_accuracy: 0.7437 - val_loss: 0.4363\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.7589 - loss: 0.4629 - val_accuracy: 0.7469 - val_loss: 0.4454\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 700ms/step - accuracy: 0.7387 - loss: 0.4676 - val_accuracy: 0.7344 - val_loss: 0.4364\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7540 - loss: 0.4579 - val_accuracy: 0.7437 - val_loss: 0.4339\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 985ms/step - accuracy: 0.7526 - loss: 0.4450 - val_accuracy: 0.7375 - val_loss: 0.4405\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 684ms/step - accuracy: 0.7369 - loss: 0.4615 - val_accuracy: 0.7344 - val_loss: 0.4349\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 700ms/step - accuracy: 0.7478 - loss: 0.4596 - val_accuracy: 0.7469 - val_loss: 0.4364\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 683ms/step - accuracy: 0.7441 - loss: 0.4640 - val_accuracy: 0.7469 - val_loss: 0.4353\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - accuracy: 0.7541 - loss: 0.4511 - val_accuracy: 0.7469 - val_loss: 0.4322\n",
            "Epoch 14: early stopping\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7533\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7740\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7533\n",
            "Time taken to train: 69.39 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6939 - loss: 0.5788 - val_accuracy: 0.7500 - val_loss: 0.4546\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 909ms/step - accuracy: 0.7430 - loss: 0.4873 - val_accuracy: 0.7469 - val_loss: 0.4411\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7532 - loss: 0.4585 - val_accuracy: 0.7563 - val_loss: 0.4297\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 707ms/step - accuracy: 0.7476 - loss: 0.4663 - val_accuracy: 0.7625 - val_loss: 0.4265\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7405 - loss: 0.4627 - val_accuracy: 0.7625 - val_loss: 0.4252\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692ms/step - accuracy: 0.7539 - loss: 0.4572 - val_accuracy: 0.7594 - val_loss: 0.4279\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 690ms/step - accuracy: 0.7535 - loss: 0.4708 - val_accuracy: 0.7625 - val_loss: 0.4215\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 935ms/step - accuracy: 0.7342 - loss: 0.4538 - val_accuracy: 0.7625 - val_loss: 0.4219\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7559 - loss: 0.4551 - val_accuracy: 0.7563 - val_loss: 0.4172\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.7437 - loss: 0.4586 - val_accuracy: 0.7563 - val_loss: 0.4169\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7513 - loss: 0.4317 - val_accuracy: 0.7656 - val_loss: 0.4218\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 720ms/step - accuracy: 0.7386 - loss: 0.4770 - val_accuracy: 0.7625 - val_loss: 0.4178\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7616 - loss: 0.4503 - val_accuracy: 0.7625 - val_loss: 0.4170\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7449 - loss: 0.4499 - val_accuracy: 0.7563 - val_loss: 0.4211\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 699ms/step - accuracy: 0.7568 - loss: 0.4498 - val_accuracy: 0.7625 - val_loss: 0.4179\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7477 - loss: 0.4514 - val_accuracy: 0.7563 - val_loss: 0.4186\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7490 - loss: 0.4435 - val_accuracy: 0.7656 - val_loss: 0.4187\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7564 - loss: 0.4588 - val_accuracy: 0.7656 - val_loss: 0.4183\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7405 - loss: 0.4524 - val_accuracy: 0.7656 - val_loss: 0.4189\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7506 - loss: 0.4494 - val_accuracy: 0.7656 - val_loss: 0.4191\n",
            "Epoch 20: early stopping\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7766\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7600\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7766\n",
            "Time taken to train: 107.64 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5682 - loss: 0.5994 - val_accuracy: 0.7531 - val_loss: 0.4636\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 726ms/step - accuracy: 0.7402 - loss: 0.5042 - val_accuracy: 0.7531 - val_loss: 0.4337\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 887ms/step - accuracy: 0.7420 - loss: 0.4779 - val_accuracy: 0.7563 - val_loss: 0.4231\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.7647 - loss: 0.4490 - val_accuracy: 0.7563 - val_loss: 0.4196\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 706ms/step - accuracy: 0.7655 - loss: 0.4553 - val_accuracy: 0.7594 - val_loss: 0.4200\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 723ms/step - accuracy: 0.7515 - loss: 0.4488 - val_accuracy: 0.7594 - val_loss: 0.4217\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7350 - loss: 0.4552 - val_accuracy: 0.7656 - val_loss: 0.4176\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7604 - loss: 0.4355 - val_accuracy: 0.7594 - val_loss: 0.4167\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 685ms/step - accuracy: 0.7742 - loss: 0.4462 - val_accuracy: 0.7656 - val_loss: 0.4167\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7567 - loss: 0.4547 - val_accuracy: 0.7594 - val_loss: 0.4186\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 955ms/step - accuracy: 0.7430 - loss: 0.4533 - val_accuracy: 0.7625 - val_loss: 0.4190\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - accuracy: 0.7703 - loss: 0.4291 - val_accuracy: 0.7563 - val_loss: 0.4189\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 705ms/step - accuracy: 0.7444 - loss: 0.4532 - val_accuracy: 0.7688 - val_loss: 0.4176\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7586 - loss: 0.4493 - val_accuracy: 0.7688 - val_loss: 0.4173\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7734 - loss: 0.4341 - val_accuracy: 0.7656 - val_loss: 0.4173\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.7164 - loss: 0.4635 - val_accuracy: 0.7594 - val_loss: 0.4199\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7546 - loss: 0.4522 - val_accuracy: 0.7563 - val_loss: 0.4208\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7408 - loss: 0.4512 - val_accuracy: 0.7625 - val_loss: 0.4200\n",
            "Epoch 18: early stopping\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7650\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7473\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7650\n",
            "Time taken to train: 91.44 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.5786 - loss: 0.5945 - val_accuracy: 0.7500 - val_loss: 0.4579\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 913ms/step - accuracy: 0.7495 - loss: 0.4755 - val_accuracy: 0.7469 - val_loss: 0.4379\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721ms/step - accuracy: 0.7297 - loss: 0.4704 - val_accuracy: 0.7688 - val_loss: 0.4286\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7548 - loss: 0.4653 - val_accuracy: 0.7625 - val_loss: 0.4230\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.7555 - loss: 0.4590 - val_accuracy: 0.7656 - val_loss: 0.4220\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7599 - loss: 0.4651 - val_accuracy: 0.7625 - val_loss: 0.4228\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7586 - loss: 0.4518 - val_accuracy: 0.7719 - val_loss: 0.4214\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7436 - loss: 0.4481 - val_accuracy: 0.7594 - val_loss: 0.4201\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721ms/step - accuracy: 0.7596 - loss: 0.4471 - val_accuracy: 0.7625 - val_loss: 0.4167\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.7642 - loss: 0.4442 - val_accuracy: 0.7656 - val_loss: 0.4201\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714ms/step - accuracy: 0.7399 - loss: 0.4486 - val_accuracy: 0.7688 - val_loss: 0.4193\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7544 - loss: 0.4345 - val_accuracy: 0.7625 - val_loss: 0.4196\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7548 - loss: 0.4620 - val_accuracy: 0.7625 - val_loss: 0.4176\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7651 - loss: 0.4555 - val_accuracy: 0.7656 - val_loss: 0.4178\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7494 - loss: 0.4475 - val_accuracy: 0.7656 - val_loss: 0.4218\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7613 - loss: 0.4429 - val_accuracy: 0.7625 - val_loss: 0.4229\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7453 - loss: 0.4333 - val_accuracy: 0.7688 - val_loss: 0.4208\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7604 - loss: 0.4384 - val_accuracy: 0.7750 - val_loss: 0.4211\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 984ms/step - accuracy: 0.7361 - loss: 0.4441 - val_accuracy: 0.7781 - val_loss: 0.4224\n",
            "Epoch 19: early stopping\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7515\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 100.34 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6200 - loss: 0.5947 - val_accuracy: 0.7469 - val_loss: 0.4604\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 715ms/step - accuracy: 0.7517 - loss: 0.4705 - val_accuracy: 0.7437 - val_loss: 0.4362\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 905ms/step - accuracy: 0.7249 - loss: 0.4816 - val_accuracy: 0.7688 - val_loss: 0.4169\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - accuracy: 0.7439 - loss: 0.4576 - val_accuracy: 0.7594 - val_loss: 0.4170\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 694ms/step - accuracy: 0.7771 - loss: 0.4418 - val_accuracy: 0.7563 - val_loss: 0.4151\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7566 - loss: 0.4473 - val_accuracy: 0.7563 - val_loss: 0.4174\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.7565 - loss: 0.4545 - val_accuracy: 0.7563 - val_loss: 0.4193\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 992ms/step - accuracy: 0.7695 - loss: 0.4466 - val_accuracy: 0.7625 - val_loss: 0.4202\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7689 - loss: 0.4495 - val_accuracy: 0.7625 - val_loss: 0.4217\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709ms/step - accuracy: 0.7476 - loss: 0.4414 - val_accuracy: 0.7625 - val_loss: 0.4188\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7527 - loss: 0.4458 - val_accuracy: 0.7656 - val_loss: 0.4178\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 709ms/step - accuracy: 0.7636 - loss: 0.4523 - val_accuracy: 0.7625 - val_loss: 0.4172\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7338 - loss: 0.4535 - val_accuracy: 0.7625 - val_loss: 0.4176\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 997ms/step - accuracy: 0.7403 - loss: 0.4818 - val_accuracy: 0.7656 - val_loss: 0.4178\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.7380 - loss: 0.4396 - val_accuracy: 0.7656 - val_loss: 0.4217\n",
            "Epoch 15: early stopping\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7810\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7651\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7810\n",
            "Time taken to train: 83.15 seconds\n",
            "\n",
            "Iteration 4 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 494ms/step - accuracy: 0.5474 - loss: 0.6025 - val_accuracy: 0.7312 - val_loss: 0.5089\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 799ms/step - accuracy: 0.7288 - loss: 0.4879 - val_accuracy: 0.7625 - val_loss: 0.4799\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7352 - loss: 0.4869 - val_accuracy: 0.7625 - val_loss: 0.4795\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7468 - loss: 0.4583 - val_accuracy: 0.7688 - val_loss: 0.4734\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.7530 - loss: 0.4608 - val_accuracy: 0.7688 - val_loss: 0.4803\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - accuracy: 0.7588 - loss: 0.4535 - val_accuracy: 0.7719 - val_loss: 0.4749\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 622ms/step - accuracy: 0.7488 - loss: 0.4536 - val_accuracy: 0.7719 - val_loss: 0.4752\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 418ms/step - accuracy: 0.7583 - loss: 0.4424 - val_accuracy: 0.7719 - val_loss: 0.4736\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - accuracy: 0.7617 - loss: 0.4493 - val_accuracy: 0.7719 - val_loss: 0.4727\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.7474 - loss: 0.4488 - val_accuracy: 0.7656 - val_loss: 0.4736\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 755ms/step - accuracy: 0.7370 - loss: 0.4714 - val_accuracy: 0.7688 - val_loss: 0.4726\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 416ms/step - accuracy: 0.7541 - loss: 0.4604 - val_accuracy: 0.7656 - val_loss: 0.4760\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7508 - loss: 0.4422 - val_accuracy: 0.7719 - val_loss: 0.4721\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step - accuracy: 0.7608 - loss: 0.4636 - val_accuracy: 0.7719 - val_loss: 0.4740\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 625ms/step - accuracy: 0.7394 - loss: 0.4662 - val_accuracy: 0.7688 - val_loss: 0.4817\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 370ms/step - accuracy: 0.7471 - loss: 0.4515 - val_accuracy: 0.7688 - val_loss: 0.4755\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - accuracy: 0.7638 - loss: 0.4588 - val_accuracy: 0.7656 - val_loss: 0.4771\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7442 - loss: 0.4503 - val_accuracy: 0.7688 - val_loss: 0.4741\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7649 - loss: 0.4356 - val_accuracy: 0.7719 - val_loss: 0.4733\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 589ms/step - accuracy: 0.7486 - loss: 0.4576 - val_accuracy: 0.7688 - val_loss: 0.4820\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7476 - loss: 0.4749 - val_accuracy: 0.7719 - val_loss: 0.4713\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - accuracy: 0.7467 - loss: 0.4506 - val_accuracy: 0.7625 - val_loss: 0.4753\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - accuracy: 0.7576 - loss: 0.4511 - val_accuracy: 0.7719 - val_loss: 0.4713\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.7610 - loss: 0.4478 - val_accuracy: 0.7719 - val_loss: 0.4721\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411ms/step - accuracy: 0.7624 - loss: 0.4430 - val_accuracy: 0.7719 - val_loss: 0.4745\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7590 - loss: 0.4522 - val_accuracy: 0.7719 - val_loss: 0.4708\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7567 - loss: 0.4444 - val_accuracy: 0.7719 - val_loss: 0.4735\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 564ms/step - accuracy: 0.7623 - loss: 0.4509 - val_accuracy: 0.7719 - val_loss: 0.4736\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.7511 - loss: 0.4421 - val_accuracy: 0.7719 - val_loss: 0.4754\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 414ms/step - accuracy: 0.7509 - loss: 0.4509 - val_accuracy: 0.7688 - val_loss: 0.4719\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7543 - loss: 0.4475 - val_accuracy: 0.7625 - val_loss: 0.4739\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 650ms/step - accuracy: 0.7579 - loss: 0.4689 - val_accuracy: 0.7719 - val_loss: 0.4728\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 434ms/step - accuracy: 0.7552 - loss: 0.4452 - val_accuracy: 0.7656 - val_loss: 0.4753\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.7439 - loss: 0.4515 - val_accuracy: 0.7719 - val_loss: 0.4703\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7566 - loss: 0.4346 - val_accuracy: 0.7688 - val_loss: 0.4726\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7579 - loss: 0.4429 - val_accuracy: 0.7688 - val_loss: 0.4735\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 0.7561 - loss: 0.4425 - val_accuracy: 0.7688 - val_loss: 0.4736\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 598ms/step - accuracy: 0.7593 - loss: 0.4538 - val_accuracy: 0.7688 - val_loss: 0.4721\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7586 - loss: 0.4393 - val_accuracy: 0.7688 - val_loss: 0.4728\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - accuracy: 0.7613 - loss: 0.4415 - val_accuracy: 0.7719 - val_loss: 0.4716\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7689 - loss: 0.4251 - val_accuracy: 0.7688 - val_loss: 0.4774\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 530ms/step - accuracy: 0.7544 - loss: 0.4385 - val_accuracy: 0.7656 - val_loss: 0.4753\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 421ms/step - accuracy: 0.7550 - loss: 0.4471 - val_accuracy: 0.7688 - val_loss: 0.4854\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7595 - loss: 0.4485 - val_accuracy: 0.7719 - val_loss: 0.4748\n",
            "Epoch 44: early stopping\n",
            "LSTM-Content w2v_cbow Accuracy 0.7401\n",
            "LSTM-Content w2v_cbow Precision 0.7785\n",
            "LSTM-Content w2v_cbow Recall 0.7401\n",
            "Time taken to train: 130.88 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 554ms/step - accuracy: 0.5649 - loss: 0.6077 - val_accuracy: 0.7312 - val_loss: 0.5034\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 419ms/step - accuracy: 0.7458 - loss: 0.4797 - val_accuracy: 0.7312 - val_loss: 0.4849\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 510ms/step - accuracy: 0.7187 - loss: 0.4883 - val_accuracy: 0.7312 - val_loss: 0.4814\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 550ms/step - accuracy: 0.7521 - loss: 0.4437 - val_accuracy: 0.7719 - val_loss: 0.4757\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418ms/step - accuracy: 0.7580 - loss: 0.4592 - val_accuracy: 0.7750 - val_loss: 0.4926\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7496 - loss: 0.4718 - val_accuracy: 0.7750 - val_loss: 0.4745\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.7653 - loss: 0.4576 - val_accuracy: 0.7750 - val_loss: 0.4778\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 560ms/step - accuracy: 0.7501 - loss: 0.4588 - val_accuracy: 0.7781 - val_loss: 0.4751\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 482ms/step - accuracy: 0.7523 - loss: 0.4565 - val_accuracy: 0.7781 - val_loss: 0.4756\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - accuracy: 0.7582 - loss: 0.4488 - val_accuracy: 0.7750 - val_loss: 0.4722\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7628 - loss: 0.4461 - val_accuracy: 0.7750 - val_loss: 0.4732\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7554 - loss: 0.4564 - val_accuracy: 0.7750 - val_loss: 0.4776\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 660ms/step - accuracy: 0.7580 - loss: 0.4530 - val_accuracy: 0.7750 - val_loss: 0.4787\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7590 - loss: 0.4428 - val_accuracy: 0.7719 - val_loss: 0.4765\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - accuracy: 0.7569 - loss: 0.4465 - val_accuracy: 0.7750 - val_loss: 0.4735\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7417 - loss: 0.4656 - val_accuracy: 0.7750 - val_loss: 0.4790\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7529 - loss: 0.4403 - val_accuracy: 0.7750 - val_loss: 0.4788\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.7516 - loss: 0.4603 - val_accuracy: 0.7750 - val_loss: 0.4812\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 509ms/step - accuracy: 0.7546 - loss: 0.4487 - val_accuracy: 0.7719 - val_loss: 0.4755\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.7563 - loss: 0.4484 - val_accuracy: 0.7750 - val_loss: 0.4774\n",
            "Epoch 20: early stopping\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7387\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7777\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7387\n",
            "Time taken to train: 59.55 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 636ms/step - accuracy: 0.5591 - loss: 0.6058 - val_accuracy: 0.7531 - val_loss: 0.5040\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.7564 - loss: 0.4675 - val_accuracy: 0.7719 - val_loss: 0.4792\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7463 - loss: 0.4746 - val_accuracy: 0.7688 - val_loss: 0.4766\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7495 - loss: 0.4666 - val_accuracy: 0.7781 - val_loss: 0.4722\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.7434 - loss: 0.4587 - val_accuracy: 0.7563 - val_loss: 0.4800\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7721 - loss: 0.4404 - val_accuracy: 0.7781 - val_loss: 0.4770\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7510 - loss: 0.4785 - val_accuracy: 0.7750 - val_loss: 0.4872\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.7647 - loss: 0.4452 - val_accuracy: 0.7781 - val_loss: 0.4690\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 570ms/step - accuracy: 0.7547 - loss: 0.4532 - val_accuracy: 0.7750 - val_loss: 0.4693\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7761 - loss: 0.4399 - val_accuracy: 0.7656 - val_loss: 0.4643\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389ms/step - accuracy: 0.7751 - loss: 0.4432 - val_accuracy: 0.7656 - val_loss: 0.4640\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 418ms/step - accuracy: 0.7926 - loss: 0.4539 - val_accuracy: 0.7625 - val_loss: 0.4673\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 528ms/step - accuracy: 0.7727 - loss: 0.4494 - val_accuracy: 0.7656 - val_loss: 0.4641\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7618 - loss: 0.4305 - val_accuracy: 0.7656 - val_loss: 0.4617\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7592 - loss: 0.4423 - val_accuracy: 0.7656 - val_loss: 0.4623\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7658 - loss: 0.4455 - val_accuracy: 0.7812 - val_loss: 0.4606\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7544 - loss: 0.4568 - val_accuracy: 0.7750 - val_loss: 0.4624\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 598ms/step - accuracy: 0.7729 - loss: 0.4479 - val_accuracy: 0.7719 - val_loss: 0.4590\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7743 - loss: 0.4518 - val_accuracy: 0.7781 - val_loss: 0.4598\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7744 - loss: 0.4460 - val_accuracy: 0.7656 - val_loss: 0.4586\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.7562 - loss: 0.4595 - val_accuracy: 0.7625 - val_loss: 0.4618\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7790 - loss: 0.4313 - val_accuracy: 0.7656 - val_loss: 0.4612\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 773ms/step - accuracy: 0.7743 - loss: 0.4286 - val_accuracy: 0.7594 - val_loss: 0.4586\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.7650 - loss: 0.4444 - val_accuracy: 0.7625 - val_loss: 0.4614\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7621 - loss: 0.4417 - val_accuracy: 0.7688 - val_loss: 0.4588\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7597 - loss: 0.4295 - val_accuracy: 0.7688 - val_loss: 0.4585\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7642 - loss: 0.4477 - val_accuracy: 0.7781 - val_loss: 0.4619\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 604ms/step - accuracy: 0.7667 - loss: 0.4551 - val_accuracy: 0.7656 - val_loss: 0.4586\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 438ms/step - accuracy: 0.7771 - loss: 0.4274 - val_accuracy: 0.7656 - val_loss: 0.4581\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7812 - loss: 0.4408 - val_accuracy: 0.7563 - val_loss: 0.4596\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7553 - loss: 0.4469 - val_accuracy: 0.7625 - val_loss: 0.4614\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7577 - loss: 0.4479 - val_accuracy: 0.7594 - val_loss: 0.4585\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.7777 - loss: 0.4407 - val_accuracy: 0.7625 - val_loss: 0.4613\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 772ms/step - accuracy: 0.7489 - loss: 0.4480 - val_accuracy: 0.7625 - val_loss: 0.4575\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7680 - loss: 0.4352 - val_accuracy: 0.7688 - val_loss: 0.4562\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7726 - loss: 0.4469 - val_accuracy: 0.7688 - val_loss: 0.4614\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7804 - loss: 0.4511 - val_accuracy: 0.7625 - val_loss: 0.4632\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 441ms/step - accuracy: 0.7668 - loss: 0.4329 - val_accuracy: 0.7594 - val_loss: 0.4645\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 624ms/step - accuracy: 0.7716 - loss: 0.4399 - val_accuracy: 0.7594 - val_loss: 0.4593\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.7657 - loss: 0.4348 - val_accuracy: 0.7688 - val_loss: 0.4623\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7637 - loss: 0.4416 - val_accuracy: 0.7625 - val_loss: 0.4610\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7791 - loss: 0.4297 - val_accuracy: 0.7594 - val_loss: 0.4650\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 789ms/step - accuracy: 0.7603 - loss: 0.4452 - val_accuracy: 0.7625 - val_loss: 0.4660\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7793 - loss: 0.4189 - val_accuracy: 0.7688 - val_loss: 0.4632\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7671 - loss: 0.4351 - val_accuracy: 0.7875 - val_loss: 0.4574\n",
            "Epoch 45: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7547\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7507\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7547\n",
            "Time taken to train: 126.69 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 606ms/step - accuracy: 0.6184 - loss: 0.5834 - val_accuracy: 0.7312 - val_loss: 0.5027\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7461 - loss: 0.4632 - val_accuracy: 0.7781 - val_loss: 0.4741\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7548 - loss: 0.4694 - val_accuracy: 0.7719 - val_loss: 0.4642\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 570ms/step - accuracy: 0.7570 - loss: 0.4566 - val_accuracy: 0.7750 - val_loss: 0.4698\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 483ms/step - accuracy: 0.7481 - loss: 0.4602 - val_accuracy: 0.7688 - val_loss: 0.4639\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392ms/step - accuracy: 0.7633 - loss: 0.4455 - val_accuracy: 0.7500 - val_loss: 0.4646\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - accuracy: 0.7441 - loss: 0.4614 - val_accuracy: 0.7625 - val_loss: 0.4633\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 556ms/step - accuracy: 0.7662 - loss: 0.4422 - val_accuracy: 0.7625 - val_loss: 0.4605\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 388ms/step - accuracy: 0.7761 - loss: 0.4369 - val_accuracy: 0.7688 - val_loss: 0.4617\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7749 - loss: 0.4441 - val_accuracy: 0.7625 - val_loss: 0.4594\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7914 - loss: 0.4311 - val_accuracy: 0.7750 - val_loss: 0.4608\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7672 - loss: 0.4432 - val_accuracy: 0.7531 - val_loss: 0.4574\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 596ms/step - accuracy: 0.7664 - loss: 0.4307 - val_accuracy: 0.7656 - val_loss: 0.4591\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.7714 - loss: 0.4478 - val_accuracy: 0.7688 - val_loss: 0.4616\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7707 - loss: 0.4418 - val_accuracy: 0.7656 - val_loss: 0.4577\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 427ms/step - accuracy: 0.7680 - loss: 0.4502 - val_accuracy: 0.7594 - val_loss: 0.4563\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7700 - loss: 0.4395 - val_accuracy: 0.7563 - val_loss: 0.4574\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 396ms/step - accuracy: 0.7618 - loss: 0.4444 - val_accuracy: 0.7625 - val_loss: 0.4550\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7735 - loss: 0.4422 - val_accuracy: 0.7594 - val_loss: 0.4584\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.7620 - loss: 0.4442 - val_accuracy: 0.7594 - val_loss: 0.4537\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 562ms/step - accuracy: 0.7704 - loss: 0.4426 - val_accuracy: 0.7688 - val_loss: 0.4575\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 426ms/step - accuracy: 0.7762 - loss: 0.4279 - val_accuracy: 0.7906 - val_loss: 0.4549\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7732 - loss: 0.4494 - val_accuracy: 0.7688 - val_loss: 0.4641\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - accuracy: 0.7742 - loss: 0.4358 - val_accuracy: 0.7656 - val_loss: 0.4566\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 513ms/step - accuracy: 0.7887 - loss: 0.4296 - val_accuracy: 0.7688 - val_loss: 0.4543\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 527ms/step - accuracy: 0.7831 - loss: 0.4244 - val_accuracy: 0.7656 - val_loss: 0.4656\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379ms/step - accuracy: 0.7773 - loss: 0.4157 - val_accuracy: 0.7656 - val_loss: 0.4525\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.7894 - loss: 0.4259 - val_accuracy: 0.7594 - val_loss: 0.4534\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 446ms/step - accuracy: 0.7696 - loss: 0.4267 - val_accuracy: 0.7625 - val_loss: 0.4530\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 601ms/step - accuracy: 0.7653 - loss: 0.4259 - val_accuracy: 0.7594 - val_loss: 0.4519\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7776 - loss: 0.4367 - val_accuracy: 0.7656 - val_loss: 0.4529\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - accuracy: 0.7713 - loss: 0.4290 - val_accuracy: 0.7625 - val_loss: 0.4524\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 388ms/step - accuracy: 0.7649 - loss: 0.4429 - val_accuracy: 0.7625 - val_loss: 0.4531\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7542 - loss: 0.4424 - val_accuracy: 0.7656 - val_loss: 0.4547\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 591ms/step - accuracy: 0.7634 - loss: 0.4321 - val_accuracy: 0.7688 - val_loss: 0.4538\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7694 - loss: 0.4401 - val_accuracy: 0.7688 - val_loss: 0.4592\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.7711 - loss: 0.4292 - val_accuracy: 0.7688 - val_loss: 0.4557\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.7665 - loss: 0.4353 - val_accuracy: 0.7625 - val_loss: 0.4545\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 744ms/step - accuracy: 0.7701 - loss: 0.4334 - val_accuracy: 0.7594 - val_loss: 0.4580\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374ms/step - accuracy: 0.7713 - loss: 0.4301 - val_accuracy: 0.7625 - val_loss: 0.4550\n",
            "Epoch 40: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7533\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7340\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7533\n",
            "Time taken to train: 124.18 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 610ms/step - accuracy: 0.5319 - loss: 0.6223 - val_accuracy: 0.7312 - val_loss: 0.5253\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.7268 - loss: 0.5097 - val_accuracy: 0.7312 - val_loss: 0.4879\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 752ms/step - accuracy: 0.7364 - loss: 0.4678 - val_accuracy: 0.7500 - val_loss: 0.4799\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7343 - loss: 0.4674 - val_accuracy: 0.7563 - val_loss: 0.4719\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7435 - loss: 0.4633 - val_accuracy: 0.7625 - val_loss: 0.4724\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 387ms/step - accuracy: 0.7532 - loss: 0.4599 - val_accuracy: 0.7656 - val_loss: 0.4689\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7606 - loss: 0.4418 - val_accuracy: 0.7812 - val_loss: 0.4676\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 613ms/step - accuracy: 0.7592 - loss: 0.4582 - val_accuracy: 0.7844 - val_loss: 0.4692\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7833 - loss: 0.4404 - val_accuracy: 0.7656 - val_loss: 0.4668\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7688 - loss: 0.4688 - val_accuracy: 0.7594 - val_loss: 0.4709\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step - accuracy: 0.7550 - loss: 0.4597 - val_accuracy: 0.7625 - val_loss: 0.4847\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.7711 - loss: 0.4272 - val_accuracy: 0.7656 - val_loss: 0.4708\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 561ms/step - accuracy: 0.7553 - loss: 0.4550 - val_accuracy: 0.7625 - val_loss: 0.4689\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 420ms/step - accuracy: 0.7545 - loss: 0.4556 - val_accuracy: 0.7625 - val_loss: 0.4706\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7482 - loss: 0.4504 - val_accuracy: 0.7594 - val_loss: 0.4701\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7583 - loss: 0.4428 - val_accuracy: 0.7563 - val_loss: 0.4620\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 543ms/step - accuracy: 0.7652 - loss: 0.4479 - val_accuracy: 0.7563 - val_loss: 0.4619\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7508 - loss: 0.4493 - val_accuracy: 0.7656 - val_loss: 0.4639\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7458 - loss: 0.4466 - val_accuracy: 0.7563 - val_loss: 0.4613\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.7721 - loss: 0.4460 - val_accuracy: 0.7656 - val_loss: 0.4636\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7582 - loss: 0.4490 - val_accuracy: 0.7656 - val_loss: 0.4660\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 791ms/step - accuracy: 0.7591 - loss: 0.4455 - val_accuracy: 0.7594 - val_loss: 0.4618\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 435ms/step - accuracy: 0.7604 - loss: 0.4431 - val_accuracy: 0.7594 - val_loss: 0.4603\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7691 - loss: 0.4393 - val_accuracy: 0.7625 - val_loss: 0.4582\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7658 - loss: 0.4341 - val_accuracy: 0.7688 - val_loss: 0.4576\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 589ms/step - accuracy: 0.7632 - loss: 0.4384 - val_accuracy: 0.7688 - val_loss: 0.4578\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379ms/step - accuracy: 0.7515 - loss: 0.4648 - val_accuracy: 0.7656 - val_loss: 0.4622\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.7639 - loss: 0.4403 - val_accuracy: 0.7688 - val_loss: 0.4620\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step - accuracy: 0.7672 - loss: 0.4375 - val_accuracy: 0.7688 - val_loss: 0.4554\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.7746 - loss: 0.4394 - val_accuracy: 0.7688 - val_loss: 0.4587\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 536ms/step - accuracy: 0.7730 - loss: 0.4267 - val_accuracy: 0.7906 - val_loss: 0.4616\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7722 - loss: 0.4361 - val_accuracy: 0.7656 - val_loss: 0.4654\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.7680 - loss: 0.4244 - val_accuracy: 0.7625 - val_loss: 0.4553\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7881 - loss: 0.4123 - val_accuracy: 0.7750 - val_loss: 0.4600\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7736 - loss: 0.4323 - val_accuracy: 0.7688 - val_loss: 0.4548\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 648ms/step - accuracy: 0.7685 - loss: 0.4206 - val_accuracy: 0.7719 - val_loss: 0.4542\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.7621 - loss: 0.4300 - val_accuracy: 0.7719 - val_loss: 0.4610\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7641 - loss: 0.4247 - val_accuracy: 0.7656 - val_loss: 0.4582\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - accuracy: 0.7785 - loss: 0.4186 - val_accuracy: 0.7625 - val_loss: 0.4597\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.7798 - loss: 0.4227 - val_accuracy: 0.7594 - val_loss: 0.4594\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 656ms/step - accuracy: 0.7609 - loss: 0.4253 - val_accuracy: 0.7656 - val_loss: 0.4653\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.7767 - loss: 0.4100 - val_accuracy: 0.7594 - val_loss: 0.4592\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7652 - loss: 0.4323 - val_accuracy: 0.7719 - val_loss: 0.4723\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.7553 - loss: 0.4296 - val_accuracy: 0.7688 - val_loss: 0.4632\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.7732 - loss: 0.4232 - val_accuracy: 0.7594 - val_loss: 0.4626\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 701ms/step - accuracy: 0.7676 - loss: 0.4287 - val_accuracy: 0.7625 - val_loss: 0.4662\n",
            "Epoch 46: early stopping\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7387\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.7124\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7387\n",
            "Time taken to train: 133.45 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 678ms/step - accuracy: 0.7240 - loss: 0.5853 - val_accuracy: 0.7312 - val_loss: 0.5060\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7373 - loss: 0.4761 - val_accuracy: 0.7563 - val_loss: 0.4785\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.7391 - loss: 0.4677 - val_accuracy: 0.7812 - val_loss: 0.4722\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7638 - loss: 0.4451 - val_accuracy: 0.7750 - val_loss: 0.4656\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7611 - loss: 0.4608 - val_accuracy: 0.7563 - val_loss: 0.4789\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 395ms/step - accuracy: 0.7490 - loss: 0.4591 - val_accuracy: 0.7750 - val_loss: 0.4643\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.7520 - loss: 0.4558 - val_accuracy: 0.7594 - val_loss: 0.4813\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.7716 - loss: 0.4554 - val_accuracy: 0.7531 - val_loss: 0.4650\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721ms/step - accuracy: 0.7665 - loss: 0.4437 - val_accuracy: 0.7531 - val_loss: 0.4623\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7435 - loss: 0.4556 - val_accuracy: 0.7656 - val_loss: 0.4706\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7610 - loss: 0.4589 - val_accuracy: 0.7656 - val_loss: 0.4620\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.7580 - loss: 0.4483 - val_accuracy: 0.7625 - val_loss: 0.4668\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7529 - loss: 0.4517 - val_accuracy: 0.7563 - val_loss: 0.4629\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 770ms/step - accuracy: 0.7737 - loss: 0.4377 - val_accuracy: 0.7656 - val_loss: 0.4585\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - accuracy: 0.7630 - loss: 0.4536 - val_accuracy: 0.7625 - val_loss: 0.4654\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.7720 - loss: 0.4520 - val_accuracy: 0.7625 - val_loss: 0.4590\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7735 - loss: 0.4288 - val_accuracy: 0.7563 - val_loss: 0.4592\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 747ms/step - accuracy: 0.7792 - loss: 0.4338 - val_accuracy: 0.7625 - val_loss: 0.4579\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.7547 - loss: 0.4575 - val_accuracy: 0.7625 - val_loss: 0.4646\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.7715 - loss: 0.4434 - val_accuracy: 0.7594 - val_loss: 0.4625\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389ms/step - accuracy: 0.7592 - loss: 0.4503 - val_accuracy: 0.7625 - val_loss: 0.4578\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7726 - loss: 0.4383 - val_accuracy: 0.7625 - val_loss: 0.4586\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 672ms/step - accuracy: 0.7707 - loss: 0.4302 - val_accuracy: 0.7594 - val_loss: 0.4607\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7812 - loss: 0.4407 - val_accuracy: 0.7719 - val_loss: 0.4644\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7832 - loss: 0.4362 - val_accuracy: 0.7625 - val_loss: 0.4550\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - accuracy: 0.7791 - loss: 0.4301 - val_accuracy: 0.7594 - val_loss: 0.4559\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7667 - loss: 0.4337 - val_accuracy: 0.7688 - val_loss: 0.4585\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 730ms/step - accuracy: 0.7788 - loss: 0.4193 - val_accuracy: 0.7563 - val_loss: 0.4558\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7581 - loss: 0.4423 - val_accuracy: 0.7625 - val_loss: 0.4599\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7786 - loss: 0.4408 - val_accuracy: 0.7750 - val_loss: 0.4575\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.7608 - loss: 0.4367 - val_accuracy: 0.7688 - val_loss: 0.4557\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.7738 - loss: 0.4317 - val_accuracy: 0.7656 - val_loss: 0.4522\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 808ms/step - accuracy: 0.7680 - loss: 0.4357 - val_accuracy: 0.7688 - val_loss: 0.4632\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7800 - loss: 0.4251 - val_accuracy: 0.7656 - val_loss: 0.4588\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 387ms/step - accuracy: 0.7994 - loss: 0.3992 - val_accuracy: 0.7688 - val_loss: 0.4534\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 419ms/step - accuracy: 0.7823 - loss: 0.4185 - val_accuracy: 0.7594 - val_loss: 0.4546\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7732 - loss: 0.4171 - val_accuracy: 0.7656 - val_loss: 0.4570\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 748ms/step - accuracy: 0.7743 - loss: 0.4182 - val_accuracy: 0.7625 - val_loss: 0.4485\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - accuracy: 0.7888 - loss: 0.4225 - val_accuracy: 0.7625 - val_loss: 0.4577\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 425ms/step - accuracy: 0.7767 - loss: 0.4086 - val_accuracy: 0.7656 - val_loss: 0.4593\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.7818 - loss: 0.4102 - val_accuracy: 0.7656 - val_loss: 0.4613\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 690ms/step - accuracy: 0.7706 - loss: 0.4227 - val_accuracy: 0.7625 - val_loss: 0.4455\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 382ms/step - accuracy: 0.7748 - loss: 0.4102 - val_accuracy: 0.7719 - val_loss: 0.4616\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.7726 - loss: 0.4178 - val_accuracy: 0.7688 - val_loss: 0.4595\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7747 - loss: 0.4160 - val_accuracy: 0.7625 - val_loss: 0.4621\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 528ms/step - accuracy: 0.7801 - loss: 0.3983 - val_accuracy: 0.7656 - val_loss: 0.4593\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 496ms/step - accuracy: 0.7688 - loss: 0.4141 - val_accuracy: 0.7625 - val_loss: 0.4588\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419ms/step - accuracy: 0.7653 - loss: 0.4137 - val_accuracy: 0.7625 - val_loss: 0.4615\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.8067 - loss: 0.3766 - val_accuracy: 0.7750 - val_loss: 0.4712\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 519ms/step - accuracy: 0.7808 - loss: 0.3962 - val_accuracy: 0.7656 - val_loss: 0.4763\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7358\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7088\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7358\n",
            "Time taken to train: 149.16 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.7085 - loss: 0.5771 - val_accuracy: 0.7781 - val_loss: 0.4865\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 907ms/step - accuracy: 0.7446 - loss: 0.5180 - val_accuracy: 0.7625 - val_loss: 0.5121\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.7251 - loss: 0.5123 - val_accuracy: 0.7656 - val_loss: 0.4711\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7435 - loss: 0.4591 - val_accuracy: 0.7688 - val_loss: 0.4726\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7421 - loss: 0.4610 - val_accuracy: 0.7656 - val_loss: 0.4830\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7432 - loss: 0.4677 - val_accuracy: 0.7719 - val_loss: 0.4752\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.7450 - loss: 0.4531 - val_accuracy: 0.7688 - val_loss: 0.4751\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709ms/step - accuracy: 0.7478 - loss: 0.4475 - val_accuracy: 0.7719 - val_loss: 0.4739\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 704ms/step - accuracy: 0.7389 - loss: 0.4663 - val_accuracy: 0.7719 - val_loss: 0.4746\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7575 - loss: 0.4366 - val_accuracy: 0.7719 - val_loss: 0.4776\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7427 - loss: 0.4766 - val_accuracy: 0.7719 - val_loss: 0.4721\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.7543 - loss: 0.4606 - val_accuracy: 0.7656 - val_loss: 0.4800\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7603 - loss: 0.4565 - val_accuracy: 0.7719 - val_loss: 0.4718\n",
            "Epoch 13: early stopping\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7372\n",
            "BiLSTM-Content w2v_cbow Precision 0.7745\n",
            "BiLSTM-Content w2v_cbow Recall 0.7372\n",
            "Time taken to train: 78.90 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 902ms/step - accuracy: 0.6856 - loss: 0.5771 - val_accuracy: 0.7656 - val_loss: 0.5211\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 959ms/step - accuracy: 0.7239 - loss: 0.5019 - val_accuracy: 0.7625 - val_loss: 0.5123\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.7488 - loss: 0.4580 - val_accuracy: 0.7781 - val_loss: 0.4927\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 689ms/step - accuracy: 0.7505 - loss: 0.4705 - val_accuracy: 0.7375 - val_loss: 0.4974\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 852ms/step - accuracy: 0.7459 - loss: 0.4426 - val_accuracy: 0.7688 - val_loss: 0.4836\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 771ms/step - accuracy: 0.7317 - loss: 0.4718 - val_accuracy: 0.7375 - val_loss: 0.4835\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.7249 - loss: 0.4798 - val_accuracy: 0.7375 - val_loss: 0.4832\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7488 - loss: 0.4779 - val_accuracy: 0.7719 - val_loss: 0.4766\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 688ms/step - accuracy: 0.7349 - loss: 0.4707 - val_accuracy: 0.7719 - val_loss: 0.4865\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7575 - loss: 0.4604 - val_accuracy: 0.7781 - val_loss: 0.4778\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7575 - loss: 0.4526 - val_accuracy: 0.7781 - val_loss: 0.4753\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7545 - loss: 0.4493 - val_accuracy: 0.7719 - val_loss: 0.4765\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 710ms/step - accuracy: 0.7475 - loss: 0.4589 - val_accuracy: 0.7750 - val_loss: 0.4758\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 706ms/step - accuracy: 0.7483 - loss: 0.4517 - val_accuracy: 0.7781 - val_loss: 0.4791\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7716 - loss: 0.4439 - val_accuracy: 0.7781 - val_loss: 0.4745\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7403 - loss: 0.4615 - val_accuracy: 0.7750 - val_loss: 0.4741\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 689ms/step - accuracy: 0.7658 - loss: 0.4336 - val_accuracy: 0.7781 - val_loss: 0.4750\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687ms/step - accuracy: 0.7569 - loss: 0.4482 - val_accuracy: 0.7750 - val_loss: 0.4846\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973ms/step - accuracy: 0.7472 - loss: 0.4536 - val_accuracy: 0.7781 - val_loss: 0.4738\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7625 - loss: 0.4488 - val_accuracy: 0.7750 - val_loss: 0.4740\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7621 - loss: 0.4334 - val_accuracy: 0.7781 - val_loss: 0.4730\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7633 - loss: 0.4330 - val_accuracy: 0.7812 - val_loss: 0.4766\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7599 - loss: 0.4380 - val_accuracy: 0.7750 - val_loss: 0.4720\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7547 - loss: 0.4385 - val_accuracy: 0.7781 - val_loss: 0.4800\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7598 - loss: 0.4321 - val_accuracy: 0.7750 - val_loss: 0.4715\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 705ms/step - accuracy: 0.7575 - loss: 0.4318 - val_accuracy: 0.7812 - val_loss: 0.4792\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 760ms/step - accuracy: 0.7585 - loss: 0.4299 - val_accuracy: 0.7781 - val_loss: 0.4740\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7623 - loss: 0.4234 - val_accuracy: 0.7781 - val_loss: 0.4779\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7550 - loss: 0.4212 - val_accuracy: 0.7719 - val_loss: 0.4829\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 697ms/step - accuracy: 0.7617 - loss: 0.4212 - val_accuracy: 0.7750 - val_loss: 0.4778\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7610 - loss: 0.4195 - val_accuracy: 0.7812 - val_loss: 0.4816\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 732ms/step - accuracy: 0.7555 - loss: 0.4255 - val_accuracy: 0.7781 - val_loss: 0.4843\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 694ms/step - accuracy: 0.7643 - loss: 0.4337 - val_accuracy: 0.7750 - val_loss: 0.5169\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.7646 - loss: 0.4197 - val_accuracy: 0.7656 - val_loss: 0.4894\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 708ms/step - accuracy: 0.7780 - loss: 0.4017 - val_accuracy: 0.7750 - val_loss: 0.4944\n",
            "Epoch 35: early stopping\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7387\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7777\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7387\n",
            "Time taken to train: 172.06 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5719 - loss: 0.5973 - val_accuracy: 0.7719 - val_loss: 0.4911\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 958ms/step - accuracy: 0.7585 - loss: 0.4760 - val_accuracy: 0.7750 - val_loss: 0.4804\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7410 - loss: 0.4753 - val_accuracy: 0.7594 - val_loss: 0.4706\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.7704 - loss: 0.4599 - val_accuracy: 0.7594 - val_loss: 0.4771\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.7589 - loss: 0.4529 - val_accuracy: 0.7781 - val_loss: 0.4735\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 708ms/step - accuracy: 0.7630 - loss: 0.4584 - val_accuracy: 0.7750 - val_loss: 0.4729\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.7441 - loss: 0.4452 - val_accuracy: 0.7750 - val_loss: 0.4652\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 702ms/step - accuracy: 0.7606 - loss: 0.4619 - val_accuracy: 0.7625 - val_loss: 0.4681\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7527 - loss: 0.4628 - val_accuracy: 0.7563 - val_loss: 0.4644\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 704ms/step - accuracy: 0.7540 - loss: 0.4455 - val_accuracy: 0.7750 - val_loss: 0.4642\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7826 - loss: 0.4259 - val_accuracy: 0.7844 - val_loss: 0.4620\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7642 - loss: 0.4560 - val_accuracy: 0.7594 - val_loss: 0.4678\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 0.7471 - loss: 0.4685 - val_accuracy: 0.7563 - val_loss: 0.4620\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.7668 - loss: 0.4598 - val_accuracy: 0.7594 - val_loss: 0.4635\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7580 - loss: 0.4501 - val_accuracy: 0.7906 - val_loss: 0.4602\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7667 - loss: 0.4396 - val_accuracy: 0.7594 - val_loss: 0.4611\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7753 - loss: 0.4381 - val_accuracy: 0.7750 - val_loss: 0.4587\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7653 - loss: 0.4412 - val_accuracy: 0.7625 - val_loss: 0.4633\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714ms/step - accuracy: 0.7725 - loss: 0.4393 - val_accuracy: 0.7625 - val_loss: 0.4589\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.8001 - loss: 0.4183 - val_accuracy: 0.7719 - val_loss: 0.4604\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7539 - loss: 0.4460 - val_accuracy: 0.7594 - val_loss: 0.4566\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7865 - loss: 0.4284 - val_accuracy: 0.7656 - val_loss: 0.4567\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 708ms/step - accuracy: 0.7750 - loss: 0.4224 - val_accuracy: 0.7781 - val_loss: 0.4548\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 711ms/step - accuracy: 0.7659 - loss: 0.4323 - val_accuracy: 0.7594 - val_loss: 0.4560\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 830ms/step - accuracy: 0.7631 - loss: 0.4411 - val_accuracy: 0.7719 - val_loss: 0.4564\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7637 - loss: 0.4360 - val_accuracy: 0.7625 - val_loss: 0.4575\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 724ms/step - accuracy: 0.7643 - loss: 0.4364 - val_accuracy: 0.7656 - val_loss: 0.4586\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 850ms/step - accuracy: 0.7675 - loss: 0.4189 - val_accuracy: 0.7688 - val_loss: 0.4571\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709ms/step - accuracy: 0.7689 - loss: 0.4282 - val_accuracy: 0.7563 - val_loss: 0.4673\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 694ms/step - accuracy: 0.7753 - loss: 0.4337 - val_accuracy: 0.7688 - val_loss: 0.4584\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.7688 - loss: 0.4275 - val_accuracy: 0.7625 - val_loss: 0.4556\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 710ms/step - accuracy: 0.7756 - loss: 0.4248 - val_accuracy: 0.7656 - val_loss: 0.4619\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.7637 - loss: 0.4317 - val_accuracy: 0.7688 - val_loss: 0.4585\n",
            "Epoch 33: early stopping\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7181\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 169.97 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5716 - loss: 0.6014 - val_accuracy: 0.7719 - val_loss: 0.4983\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7572 - loss: 0.4625 - val_accuracy: 0.7688 - val_loss: 0.4742\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 706ms/step - accuracy: 0.7490 - loss: 0.4727 - val_accuracy: 0.7719 - val_loss: 0.4686\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7448 - loss: 0.4629 - val_accuracy: 0.7656 - val_loss: 0.4720\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7728 - loss: 0.4199 - val_accuracy: 0.7688 - val_loss: 0.4669\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7700 - loss: 0.4474 - val_accuracy: 0.7656 - val_loss: 0.4725\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 741ms/step - accuracy: 0.7538 - loss: 0.4556 - val_accuracy: 0.7563 - val_loss: 0.4601\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 714ms/step - accuracy: 0.7626 - loss: 0.4667 - val_accuracy: 0.7625 - val_loss: 0.4658\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7583 - loss: 0.4501 - val_accuracy: 0.7750 - val_loss: 0.4686\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7854 - loss: 0.4298 - val_accuracy: 0.7594 - val_loss: 0.4597\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7521 - loss: 0.4456 - val_accuracy: 0.7625 - val_loss: 0.4629\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7676 - loss: 0.4458 - val_accuracy: 0.7563 - val_loss: 0.4579\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7657 - loss: 0.4379 - val_accuracy: 0.7625 - val_loss: 0.4572\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.7819 - loss: 0.4305 - val_accuracy: 0.7594 - val_loss: 0.4564\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 711ms/step - accuracy: 0.7766 - loss: 0.4356 - val_accuracy: 0.7531 - val_loss: 0.4572\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7509 - loss: 0.4573 - val_accuracy: 0.7594 - val_loss: 0.4550\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7596 - loss: 0.4325 - val_accuracy: 0.7688 - val_loss: 0.4521\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7717 - loss: 0.4347 - val_accuracy: 0.7656 - val_loss: 0.4536\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7663 - loss: 0.4358 - val_accuracy: 0.7594 - val_loss: 0.4518\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 727ms/step - accuracy: 0.7667 - loss: 0.4381 - val_accuracy: 0.7594 - val_loss: 0.4539\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 712ms/step - accuracy: 0.7884 - loss: 0.4333 - val_accuracy: 0.7656 - val_loss: 0.4529\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 934ms/step - accuracy: 0.7747 - loss: 0.4300 - val_accuracy: 0.7625 - val_loss: 0.4525\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 744ms/step - accuracy: 0.7614 - loss: 0.4278 - val_accuracy: 0.7781 - val_loss: 0.4530\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.7738 - loss: 0.4347 - val_accuracy: 0.7594 - val_loss: 0.4663\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7861 - loss: 0.4125 - val_accuracy: 0.7594 - val_loss: 0.4533\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7677 - loss: 0.4406 - val_accuracy: 0.7625 - val_loss: 0.4620\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7707 - loss: 0.4338 - val_accuracy: 0.7688 - val_loss: 0.4507\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 699ms/step - accuracy: 0.7729 - loss: 0.4312 - val_accuracy: 0.7625 - val_loss: 0.4553\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 719ms/step - accuracy: 0.7686 - loss: 0.4262 - val_accuracy: 0.7688 - val_loss: 0.4521\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7670 - loss: 0.4235 - val_accuracy: 0.7688 - val_loss: 0.4593\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 699ms/step - accuracy: 0.7878 - loss: 0.4116 - val_accuracy: 0.7625 - val_loss: 0.4545\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7728 - loss: 0.4327 - val_accuracy: 0.7625 - val_loss: 0.4682\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 977ms/step - accuracy: 0.7670 - loss: 0.4370 - val_accuracy: 0.7625 - val_loss: 0.4554\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7784 - loss: 0.4156 - val_accuracy: 0.7656 - val_loss: 0.4656\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 700ms/step - accuracy: 0.7672 - loss: 0.4391 - val_accuracy: 0.7656 - val_loss: 0.4562\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 936ms/step - accuracy: 0.7816 - loss: 0.4111 - val_accuracy: 0.7625 - val_loss: 0.4600\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 0.7712 - loss: 0.4217 - val_accuracy: 0.7719 - val_loss: 0.4565\n",
            "Epoch 37: early stopping\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7504\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7342\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7504\n",
            "Time taken to train: 187.24 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7499 - loss: 0.5805 - val_accuracy: 0.7563 - val_loss: 0.5036\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 942ms/step - accuracy: 0.7530 - loss: 0.4885 - val_accuracy: 0.7500 - val_loss: 0.4855\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7496 - loss: 0.4633 - val_accuracy: 0.7594 - val_loss: 0.4717\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7582 - loss: 0.4460 - val_accuracy: 0.7656 - val_loss: 0.4779\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7683 - loss: 0.4687 - val_accuracy: 0.7625 - val_loss: 0.4781\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7681 - loss: 0.4489 - val_accuracy: 0.7594 - val_loss: 0.4697\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870ms/step - accuracy: 0.7649 - loss: 0.4408 - val_accuracy: 0.7625 - val_loss: 0.4683\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 710ms/step - accuracy: 0.7592 - loss: 0.4410 - val_accuracy: 0.7656 - val_loss: 0.4715\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714ms/step - accuracy: 0.7595 - loss: 0.4579 - val_accuracy: 0.7563 - val_loss: 0.4672\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7689 - loss: 0.4324 - val_accuracy: 0.7594 - val_loss: 0.4792\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 0.7612 - loss: 0.4562 - val_accuracy: 0.7875 - val_loss: 0.4664\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 711ms/step - accuracy: 0.7661 - loss: 0.4436 - val_accuracy: 0.7594 - val_loss: 0.4786\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 708ms/step - accuracy: 0.7646 - loss: 0.4431 - val_accuracy: 0.7594 - val_loss: 0.4655\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 707ms/step - accuracy: 0.7713 - loss: 0.4441 - val_accuracy: 0.7594 - val_loss: 0.4679\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 876ms/step - accuracy: 0.7643 - loss: 0.4438 - val_accuracy: 0.7594 - val_loss: 0.4705\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 696ms/step - accuracy: 0.7647 - loss: 0.4355 - val_accuracy: 0.7563 - val_loss: 0.4651\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7733 - loss: 0.4337 - val_accuracy: 0.7563 - val_loss: 0.4696\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7725 - loss: 0.4271 - val_accuracy: 0.7563 - val_loss: 0.4634\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 708ms/step - accuracy: 0.7559 - loss: 0.4390 - val_accuracy: 0.7594 - val_loss: 0.4665\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.7713 - loss: 0.4213 - val_accuracy: 0.7625 - val_loss: 0.4609\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 700ms/step - accuracy: 0.7682 - loss: 0.4337 - val_accuracy: 0.7750 - val_loss: 0.4628\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.7702 - loss: 0.4349 - val_accuracy: 0.7594 - val_loss: 0.4635\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7633 - loss: 0.4330 - val_accuracy: 0.7563 - val_loss: 0.4623\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7823 - loss: 0.4288 - val_accuracy: 0.7563 - val_loss: 0.4720\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7785 - loss: 0.4112 - val_accuracy: 0.7594 - val_loss: 0.4648\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 783ms/step - accuracy: 0.7651 - loss: 0.4183 - val_accuracy: 0.7625 - val_loss: 0.4690\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 697ms/step - accuracy: 0.7760 - loss: 0.4089 - val_accuracy: 0.7594 - val_loss: 0.4685\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 998ms/step - accuracy: 0.7880 - loss: 0.4203 - val_accuracy: 0.7563 - val_loss: 0.4718\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7737 - loss: 0.4092 - val_accuracy: 0.7594 - val_loss: 0.4711\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 704ms/step - accuracy: 0.7643 - loss: 0.4222 - val_accuracy: 0.7688 - val_loss: 0.4818\n",
            "Epoch 30: early stopping\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7474\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.7200\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7474\n",
            "Time taken to train: 158.08 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5947 - loss: 0.6019 - val_accuracy: 0.7469 - val_loss: 0.4874\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 940ms/step - accuracy: 0.7357 - loss: 0.4927 - val_accuracy: 0.7563 - val_loss: 0.4910\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 697ms/step - accuracy: 0.7359 - loss: 0.4743 - val_accuracy: 0.7688 - val_loss: 0.4649\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 705ms/step - accuracy: 0.7726 - loss: 0.4447 - val_accuracy: 0.7563 - val_loss: 0.4788\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7517 - loss: 0.4675 - val_accuracy: 0.7500 - val_loss: 0.4624\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7652 - loss: 0.4424 - val_accuracy: 0.7594 - val_loss: 0.4638\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.7614 - loss: 0.4626 - val_accuracy: 0.7625 - val_loss: 0.4615\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7563 - loss: 0.4543 - val_accuracy: 0.7594 - val_loss: 0.4646\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 700ms/step - accuracy: 0.7631 - loss: 0.4561 - val_accuracy: 0.7688 - val_loss: 0.4588\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7703 - loss: 0.4507 - val_accuracy: 0.7594 - val_loss: 0.4633\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 904ms/step - accuracy: 0.7849 - loss: 0.4273 - val_accuracy: 0.7594 - val_loss: 0.4588\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 711ms/step - accuracy: 0.7624 - loss: 0.4432 - val_accuracy: 0.7594 - val_loss: 0.4625\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.7662 - loss: 0.4545 - val_accuracy: 0.7625 - val_loss: 0.4593\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 710ms/step - accuracy: 0.7604 - loss: 0.4617 - val_accuracy: 0.7594 - val_loss: 0.4621\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7730 - loss: 0.4258 - val_accuracy: 0.7625 - val_loss: 0.4582\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.7671 - loss: 0.4445 - val_accuracy: 0.7688 - val_loss: 0.4593\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 706ms/step - accuracy: 0.7682 - loss: 0.4405 - val_accuracy: 0.7688 - val_loss: 0.4635\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.7612 - loss: 0.4317 - val_accuracy: 0.7625 - val_loss: 0.4573\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 706ms/step - accuracy: 0.7689 - loss: 0.4456 - val_accuracy: 0.7594 - val_loss: 0.4643\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7502 - loss: 0.4544 - val_accuracy: 0.7594 - val_loss: 0.4583\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 881ms/step - accuracy: 0.7676 - loss: 0.4450 - val_accuracy: 0.7656 - val_loss: 0.4599\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.7715 - loss: 0.4287 - val_accuracy: 0.7594 - val_loss: 0.4555\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - accuracy: 0.7747 - loss: 0.4358 - val_accuracy: 0.7594 - val_loss: 0.4574\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.7736 - loss: 0.4496 - val_accuracy: 0.7656 - val_loss: 0.4714\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 695ms/step - accuracy: 0.7654 - loss: 0.4426 - val_accuracy: 0.7563 - val_loss: 0.4548\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.7590 - loss: 0.4349 - val_accuracy: 0.7563 - val_loss: 0.4604\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7772 - loss: 0.4195 - val_accuracy: 0.7594 - val_loss: 0.4540\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7776 - loss: 0.4270 - val_accuracy: 0.7625 - val_loss: 0.4545\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7726 - loss: 0.4258 - val_accuracy: 0.7625 - val_loss: 0.4564\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 709ms/step - accuracy: 0.7949 - loss: 0.4052 - val_accuracy: 0.7781 - val_loss: 0.4521\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 698ms/step - accuracy: 0.7772 - loss: 0.4249 - val_accuracy: 0.7625 - val_loss: 0.4595\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 750ms/step - accuracy: 0.7713 - loss: 0.4352 - val_accuracy: 0.7594 - val_loss: 0.4623\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.7721 - loss: 0.4170 - val_accuracy: 0.7906 - val_loss: 0.4548\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 895ms/step - accuracy: 0.7881 - loss: 0.4162 - val_accuracy: 0.7719 - val_loss: 0.4574\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 0.7832 - loss: 0.4164 - val_accuracy: 0.7688 - val_loss: 0.4607\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702ms/step - accuracy: 0.7844 - loss: 0.4164 - val_accuracy: 0.7656 - val_loss: 0.4561\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.7772 - loss: 0.4134 - val_accuracy: 0.7625 - val_loss: 0.4576\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.7742 - loss: 0.4136 - val_accuracy: 0.7625 - val_loss: 0.4511\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707ms/step - accuracy: 0.7859 - loss: 0.4005 - val_accuracy: 0.7719 - val_loss: 0.4628\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 699ms/step - accuracy: 0.7723 - loss: 0.4143 - val_accuracy: 0.7625 - val_loss: 0.4589\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7762 - loss: 0.4029 - val_accuracy: 0.7656 - val_loss: 0.4623\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7967 - loss: 0.3847 - val_accuracy: 0.7656 - val_loss: 0.4651\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 716ms/step - accuracy: 0.7757 - loss: 0.4032 - val_accuracy: 0.7656 - val_loss: 0.4713\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7827 - loss: 0.3989 - val_accuracy: 0.7688 - val_loss: 0.4839\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7608 - loss: 0.4055 - val_accuracy: 0.7563 - val_loss: 0.4691\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702ms/step - accuracy: 0.7663 - loss: 0.3911 - val_accuracy: 0.7594 - val_loss: 0.4690\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 992ms/step - accuracy: 0.7920 - loss: 0.3783 - val_accuracy: 0.7594 - val_loss: 0.4763\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694ms/step - accuracy: 0.7826 - loss: 0.3812 - val_accuracy: 0.7625 - val_loss: 0.4818\n",
            "Epoch 48: early stopping\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7445\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7238\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7445\n",
            "Time taken to train: 241.47 seconds\n",
            "\n",
            "Iteration 5 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_cbow embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 503ms/step - accuracy: 0.6856 - loss: 0.5866 - val_accuracy: 0.7000 - val_loss: 0.5221\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7427 - loss: 0.5113 - val_accuracy: 0.7000 - val_loss: 0.5053\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7524 - loss: 0.4739 - val_accuracy: 0.7000 - val_loss: 0.5038\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 806ms/step - accuracy: 0.7708 - loss: 0.4600 - val_accuracy: 0.7094 - val_loss: 0.5014\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.7525 - loss: 0.4747 - val_accuracy: 0.7094 - val_loss: 0.5039\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7480 - loss: 0.4828 - val_accuracy: 0.7063 - val_loss: 0.5008\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.7648 - loss: 0.4540 - val_accuracy: 0.7063 - val_loss: 0.5013\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7558 - loss: 0.4708 - val_accuracy: 0.7094 - val_loss: 0.5009\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 627ms/step - accuracy: 0.7477 - loss: 0.4764 - val_accuracy: 0.7063 - val_loss: 0.5027\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376ms/step - accuracy: 0.7482 - loss: 0.4582 - val_accuracy: 0.7000 - val_loss: 0.5011\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - accuracy: 0.7402 - loss: 0.4739 - val_accuracy: 0.7000 - val_loss: 0.5018\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.7547 - loss: 0.4637 - val_accuracy: 0.7031 - val_loss: 0.5022\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624ms/step - accuracy: 0.7544 - loss: 0.4566 - val_accuracy: 0.7000 - val_loss: 0.5030\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 371ms/step - accuracy: 0.7438 - loss: 0.4633 - val_accuracy: 0.7063 - val_loss: 0.5048\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - accuracy: 0.7587 - loss: 0.4525 - val_accuracy: 0.7031 - val_loss: 0.5072\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7601 - loss: 0.4594 - val_accuracy: 0.7000 - val_loss: 0.5074\n",
            "Epoch 16: early stopping\n",
            "LSTM-Content w2v_cbow Accuracy 0.7591\n",
            "LSTM-Content w2v_cbow Precision 0.7873\n",
            "LSTM-Content w2v_cbow Recall 0.7591\n",
            "Time taken to train: 48.84 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - accuracy: 0.6158 - loss: 0.5918 - val_accuracy: 0.7312 - val_loss: 0.5200\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - accuracy: 0.7334 - loss: 0.4937 - val_accuracy: 0.7312 - val_loss: 0.5089\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.7333 - loss: 0.4821 - val_accuracy: 0.7375 - val_loss: 0.5029\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 659ms/step - accuracy: 0.7383 - loss: 0.4801 - val_accuracy: 0.7094 - val_loss: 0.5020\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - accuracy: 0.7377 - loss: 0.4774 - val_accuracy: 0.7094 - val_loss: 0.5082\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 0.7442 - loss: 0.4903 - val_accuracy: 0.7094 - val_loss: 0.5058\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - accuracy: 0.7402 - loss: 0.4789 - val_accuracy: 0.7406 - val_loss: 0.5069\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - accuracy: 0.7215 - loss: 0.4747 - val_accuracy: 0.7125 - val_loss: 0.5040\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.7525 - loss: 0.4706 - val_accuracy: 0.7094 - val_loss: 0.5048\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 567ms/step - accuracy: 0.7506 - loss: 0.4628 - val_accuracy: 0.7063 - val_loss: 0.5055\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7612 - loss: 0.4544 - val_accuracy: 0.7063 - val_loss: 0.5077\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - accuracy: 0.7624 - loss: 0.4660 - val_accuracy: 0.7063 - val_loss: 0.5088\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.7453 - loss: 0.4740 - val_accuracy: 0.7094 - val_loss: 0.5070\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7428 - loss: 0.4699 - val_accuracy: 0.7094 - val_loss: 0.5062\n",
            "Epoch 14: early stopping\n",
            "LSTM-CNN-Content w2v_cbow Accuracy 0.7591\n",
            "LSTM-CNN-Content w2v_cbow Precision 0.7885\n",
            "LSTM-CNN-Content w2v_cbow Recall 0.7591\n",
            "Time taken to train: 37.13 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 970ms/step - accuracy: 0.5404 - loss: 0.6101 - val_accuracy: 0.7312 - val_loss: 0.5359\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402ms/step - accuracy: 0.7535 - loss: 0.5002 - val_accuracy: 0.7031 - val_loss: 0.5152\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.7481 - loss: 0.4798 - val_accuracy: 0.7375 - val_loss: 0.5093\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.7362 - loss: 0.4869 - val_accuracy: 0.7125 - val_loss: 0.4982\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.7566 - loss: 0.4641 - val_accuracy: 0.7156 - val_loss: 0.4956\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 653ms/step - accuracy: 0.7679 - loss: 0.4518 - val_accuracy: 0.7156 - val_loss: 0.4924\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 395ms/step - accuracy: 0.7521 - loss: 0.4491 - val_accuracy: 0.7156 - val_loss: 0.4909\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.7619 - loss: 0.4587 - val_accuracy: 0.7156 - val_loss: 0.4909\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.7463 - loss: 0.4621 - val_accuracy: 0.7188 - val_loss: 0.4906\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 781ms/step - accuracy: 0.7507 - loss: 0.4586 - val_accuracy: 0.7125 - val_loss: 0.4889\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 432ms/step - accuracy: 0.7583 - loss: 0.4488 - val_accuracy: 0.7437 - val_loss: 0.4874\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - accuracy: 0.7444 - loss: 0.4555 - val_accuracy: 0.7406 - val_loss: 0.4860\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.7763 - loss: 0.4410 - val_accuracy: 0.7656 - val_loss: 0.4861\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.7674 - loss: 0.4445 - val_accuracy: 0.7437 - val_loss: 0.4864\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 760ms/step - accuracy: 0.7501 - loss: 0.4586 - val_accuracy: 0.7500 - val_loss: 0.4871\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - accuracy: 0.7487 - loss: 0.4488 - val_accuracy: 0.7437 - val_loss: 0.4868\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 449ms/step - accuracy: 0.7539 - loss: 0.4545 - val_accuracy: 0.7375 - val_loss: 0.4863\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 403ms/step - accuracy: 0.7478 - loss: 0.4486 - val_accuracy: 0.7406 - val_loss: 0.4873\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 668ms/step - accuracy: 0.7414 - loss: 0.4513 - val_accuracy: 0.7437 - val_loss: 0.4873\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.7448 - loss: 0.4641 - val_accuracy: 0.7563 - val_loss: 0.4887\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7644 - loss: 0.4528 - val_accuracy: 0.7406 - val_loss: 0.4883\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7823 - loss: 0.4245 - val_accuracy: 0.7406 - val_loss: 0.4896\n",
            "Epoch 22: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7810\n",
            "LSTM-00CNN-ContentNets w2v_cbow Precision 0.7647\n",
            "LSTM-00CNN-ContentNets w2v_cbow Recall 0.7810\n",
            "Time taken to train: 70.55 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 643ms/step - accuracy: 0.5767 - loss: 0.6014 - val_accuracy: 0.7031 - val_loss: 0.5246\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.7537 - loss: 0.4941 - val_accuracy: 0.7094 - val_loss: 0.5021\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.7530 - loss: 0.4696 - val_accuracy: 0.7437 - val_loss: 0.4917\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 774ms/step - accuracy: 0.7527 - loss: 0.4609 - val_accuracy: 0.7156 - val_loss: 0.4853\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7641 - loss: 0.4581 - val_accuracy: 0.7156 - val_loss: 0.4869\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - accuracy: 0.7610 - loss: 0.4470 - val_accuracy: 0.7156 - val_loss: 0.4845\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - accuracy: 0.7563 - loss: 0.4561 - val_accuracy: 0.7437 - val_loss: 0.4836\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.7507 - loss: 0.4810 - val_accuracy: 0.7437 - val_loss: 0.4836\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 803ms/step - accuracy: 0.7465 - loss: 0.4681 - val_accuracy: 0.7437 - val_loss: 0.4840\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 438ms/step - accuracy: 0.7615 - loss: 0.4451 - val_accuracy: 0.7156 - val_loss: 0.4834\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7715 - loss: 0.4440 - val_accuracy: 0.7125 - val_loss: 0.4837\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7934 - loss: 0.4306 - val_accuracy: 0.7437 - val_loss: 0.4821\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 524ms/step - accuracy: 0.7528 - loss: 0.4573 - val_accuracy: 0.7594 - val_loss: 0.4812\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 556ms/step - accuracy: 0.7715 - loss: 0.4336 - val_accuracy: 0.7594 - val_loss: 0.4813\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7661 - loss: 0.4358 - val_accuracy: 0.7437 - val_loss: 0.4840\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.7511 - loss: 0.4577 - val_accuracy: 0.7469 - val_loss: 0.4853\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7535 - loss: 0.4438 - val_accuracy: 0.7437 - val_loss: 0.4849\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step - accuracy: 0.7541 - loss: 0.4516 - val_accuracy: 0.7437 - val_loss: 0.4849\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7560 - loss: 0.4363 - val_accuracy: 0.7437 - val_loss: 0.4854\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7537 - loss: 0.4474 - val_accuracy: 0.7406 - val_loss: 0.4849\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391ms/step - accuracy: 0.7497 - loss: 0.4535 - val_accuracy: 0.7406 - val_loss: 0.4842\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7705 - loss: 0.4341 - val_accuracy: 0.7469 - val_loss: 0.4864\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - accuracy: 0.7668 - loss: 0.4359 - val_accuracy: 0.7437 - val_loss: 0.4885\n",
            "Epoch 23: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7883\n",
            "LSTM-01CNN-ContentNets w2v_cbow Precision 0.7741\n",
            "LSTM-01CNN-ContentNets w2v_cbow Recall 0.7883\n",
            "Time taken to train: 65.25 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 666ms/step - accuracy: 0.7337 - loss: 0.5806 - val_accuracy: 0.7312 - val_loss: 0.5120\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 427ms/step - accuracy: 0.7384 - loss: 0.5013 - val_accuracy: 0.7312 - val_loss: 0.5038\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - accuracy: 0.7372 - loss: 0.4775 - val_accuracy: 0.7437 - val_loss: 0.5006\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391ms/step - accuracy: 0.7490 - loss: 0.4693 - val_accuracy: 0.7625 - val_loss: 0.4957\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 434ms/step - accuracy: 0.7458 - loss: 0.4716 - val_accuracy: 0.7375 - val_loss: 0.4985\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 681ms/step - accuracy: 0.7647 - loss: 0.4523 - val_accuracy: 0.7094 - val_loss: 0.4980\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.7490 - loss: 0.4790 - val_accuracy: 0.7406 - val_loss: 0.4916\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step - accuracy: 0.7671 - loss: 0.4452 - val_accuracy: 0.7594 - val_loss: 0.4928\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7544 - loss: 0.4653 - val_accuracy: 0.7563 - val_loss: 0.4918\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.7718 - loss: 0.4542 - val_accuracy: 0.7688 - val_loss: 0.4882\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 654ms/step - accuracy: 0.7688 - loss: 0.4433 - val_accuracy: 0.7656 - val_loss: 0.4884\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 486ms/step - accuracy: 0.7477 - loss: 0.4748 - val_accuracy: 0.7594 - val_loss: 0.4883\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 425ms/step - accuracy: 0.7552 - loss: 0.4650 - val_accuracy: 0.7531 - val_loss: 0.4899\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7616 - loss: 0.4640 - val_accuracy: 0.7375 - val_loss: 0.4859\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 541ms/step - accuracy: 0.7570 - loss: 0.4560 - val_accuracy: 0.7406 - val_loss: 0.4859\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 575ms/step - accuracy: 0.7479 - loss: 0.4470 - val_accuracy: 0.7437 - val_loss: 0.4875\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392ms/step - accuracy: 0.7549 - loss: 0.4550 - val_accuracy: 0.7344 - val_loss: 0.4877\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - accuracy: 0.7688 - loss: 0.4461 - val_accuracy: 0.7469 - val_loss: 0.4876\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 427ms/step - accuracy: 0.7716 - loss: 0.4341 - val_accuracy: 0.7375 - val_loss: 0.4862\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629ms/step - accuracy: 0.7676 - loss: 0.4452 - val_accuracy: 0.7375 - val_loss: 0.4880\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - accuracy: 0.7520 - loss: 0.4567 - val_accuracy: 0.7625 - val_loss: 0.4892\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7677 - loss: 0.4432 - val_accuracy: 0.7406 - val_loss: 0.4891\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 419ms/step - accuracy: 0.7606 - loss: 0.4503 - val_accuracy: 0.7156 - val_loss: 0.4904\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.7690 - loss: 0.4373 - val_accuracy: 0.7437 - val_loss: 0.4903\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593ms/step - accuracy: 0.7592 - loss: 0.4448 - val_accuracy: 0.7094 - val_loss: 0.4920\n",
            "Epoch 25: early stopping\n",
            "LSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7679\n",
            "LSTM-10CNN-ContentNets w2v_cbow Precision 0.8065\n",
            "LSTM-10CNN-ContentNets w2v_cbow Recall 0.7679\n",
            "Time taken to train: 77.36 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 614ms/step - accuracy: 0.7190 - loss: 0.5939 - val_accuracy: 0.7312 - val_loss: 0.5111\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 438ms/step - accuracy: 0.7369 - loss: 0.5021 - val_accuracy: 0.7437 - val_loss: 0.5007\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.7466 - loss: 0.4704 - val_accuracy: 0.7688 - val_loss: 0.4934\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662ms/step - accuracy: 0.7629 - loss: 0.4533 - val_accuracy: 0.7125 - val_loss: 0.4912\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.7593 - loss: 0.4454 - val_accuracy: 0.7063 - val_loss: 0.4884\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.7638 - loss: 0.4573 - val_accuracy: 0.7125 - val_loss: 0.4859\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.7525 - loss: 0.4523 - val_accuracy: 0.7375 - val_loss: 0.4831\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.7622 - loss: 0.4525 - val_accuracy: 0.7531 - val_loss: 0.4810\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 492ms/step - accuracy: 0.7437 - loss: 0.4588 - val_accuracy: 0.7594 - val_loss: 0.4826\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 536ms/step - accuracy: 0.7535 - loss: 0.4568 - val_accuracy: 0.7500 - val_loss: 0.4840\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 431ms/step - accuracy: 0.7600 - loss: 0.4472 - val_accuracy: 0.7375 - val_loss: 0.4860\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.7466 - loss: 0.4618 - val_accuracy: 0.7437 - val_loss: 0.4859\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7572 - loss: 0.4538 - val_accuracy: 0.7406 - val_loss: 0.4888\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 610ms/step - accuracy: 0.7694 - loss: 0.4358 - val_accuracy: 0.7625 - val_loss: 0.4880\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - accuracy: 0.7474 - loss: 0.4663 - val_accuracy: 0.7375 - val_loss: 0.4886\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7621 - loss: 0.4603 - val_accuracy: 0.7406 - val_loss: 0.4857\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.7628 - loss: 0.4433 - val_accuracy: 0.7531 - val_loss: 0.4867\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.7458 - loss: 0.4508 - val_accuracy: 0.7406 - val_loss: 0.4873\n",
            "Epoch 18: early stopping\n",
            "LSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "LSTM-11CNN-ContentNets w2v_cbow Precision 0.7514\n",
            "LSTM-11CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 56.59 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7276 - loss: 0.5863 - val_accuracy: 0.6938 - val_loss: 0.5254\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 700ms/step - accuracy: 0.7376 - loss: 0.4934 - val_accuracy: 0.7312 - val_loss: 0.5133\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 734ms/step - accuracy: 0.7357 - loss: 0.4700 - val_accuracy: 0.7063 - val_loss: 0.5089\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 704ms/step - accuracy: 0.7571 - loss: 0.4728 - val_accuracy: 0.7063 - val_loss: 0.5083\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.7522 - loss: 0.4758 - val_accuracy: 0.7063 - val_loss: 0.5034\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.7520 - loss: 0.4865 - val_accuracy: 0.7094 - val_loss: 0.5053\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693ms/step - accuracy: 0.7531 - loss: 0.4637 - val_accuracy: 0.7031 - val_loss: 0.5039\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7703 - loss: 0.4522 - val_accuracy: 0.7031 - val_loss: 0.5044\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7550 - loss: 0.4625 - val_accuracy: 0.7000 - val_loss: 0.5050\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.7500 - loss: 0.4681 - val_accuracy: 0.7031 - val_loss: 0.5060\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step - accuracy: 0.7604 - loss: 0.4418 - val_accuracy: 0.7031 - val_loss: 0.5093\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 679ms/step - accuracy: 0.7513 - loss: 0.4649 - val_accuracy: 0.7063 - val_loss: 0.5108\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796ms/step - accuracy: 0.7514 - loss: 0.4690 - val_accuracy: 0.7000 - val_loss: 0.5136\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687ms/step - accuracy: 0.7660 - loss: 0.4468 - val_accuracy: 0.7063 - val_loss: 0.5142\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.7598 - loss: 0.4864 - val_accuracy: 0.7094 - val_loss: 0.5240\n",
            "Epoch 15: early stopping\n",
            "BiLSTM-Content w2v_cbow Accuracy 0.7533\n",
            "BiLSTM-Content w2v_cbow Precision 0.7773\n",
            "BiLSTM-Content w2v_cbow Recall 0.7533\n",
            "Time taken to train: 84.12 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5385 - loss: 0.6020 - val_accuracy: 0.7312 - val_loss: 0.5153\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 674ms/step - accuracy: 0.7238 - loss: 0.5049 - val_accuracy: 0.7312 - val_loss: 0.5345\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7422 - loss: 0.4887 - val_accuracy: 0.7125 - val_loss: 0.5220\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.7463 - loss: 0.4868 - val_accuracy: 0.7375 - val_loss: 0.5168\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7410 - loss: 0.4715 - val_accuracy: 0.7094 - val_loss: 0.5089\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 688ms/step - accuracy: 0.7555 - loss: 0.4746 - val_accuracy: 0.7125 - val_loss: 0.5074\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 762ms/step - accuracy: 0.7477 - loss: 0.4808 - val_accuracy: 0.7063 - val_loss: 0.5045\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 820ms/step - accuracy: 0.7574 - loss: 0.4533 - val_accuracy: 0.7063 - val_loss: 0.5059\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 681ms/step - accuracy: 0.7426 - loss: 0.4780 - val_accuracy: 0.7063 - val_loss: 0.5085\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7549 - loss: 0.4623 - val_accuracy: 0.7063 - val_loss: 0.5122\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 683ms/step - accuracy: 0.7752 - loss: 0.4419 - val_accuracy: 0.7094 - val_loss: 0.5119\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 695ms/step - accuracy: 0.7618 - loss: 0.4554 - val_accuracy: 0.7063 - val_loss: 0.5109\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987ms/step - accuracy: 0.7546 - loss: 0.4578 - val_accuracy: 0.7094 - val_loss: 0.5117\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 706ms/step - accuracy: 0.7548 - loss: 0.4574 - val_accuracy: 0.7094 - val_loss: 0.5114\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.7537 - loss: 0.4524 - val_accuracy: 0.7063 - val_loss: 0.5153\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.7635 - loss: 0.4505 - val_accuracy: 0.7094 - val_loss: 0.5174\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 687ms/step - accuracy: 0.7502 - loss: 0.4644 - val_accuracy: 0.7094 - val_loss: 0.5165\n",
            "Epoch 17: early stopping\n",
            "BiLSTM-CNN-Content w2v_cbow Accuracy 0.7635\n",
            "BiLSTM-CNN-Content w2v_cbow Precision 0.7932\n",
            "BiLSTM-CNN-Content w2v_cbow Recall 0.7635\n",
            "Time taken to train: 95.02 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6978 - loss: 0.5876 - val_accuracy: 0.6969 - val_loss: 0.5191\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 721ms/step - accuracy: 0.7485 - loss: 0.4944 - val_accuracy: 0.7437 - val_loss: 0.5068\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7451 - loss: 0.4826 - val_accuracy: 0.7094 - val_loss: 0.4977\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 715ms/step - accuracy: 0.7629 - loss: 0.4554 - val_accuracy: 0.7063 - val_loss: 0.4988\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713ms/step - accuracy: 0.7757 - loss: 0.4445 - val_accuracy: 0.7125 - val_loss: 0.4979\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7509 - loss: 0.4791 - val_accuracy: 0.7406 - val_loss: 0.4952\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7469 - loss: 0.4792 - val_accuracy: 0.7594 - val_loss: 0.4899\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 803ms/step - accuracy: 0.7569 - loss: 0.4528 - val_accuracy: 0.7406 - val_loss: 0.4903\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 710ms/step - accuracy: 0.7645 - loss: 0.4451 - val_accuracy: 0.7656 - val_loss: 0.4892\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 709ms/step - accuracy: 0.7618 - loss: 0.4707 - val_accuracy: 0.7531 - val_loss: 0.4913\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7564 - loss: 0.4598 - val_accuracy: 0.7531 - val_loss: 0.4880\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 723ms/step - accuracy: 0.7649 - loss: 0.4400 - val_accuracy: 0.7406 - val_loss: 0.4886\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 708ms/step - accuracy: 0.7445 - loss: 0.4481 - val_accuracy: 0.7375 - val_loss: 0.4945\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 782ms/step - accuracy: 0.7555 - loss: 0.4627 - val_accuracy: 0.7156 - val_loss: 0.4925\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.7790 - loss: 0.4369 - val_accuracy: 0.7375 - val_loss: 0.4915\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7612 - loss: 0.4613 - val_accuracy: 0.7500 - val_loss: 0.4888\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 709ms/step - accuracy: 0.7539 - loss: 0.4407 - val_accuracy: 0.7469 - val_loss: 0.4915\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7473 - loss: 0.4359 - val_accuracy: 0.7375 - val_loss: 0.4926\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 716ms/step - accuracy: 0.7438 - loss: 0.4353 - val_accuracy: 0.7437 - val_loss: 0.4924\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7514 - loss: 0.4571 - val_accuracy: 0.7469 - val_loss: 0.4944\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7629 - loss: 0.4447 - val_accuracy: 0.7406 - val_loss: 0.4908\n",
            "Epoch 21: early stopping\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Accuracy 0.7708\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Precision 0.7514\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow Recall 0.7708\n",
            "Time taken to train: 112.41 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6810 - loss: 0.5762 - val_accuracy: 0.7000 - val_loss: 0.5233\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 715ms/step - accuracy: 0.7533 - loss: 0.4856 - val_accuracy: 0.7125 - val_loss: 0.5093\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 992ms/step - accuracy: 0.7612 - loss: 0.4732 - val_accuracy: 0.7063 - val_loss: 0.4972\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 711ms/step - accuracy: 0.7531 - loss: 0.4561 - val_accuracy: 0.7656 - val_loss: 0.4943\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7539 - loss: 0.4566 - val_accuracy: 0.7156 - val_loss: 0.4901\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 963ms/step - accuracy: 0.7629 - loss: 0.4709 - val_accuracy: 0.7594 - val_loss: 0.4900\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7537 - loss: 0.4664 - val_accuracy: 0.7406 - val_loss: 0.4857\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 809ms/step - accuracy: 0.7544 - loss: 0.4640 - val_accuracy: 0.7406 - val_loss: 0.4864\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 814ms/step - accuracy: 0.7690 - loss: 0.4625 - val_accuracy: 0.7406 - val_loss: 0.4863\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 710ms/step - accuracy: 0.7611 - loss: 0.4502 - val_accuracy: 0.7406 - val_loss: 0.4866\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 736ms/step - accuracy: 0.7700 - loss: 0.4419 - val_accuracy: 0.7375 - val_loss: 0.4872\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 706ms/step - accuracy: 0.7492 - loss: 0.4570 - val_accuracy: 0.7563 - val_loss: 0.4896\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714ms/step - accuracy: 0.7419 - loss: 0.4707 - val_accuracy: 0.7406 - val_loss: 0.4871\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 870ms/step - accuracy: 0.7631 - loss: 0.4347 - val_accuracy: 0.7375 - val_loss: 0.4874\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7626 - loss: 0.4368 - val_accuracy: 0.7406 - val_loss: 0.4888\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 711ms/step - accuracy: 0.7589 - loss: 0.4500 - val_accuracy: 0.7406 - val_loss: 0.4885\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7693 - loss: 0.4326 - val_accuracy: 0.7437 - val_loss: 0.4881\n",
            "Epoch 17: early stopping\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Accuracy 0.7679\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Precision 0.7473\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow Recall 0.7679\n",
            "Time taken to train: 91.39 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7317 - loss: 0.5843 - val_accuracy: 0.7594 - val_loss: 0.5450\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7349 - loss: 0.5165 - val_accuracy: 0.7469 - val_loss: 0.5193\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 696ms/step - accuracy: 0.7323 - loss: 0.4909 - val_accuracy: 0.7031 - val_loss: 0.5034\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7601 - loss: 0.4640 - val_accuracy: 0.7469 - val_loss: 0.4924\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7457 - loss: 0.4651 - val_accuracy: 0.7656 - val_loss: 0.4911\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 710ms/step - accuracy: 0.7519 - loss: 0.4769 - val_accuracy: 0.7594 - val_loss: 0.4937\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7356 - loss: 0.4745 - val_accuracy: 0.7094 - val_loss: 0.4946\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 963ms/step - accuracy: 0.7499 - loss: 0.4648 - val_accuracy: 0.7437 - val_loss: 0.4907\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 697ms/step - accuracy: 0.7506 - loss: 0.4528 - val_accuracy: 0.7469 - val_loss: 0.4922\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708ms/step - accuracy: 0.7491 - loss: 0.4485 - val_accuracy: 0.7437 - val_loss: 0.4924\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 994ms/step - accuracy: 0.7513 - loss: 0.4419 - val_accuracy: 0.7125 - val_loss: 0.4937\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694ms/step - accuracy: 0.7743 - loss: 0.4348 - val_accuracy: 0.7375 - val_loss: 0.4919\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692ms/step - accuracy: 0.7658 - loss: 0.4557 - val_accuracy: 0.7625 - val_loss: 0.4941\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 737ms/step - accuracy: 0.7633 - loss: 0.4424 - val_accuracy: 0.7437 - val_loss: 0.4933\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.7512 - loss: 0.4437 - val_accuracy: 0.7406 - val_loss: 0.4943\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7611 - loss: 0.4472 - val_accuracy: 0.7437 - val_loss: 0.4964\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step - accuracy: 0.7572 - loss: 0.4396 - val_accuracy: 0.7500 - val_loss: 0.4970\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 705ms/step - accuracy: 0.7509 - loss: 0.4421 - val_accuracy: 0.7219 - val_loss: 0.4984\n",
            "Epoch 18: early stopping\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Accuracy 0.7737\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Precision 0.8046\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow Recall 0.7737\n",
            "Time taken to train: 95.30 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5723 - loss: 0.6016 - val_accuracy: 0.7406 - val_loss: 0.5207\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 711ms/step - accuracy: 0.7479 - loss: 0.4992 - val_accuracy: 0.7500 - val_loss: 0.4979\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 714ms/step - accuracy: 0.7518 - loss: 0.4756 - val_accuracy: 0.7563 - val_loss: 0.4868\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7555 - loss: 0.4651 - val_accuracy: 0.7063 - val_loss: 0.4857\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 704ms/step - accuracy: 0.7400 - loss: 0.4633 - val_accuracy: 0.7563 - val_loss: 0.4842\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 711ms/step - accuracy: 0.7536 - loss: 0.4691 - val_accuracy: 0.7656 - val_loss: 0.4796\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806ms/step - accuracy: 0.7626 - loss: 0.4489 - val_accuracy: 0.7375 - val_loss: 0.4805\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.7581 - loss: 0.4465 - val_accuracy: 0.7563 - val_loss: 0.4803\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7606 - loss: 0.4456 - val_accuracy: 0.7469 - val_loss: 0.4833\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 723ms/step - accuracy: 0.7506 - loss: 0.4486 - val_accuracy: 0.7406 - val_loss: 0.4872\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.7639 - loss: 0.4473 - val_accuracy: 0.7375 - val_loss: 0.4842\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7546 - loss: 0.4469 - val_accuracy: 0.7594 - val_loss: 0.4809\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 713ms/step - accuracy: 0.7548 - loss: 0.4528 - val_accuracy: 0.7344 - val_loss: 0.4851\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 719ms/step - accuracy: 0.7533 - loss: 0.4453 - val_accuracy: 0.7406 - val_loss: 0.4857\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7610 - loss: 0.4384 - val_accuracy: 0.7406 - val_loss: 0.4837\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 722ms/step - accuracy: 0.7584 - loss: 0.4576 - val_accuracy: 0.7563 - val_loss: 0.4839\n",
            "Epoch 16: early stopping\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Accuracy 0.7518\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Precision 0.7235\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow Recall 0.7518\n",
            "Time taken to train: 86.58 seconds\n",
            "\n",
            "Summary for w2v_cbow:\n",
            "LSTM-00CNN-ContentNets w2v_cbow ACCURACY 0.7653 ± 0.0113\n",
            "LSTM-00CNN-ContentNets w2v_cbow PRECISION 0.7477 ± 0.0142\n",
            "LSTM-00CNN-ContentNets w2v_cbow RECALL 0.7653 ± 0.0113\n",
            "LSTM-00CNN-ContentNets w2v_cbow EXECUTION TIME 107.48 ± 24.01\n",
            "LSTM-01CNN-ContentNets w2v_cbow ACCURACY 0.7691 ± 0.0133\n",
            "LSTM-01CNN-ContentNets w2v_cbow PRECISION 0.7503 ± 0.0161\n",
            "LSTM-01CNN-ContentNets w2v_cbow RECALL 0.7691 ± 0.0133\n",
            "LSTM-01CNN-ContentNets w2v_cbow EXECUTION TIME 96.29 ± 24.64\n",
            "LSTM-10CNN-ContentNets w2v_cbow ACCURACY 0.7588 ± 0.0115\n",
            "LSTM-10CNN-ContentNets w2v_cbow PRECISION 0.7484 ± 0.0320\n",
            "LSTM-10CNN-ContentNets w2v_cbow RECALL 0.7588 ± 0.0115\n",
            "LSTM-10CNN-ContentNets w2v_cbow EXECUTION TIME 91.83 ± 27.47\n",
            "LSTM-11CNN-ContentNets w2v_cbow ACCURACY 0.7606 ± 0.0140\n",
            "LSTM-11CNN-ContentNets w2v_cbow PRECISION 0.7384 ± 0.0174\n",
            "LSTM-11CNN-ContentNets w2v_cbow RECALL 0.7606 ± 0.0140\n",
            "LSTM-11CNN-ContentNets w2v_cbow EXECUTION TIME 83.98 ± 41.53\n",
            "LSTM-Content w2v_cbow ACCURACY 0.7507 ± 0.0098\n",
            "LSTM-Content w2v_cbow PRECISION 0.7788 ± 0.0051\n",
            "LSTM-Content w2v_cbow RECALL 0.7507 ± 0.0098\n",
            "LSTM-Content w2v_cbow EXECUTION TIME 71.89 ± 30.95\n",
            "LSTM-CNN-Content w2v_cbow ACCURACY 0.7457 ± 0.0096\n",
            "LSTM-CNN-Content w2v_cbow PRECISION 0.7611 ± 0.0364\n",
            "LSTM-CNN-Content w2v_cbow RECALL 0.7457 ± 0.0096\n",
            "LSTM-CNN-Content w2v_cbow EXECUTION TIME 54.29 ± 10.10\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow ACCURACY 0.7580 ± 0.0142\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow PRECISION 0.7491 ± 0.0199\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow RECALL 0.7580 ± 0.0142\n",
            "BiLSTM-00CNN-ContentNets w2v_cbow EXECUTION TIME 123.40 ± 23.62\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow ACCURACY 0.7615 ± 0.0060\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow PRECISION 0.7417 ± 0.0052\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow RECALL 0.7615 ± 0.0060\n",
            "BiLSTM-01CNN-ContentNets w2v_cbow EXECUTION TIME 137.13 ± 39.81\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow ACCURACY 0.7626 ± 0.0094\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow PRECISION 0.7505 ± 0.0290\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow RECALL 0.7626 ± 0.0094\n",
            "BiLSTM-10CNN-ContentNets w2v_cbow EXECUTION TIME 113.05 ± 26.77\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow ACCURACY 0.7588 ± 0.0136\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow PRECISION 0.7467 ± 0.0201\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow RECALL 0.7588 ± 0.0136\n",
            "BiLSTM-11CNN-ContentNets w2v_cbow EXECUTION TIME 144.42 ± 60.89\n",
            "BiLSTM-Content w2v_cbow ACCURACY 0.7504 ± 0.0102\n",
            "BiLSTM-Content w2v_cbow PRECISION 0.7756 ± 0.0042\n",
            "BiLSTM-Content w2v_cbow RECALL 0.7504 ± 0.0102\n",
            "BiLSTM-Content w2v_cbow EXECUTION TIME 102.49 ± 18.49\n",
            "BiLSTM-CNN-Content w2v_cbow ACCURACY 0.7472 ± 0.0104\n",
            "BiLSTM-CNN-Content w2v_cbow PRECISION 0.7623 ± 0.0369\n",
            "BiLSTM-CNN-Content w2v_cbow RECALL 0.7472 ± 0.0104\n",
            "BiLSTM-CNN-Content w2v_cbow EXECUTION TIME 95.36 ± 39.57\n",
            "Loaded w2v_sg shape: (4023, 128)\n",
            "\n",
            "Iteration 1 - Split shapes:\n",
            "X_train_docs: (1277, 117) X_val_docs: (320, 117) X_test_docs: (685, 117)\n",
            "X_train_net: (1277, 1, 3) X_val_net: (320, 1, 3) X_test_net: (685, 1, 3)\n",
            "y_train: (1277, 2) y_val: (320, 2) y_test: (685, 2)\n",
            "\n",
            "Running models with w2v_sg embedding:\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 509ms/step - accuracy: 0.5837 - loss: 0.6096 - val_accuracy: 0.7312 - val_loss: 0.5703\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.7293 - loss: 0.5159 - val_accuracy: 0.7406 - val_loss: 0.4951\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 572ms/step - accuracy: 0.7285 - loss: 0.4899 - val_accuracy: 0.7469 - val_loss: 0.4928\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 426ms/step - accuracy: 0.7287 - loss: 0.4639 - val_accuracy: 0.7469 - val_loss: 0.4988\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - accuracy: 0.7314 - loss: 0.4696 - val_accuracy: 0.7781 - val_loss: 0.4831\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 424ms/step - accuracy: 0.7520 - loss: 0.4558 - val_accuracy: 0.7844 - val_loss: 0.4814\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 512ms/step - accuracy: 0.7451 - loss: 0.4574 - val_accuracy: 0.7812 - val_loss: 0.4739\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - accuracy: 0.7470 - loss: 0.4518 - val_accuracy: 0.7812 - val_loss: 0.4689\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step - accuracy: 0.7435 - loss: 0.4515 - val_accuracy: 0.7812 - val_loss: 0.4722\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - accuracy: 0.7404 - loss: 0.4567 - val_accuracy: 0.7875 - val_loss: 0.4802\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.7522 - loss: 0.4413 - val_accuracy: 0.7781 - val_loss: 0.4790\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 786ms/step - accuracy: 0.7559 - loss: 0.4381 - val_accuracy: 0.7844 - val_loss: 0.4864\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 388ms/step - accuracy: 0.7555 - loss: 0.4347 - val_accuracy: 0.7875 - val_loss: 0.4898\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - accuracy: 0.7558 - loss: 0.4295 - val_accuracy: 0.7812 - val_loss: 0.4944\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.7496 - loss: 0.4392 - val_accuracy: 0.7750 - val_loss: 0.4927\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 447ms/step - accuracy: 0.7553 - loss: 0.4279 - val_accuracy: 0.7812 - val_loss: 0.4897\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 615ms/step - accuracy: 0.7469 - loss: 0.4499 - val_accuracy: 0.7750 - val_loss: 0.4858\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.7468 - loss: 0.4292 - val_accuracy: 0.7812 - val_loss: 0.4833\n",
            "Epoch 18: early stopping\n",
            "LSTM-Content w2v_sg Accuracy 0.7328\n",
            "LSTM-Content w2v_sg Precision 0.7685\n",
            "LSTM-Content w2v_sg Recall 0.7328\n",
            "Time taken to train: 53.28 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 829ms/step - accuracy: 0.7235 - loss: 0.5981 - val_accuracy: 0.7312 - val_loss: 0.5419\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7264 - loss: 0.4786 - val_accuracy: 0.7469 - val_loss: 0.4953\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7310 - loss: 0.4761 - val_accuracy: 0.7469 - val_loss: 0.5025\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.7445 - loss: 0.4511 - val_accuracy: 0.7406 - val_loss: 0.4707\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.7560 - loss: 0.4574 - val_accuracy: 0.7812 - val_loss: 0.4819\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 605ms/step - accuracy: 0.7430 - loss: 0.4591 - val_accuracy: 0.7750 - val_loss: 0.4833\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.7527 - loss: 0.4539 - val_accuracy: 0.7812 - val_loss: 0.4744\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389ms/step - accuracy: 0.7441 - loss: 0.4622 - val_accuracy: 0.7812 - val_loss: 0.4870\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - accuracy: 0.7514 - loss: 0.4268 - val_accuracy: 0.7781 - val_loss: 0.4742\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.7679 - loss: 0.4231 - val_accuracy: 0.7812 - val_loss: 0.4871\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 609ms/step - accuracy: 0.7626 - loss: 0.4358 - val_accuracy: 0.7812 - val_loss: 0.4926\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.7524 - loss: 0.4353 - val_accuracy: 0.7812 - val_loss: 0.4883\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 388ms/step - accuracy: 0.7495 - loss: 0.4369 - val_accuracy: 0.7812 - val_loss: 0.4881\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - accuracy: 0.7539 - loss: 0.4339 - val_accuracy: 0.7781 - val_loss: 0.4756\n",
            "Epoch 14: early stopping\n",
            "LSTM-CNN-Content w2v_sg Accuracy 0.7328\n",
            "LSTM-CNN-Content w2v_sg Precision 0.7774\n",
            "LSTM-CNN-Content w2v_sg Recall 0.7328\n",
            "Time taken to train: 41.41 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 610ms/step - accuracy: 0.6183 - loss: 0.6034 - val_accuracy: 0.7312 - val_loss: 0.5702\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.7341 - loss: 0.4922 - val_accuracy: 0.7844 - val_loss: 0.4971\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.7522 - loss: 0.4774 - val_accuracy: 0.7437 - val_loss: 0.4983\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.7431 - loss: 0.4586 - val_accuracy: 0.7437 - val_loss: 0.4949\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.7456 - loss: 0.4704 - val_accuracy: 0.7781 - val_loss: 0.4764\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391ms/step - accuracy: 0.7496 - loss: 0.4610 - val_accuracy: 0.7500 - val_loss: 0.4887\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.7511 - loss: 0.4473 - val_accuracy: 0.7781 - val_loss: 0.4723\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 558ms/step - accuracy: 0.7608 - loss: 0.4494 - val_accuracy: 0.7812 - val_loss: 0.4728\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 389ms/step - accuracy: 0.7607 - loss: 0.4437 - val_accuracy: 0.7563 - val_loss: 0.4859\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.7598 - loss: 0.4411 - val_accuracy: 0.7594 - val_loss: 0.4747\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 434ms/step - accuracy: 0.7507 - loss: 0.4402 - val_accuracy: 0.7469 - val_loss: 0.5010\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 567ms/step - accuracy: 0.7477 - loss: 0.4462 - val_accuracy: 0.7844 - val_loss: 0.4775\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 428ms/step - accuracy: 0.7629 - loss: 0.4327 - val_accuracy: 0.7469 - val_loss: 0.4868\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7670 - loss: 0.4298 - val_accuracy: 0.7531 - val_loss: 0.4853\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 438ms/step - accuracy: 0.7525 - loss: 0.4365 - val_accuracy: 0.7656 - val_loss: 0.4925\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 733ms/step - accuracy: 0.7485 - loss: 0.4355 - val_accuracy: 0.7594 - val_loss: 0.4930\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 396ms/step - accuracy: 0.7617 - loss: 0.4095 - val_accuracy: 0.7594 - val_loss: 0.4845\n",
            "Epoch 17: early stopping\n",
            "LSTM-00CNN-ContentNets w2v_sg Accuracy 0.7547\n",
            "LSTM-00CNN-ContentNets w2v_sg Precision 0.7306\n",
            "LSTM-00CNN-ContentNets w2v_sg Recall 0.7547\n",
            "Time taken to train: 56.26 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 617ms/step - accuracy: 0.5506 - loss: 0.6106 - val_accuracy: 0.7312 - val_loss: 0.5744\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 0.7454 - loss: 0.4877 - val_accuracy: 0.7844 - val_loss: 0.4965\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 526ms/step - accuracy: 0.7544 - loss: 0.4829 - val_accuracy: 0.7594 - val_loss: 0.4982\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 572ms/step - accuracy: 0.7537 - loss: 0.4626 - val_accuracy: 0.7625 - val_loss: 0.5009\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 393ms/step - accuracy: 0.7331 - loss: 0.4851 - val_accuracy: 0.7781 - val_loss: 0.4767\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.7578 - loss: 0.4502 - val_accuracy: 0.7594 - val_loss: 0.4883\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.7450 - loss: 0.4514 - val_accuracy: 0.7563 - val_loss: 0.4775\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 799ms/step - accuracy: 0.7543 - loss: 0.4365 - val_accuracy: 0.7812 - val_loss: 0.4689\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 443ms/step - accuracy: 0.7463 - loss: 0.4403 - val_accuracy: 0.7594 - val_loss: 0.4858\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - accuracy: 0.7669 - loss: 0.4274 - val_accuracy: 0.7656 - val_loss: 0.4801\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step - accuracy: 0.7750 - loss: 0.4294 - val_accuracy: 0.7531 - val_loss: 0.4799\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.7682 - loss: 0.4256 - val_accuracy: 0.7531 - val_loss: 0.4848\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 791ms/step - accuracy: 0.7497 - loss: 0.4374 - val_accuracy: 0.7563 - val_loss: 0.4862\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 401ms/step - accuracy: 0.7562 - loss: 0.4358 - val_accuracy: 0.7625 - val_loss: 0.4952\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.7562 - loss: 0.4444 - val_accuracy: 0.7563 - val_loss: 0.4870\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.7459 - loss: 0.4371 - val_accuracy: 0.7500 - val_loss: 0.4999\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 564ms/step - accuracy: 0.7474 - loss: 0.4380 - val_accuracy: 0.7500 - val_loss: 0.4810\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 429ms/step - accuracy: 0.7584 - loss: 0.4245 - val_accuracy: 0.7500 - val_loss: 0.4849\n",
            "Epoch 18: early stopping\n",
            "LSTM-01CNN-ContentNets w2v_sg Accuracy 0.7650\n",
            "LSTM-01CNN-ContentNets w2v_sg Precision 0.7473\n",
            "LSTM-01CNN-ContentNets w2v_sg Recall 0.7650\n",
            "Time taken to train: 58.35 seconds\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 642ms/step - accuracy: 0.5822 - loss: 0.6160 - val_accuracy: 0.7312 - val_loss: 0.6122\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.7230 - loss: 0.5121 - val_accuracy: 0.7437 - val_loss: 0.5024\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.7342 - loss: 0.4811 - val_accuracy: 0.7437 - val_loss: 0.5086\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - accuracy: 0.7510 - loss: 0.4698 - val_accuracy: 0.7531 - val_loss: 0.4805\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 807ms/step - accuracy: 0.7560 - loss: 0.4513 - val_accuracy: 0.7563 - val_loss: 0.4835\n",
            "Epoch 6/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWF6lpFj88_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
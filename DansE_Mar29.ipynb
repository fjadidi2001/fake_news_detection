{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/oqTmCLxPoUkEUgvIdzsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/fake_news_detection/blob/main/DansE_Mar29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "oA7Z8kvmccRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive in Colab"
      ],
      "metadata": {
        "id": "PxIpn64y8_JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Mzv5ciD71hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c34f4ef-4ab2-48c2-b771-eed627578666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "9J1bk_HnDc7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = '/content/drive/MyDrive/Projects/Hayat/facebook-fact-check.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_path, encoding='latin-1')"
      ],
      "metadata": {
        "id": "bhyykHvM89kI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Inspection"
      ],
      "metadata": {
        "id": "TDzZ-uobD38a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(2))  # See first 2 rows\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSYdMJU3DiFH",
        "outputId": "1b8339e9-e749-4b69-c2d3-5d5e40c697d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     account_id       post_id    Category               Page  \\\n",
            "0  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "1  1.840000e+14  1.040000e+15  mainstream  ABC News Politics   \n",
            "\n",
            "                                            Post URL Date Published Post Type  \\\n",
            "0  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016     video   \n",
            "1  https://www.facebook.com/ABCNewsPolitics/posts...      9/19/2016      link   \n",
            "\n",
            "               Rating Debate  share_count  reaction_count  comment_count  \\\n",
            "0  no factual content    NaN          NaN           146.0           15.0   \n",
            "1         mostly true    NaN          1.0            33.0           34.0   \n",
            "\n",
            "                                        Context Post  \n",
            "0  WATCH: &quot;JEB EXCLAMATION POINT!&quot; - Je...  \n",
            "1  Can either candidate move the needle in the de...  \n",
            "\n",
            "Missing values:\n",
            " account_id           0\n",
            "post_id              0\n",
            "Category             0\n",
            "Page                 0\n",
            "Post URL             0\n",
            "Date Published       0\n",
            "Post Type            0\n",
            "Rating               0\n",
            "Debate            1984\n",
            "share_count         70\n",
            "reaction_count       2\n",
            "comment_count        2\n",
            "Context Post         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values"
      ],
      "metadata": {
        "id": "_hVZN6j7FnqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strategy 1: Fill categorical columns\n",
        "df['Rating'] = df['Rating'].fillna('Unknown')\n",
        "df['Debate'] = df['Debate'].fillna('Not Specified')\n",
        "\n",
        "# Strategy 2: Fill numerical columns with median\n",
        "numeric_cols = ['share_count', 'reaction_count', 'comment_count']\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Alternative: Drop rows with critical missing values\n",
        "# df = df.dropna(subset=['important_column'])"
      ],
      "metadata": {
        "id": "CCesok3vEbWX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Preprocessing"
      ],
      "metadata": {
        "id": "GFWw2cFnGKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date to datetime format\n",
        "df['Date Published'] = pd.to_datetime(df['Date Published'], format='%m/%d/%Y')\n",
        "\n",
        "# Clean text columns\n",
        "df['Context Post'] = df['Context Post'].str.replace('\"', '')"
      ],
      "metadata": {
        "id": "-jLm9vpHGC-h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['account_id'] = df['account_id'].astype(str)\n",
        "df['post_id'] = df['post_id'].astype(str)"
      ],
      "metadata": {
        "id": "o2_ZzlhgGlq1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['Category', 'Page', 'Post Type']\n",
        "df[categorical_cols] = df[categorical_cols].fillna('Unknown')"
      ],
      "metadata": {
        "id": "DuV4oIehGoMR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgVsdZkBG2KU",
        "outputId": "5d16b487-68eb-47d9-fcff-c88889ad8418"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2282 entries, 0 to 2281\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   account_id      2282 non-null   object        \n",
            " 1   post_id         2282 non-null   object        \n",
            " 2   Category        2282 non-null   object        \n",
            " 3   Page            2282 non-null   object        \n",
            " 4   Post URL        2282 non-null   object        \n",
            " 5   Date Published  2282 non-null   datetime64[ns]\n",
            " 6   Post Type       2282 non-null   object        \n",
            " 7   Rating          2282 non-null   object        \n",
            " 8   Debate          2282 non-null   object        \n",
            " 9   share_count     2282 non-null   float64       \n",
            " 10  reaction_count  2282 non-null   float64       \n",
            " 11  comment_count   2282 non-null   float64       \n",
            " 12  Context Post    2282 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(3), object(9)\n",
            "memory usage: 231.9+ KB\n",
            "None\n",
            "account_id        0\n",
            "post_id           0\n",
            "Category          0\n",
            "Page              0\n",
            "Post URL          0\n",
            "Date Published    0\n",
            "Post Type         0\n",
            "Rating            0\n",
            "Debate            0\n",
            "share_count       0\n",
            "reaction_count    0\n",
            "comment_count     0\n",
            "Context Post      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processElement(elem):\n",
        "    id_line = elem[0]\n",
        "    text = elem[1]\n",
        "    # Use 'Context Post' instead of 'content' if needed\n",
        "    text = tkn.createCorpus(text, remove_stopwords=False)\n",
        "    return id_line, text"
      ],
      "metadata": {
        "id": "hGiF99i4JzJb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main source"
      ],
      "metadata": {
        "id": "LVGdPq9osmqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Download and save to Drive (run once)\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip -O /content/drive/MyDrive/glove.6B.zip\n",
        "!unzip /content/drive/MyDrive/glove.6B.zip -d /content/drive/MyDrive/glove\n",
        "\n",
        "# Load from Drive in future sessions\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/glove/glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(embeddings_index)} word vectors.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K5rbfZArlgD",
        "outputId": "b4013e1c-35b5-4486-c05b-3c22230a7495"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/glove.6B.zip\n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.50d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.100d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.200d.txt  \n",
            "  inflating: /content/drive/MyDrive/glove/glove.6B.300d.txt  \n",
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clean up the environment\n",
        "!pip uninstall -y numpy mittens gensim scipy smart-open wrapt tensorflow tensorflow-datasets dm-tree numba\n",
        "\n",
        "# Step 2: Install compatible versions\n",
        "!pip install numpy==1.26.4 mittens==0.2 gensim==4.3.3 scipy==1.13.1 smart-open==7.1.0 wrapt==1.17.2\n",
        "\n",
        "# Step 3: Restart runtime (run this once, then comment out)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "# Step 4: After restart, run the code\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-iINw1nwrYN",
        "outputId": "d1acb732-f0b4-4cfb-a026-a2af9beaa851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping mittens as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scipy 1.14.1\n",
            "Uninstalling scipy-1.14.1:\n",
            "  Successfully uninstalled scipy-1.14.1\n",
            "Found existing installation: smart-open 7.1.0\n",
            "Uninstalling smart-open-7.1.0:\n",
            "  Successfully uninstalled smart-open-7.1.0\n",
            "Found existing installation: wrapt 1.17.2\n",
            "Uninstalling wrapt-1.17.2:\n",
            "  Successfully uninstalled wrapt-1.17.2\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "Found existing installation: tensorflow-datasets 4.9.8\n",
            "Uninstalling tensorflow-datasets-4.9.8:\n",
            "  Successfully uninstalled tensorflow-datasets-4.9.8\n",
            "Found existing installation: dm-tree 0.1.9\n",
            "Uninstalling dm-tree-0.1.9:\n",
            "  Successfully uninstalled dm-tree-0.1.9\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mittens==0.2\n",
            "  Downloading mittens-0.2-py3-none-any.whl.metadata (377 bytes)\n",
            "Collecting gensim==4.3.3\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open==7.1.0\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt==1.17.2\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, mittens, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "tensorflow-probability 0.25.0 requires dm-tree, which is not installed.\n",
            "umap-learn 0.5.7 requires numba>=0.51.2, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n",
            "shap 0.47.0 requires numba>=0.54, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 mittens-0.2 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify versions after restart\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import gensim\n",
        "print(\"Gensim version:\", gensim.__version__)\n",
        "\n",
        "from mittens import Mittens, GloVe\n",
        "import mittens\n",
        "print(\"Mittens version:\", mittens.__version__)\n",
        "import osfit(cooccurrence, vocab=None, initial_embedding_dict=None)\n",
        "class WordEmbeddings:\n",
        "\n",
        "    def __init__(self, corpus, normalize_tfidf=False):\n",
        "        self.corpus = corpus\n",
        "        self.normalize_tfidf = normalize_tfidf\n",
        "        self.documents = []\n",
        "        self.sentences = []\n",
        "        self.word2id = {}\n",
        "        self.no_words = 0\n",
        "        self.max_size = 0\n",
        "        self.no_docs = len(self.corpus)\n",
        "\n",
        "    def prepareDocuments(self):\n",
        "        word_id = 1\n",
        "        for document in self.corpus:\n",
        "            doc = []\n",
        "            for sentence in document:\n",
        "                self.sentences.append(sentence)\n",
        "                for word in sentence:\n",
        "                    if self.word2id.get(word) is None:\n",
        "                        self.word2id[word] = word_id\n",
        "                        word_id += 1\n",
        "                    doc.append(self.word2id[word])\n",
        "            if self.max_size < len(doc):\n",
        "                self.max_size = len(doc)\n",
        "            self.documents.append(doc)\n",
        "\n",
        "        self.no_words = len(self.word2id) + 1\n",
        "        return self.documents\n",
        "\n",
        "    def word2vecEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2vec = np.empty(shape=(self.no_words, no_components))\n",
        "        model = Word2Vec(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2vec[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2vec[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2vec\n",
        "\n",
        "    def word2GloVeEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2glove = np.empty(shape=(self.no_words, no_components))\n",
        "        model = GloVe(n=no_components, learning_rate=learning_rate)\n",
        "\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        embeddings = model.fit(cooc_matrix)\n",
        "        self.word2glove[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2glove[idx] = embeddings[idx - 1]\n",
        "        return self.word2glove\n",
        "\n",
        "    def word2FastTextEmbeddings(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), sg=0, learning_rate=0.05):\n",
        "        self.word2fasttext = np.empty(shape=(self.no_words, no_components))\n",
        "        model = FastText(self.sentences, vector_size=no_components, window=window_size, min_count=1,\n",
        "                         workers=workers, sg=sg, alpha=learning_rate, epochs=epochs)\n",
        "        self.word2fasttext[0] = np.zeros(no_components)\n",
        "        for word in self.word2id:\n",
        "            self.word2fasttext[self.word2id[word]] = model.wv[word]\n",
        "        return self.word2fasttext\n",
        "\n",
        "    def word2MittensEmbedding(self, window_size=10, no_components=128, epochs=10, workers=os.cpu_count(), learning_rate=0.05):\n",
        "        self.word2mittens = np.empty(shape=(self.no_words, no_components))\n",
        "        vocab = list(self.word2id.keys())\n",
        "        cooc_matrix = np.zeros((len(vocab), len(vocab)))\n",
        "        for sentence in self.sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                word_idx = self.word2id[word] - 1\n",
        "                for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
        "                    if i != j:\n",
        "                        cooc_idx = self.word2id[sentence[j]] - 1\n",
        "                        cooc_matrix[word_idx, cooc_idx] += 1\n",
        "\n",
        "        model = Mittens(n=no_components, max_iter=epochs, mittens=learning_rate)\n",
        "        embeddings = model.fit(cooc_matrix, vocab=vocab)\n",
        "        self.word2mittens[0] = np.zeros(no_components)\n",
        "        for word, idx in self.word2id.items():\n",
        "            self.word2mittens[idx] = embeddings[idx - 1]\n",
        "        return self.word2mittens\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    corpus = [\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "        [['Hello', 'this', 'tutorial', 'on', 'how', 'convert', 'word', 'integer', 'format'],\n",
        "         ['this', 'beautiful', 'day'],\n",
        "         ['Jack', 'going', 'office']],\n",
        "    ]\n",
        "\n",
        "    we = WordEmbeddings(corpus)\n",
        "    docs = we.prepareDocuments()\n",
        "    print(np.array(docs, dtype=object).shape)\n",
        "    print(docs)\n",
        "\n",
        "    w2v = we.word2vecEmbedding()\n",
        "    print(\"Word2Vec:\", w2v.shape)\n",
        "    print(w2v)\n",
        "\n",
        "    w2f = we.word2FastTextEmbeddings()\n",
        "    print(\"FastText:\", w2f.shape)\n",
        "    print(w2f)\n",
        "\n",
        "    w2g = we.word2GloVeEmbedding()\n",
        "    print(\"GloVe:\", w2g.shape)\n",
        "    print(w2g)\n",
        "\n",
        "    w2m = we.word2MittensEmbedding()\n",
        "    print(\"Mittens:\", w2m.shape)\n",
        "    print(w2m)\n",
        "\n",
        "    print(\"\\n\\nComparison for word ID 1:\")\n",
        "    print(\"Word2Vec:\", w2v[1])\n",
        "    print(\"FastText:\", w2f[1])\n",
        "    print(\"GloVe:\", w2g[1])\n",
        "    print(\"Mittens:\", w2m[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tJ-FKOOovXUR",
        "outputId": "2e02fed7-7d80-488e-b76e-531ea717c3a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "Mittens version: 0.2\n",
            "(3, 15)\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14], [1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14]]\n",
            "Word2Vec: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-6.21626532e-05  3.19088437e-03 -7.12745590e-03 ...  9.92520479e-04\n",
            "   7.14840600e-03  2.83964048e-03]\n",
            " [-3.82514030e-04  1.51936125e-04  3.97204095e-03 ...  2.31946167e-03\n",
            "  -3.84517061e-03  3.48054501e-03]\n",
            " ...\n",
            " [-1.44330040e-03 -3.37802432e-03 -5.04739862e-03 ...  4.78180777e-03\n",
            "   3.40414606e-03  2.03621481e-03]\n",
            " [ 5.68562094e-03 -4.50939965e-03  6.46589976e-03 ...  4.88198549e-03\n",
            "  -7.37946481e-03  7.49228429e-03]\n",
            " [-1.35904271e-03  5.24326880e-03  7.78503902e-03 ... -6.09789602e-03\n",
            "  -7.12639559e-03 -4.63685114e-03]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration 100: error 0.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText: (15, 128)\n",
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.05216913e-03 -7.23858946e-04 -2.48263852e-04 ...  4.79545008e-04\n",
            "   1.65466184e-03 -2.04305412e-04]\n",
            " [-1.36351539e-03  1.12285069e-03 -1.62398699e-03 ...  1.27794396e-03\n",
            "  -4.78518370e-04  1.83548301e-03]\n",
            " ...\n",
            " [-2.22318270e-03  2.95931986e-05 -4.96662979e-04 ...  1.28600537e-03\n",
            "   9.15645447e-04 -2.91286968e-04]\n",
            " [-3.23804357e-04  9.54689051e-04 -1.18813978e-03 ...  6.51234936e-04\n",
            "   2.29042576e-04  1.05157425e-03]\n",
            " [-4.99513757e-04  2.49632495e-03  2.18920293e-03 ...  4.68000828e-04\n",
            "  -1.34677067e-03 -1.70546729e-04]]\n",
            "GloVe: (15, 128)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.35759968 -0.41002173 -0.11296739 ... -0.13695379 -0.08978107\n",
            "  -0.02064198]\n",
            " [ 0.03458208 -0.26300714  0.31167143 ... -0.42121385  0.17037075\n",
            "   0.06615572]\n",
            " ...\n",
            " [ 0.00209569  0.26936345  0.07195031 ...  0.01113254  0.02607798\n",
            "   0.16050002]\n",
            " [ 0.00497766  0.02229993  0.00638193 ...  0.05898192 -0.15140509\n",
            "  -0.05942085]\n",
            " [ 0.08744059  0.12552654  0.06976608 ... -0.14350026 -0.07537804\n",
            "   0.00438942]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Mittens' object has no attribute 'has_embedding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a5e2d75135b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mw2m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2MittensEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mittens:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a5e2d75135b9>\u001b[0m in \u001b[0;36mword2MittensEmbedding\u001b[0;34m(self, window_size, no_components, epochs, workers, learning_rate)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMittens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmittens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2mittens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/mittens_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, vocab, initial_embedding_dict, fixed_initialization)\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_coincidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         return self._fit(X, weights, log_coincidence,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                          \u001b[0minitial_embedding_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_embedding_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/np_mittens.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, coincidence, weights, log_coincidence, vocab, initial_embedding_dict, fixed_initialization)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             gradients, error = self._get_gradients_and_error(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 pred, log_coincidence, weights)\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mittens/np_mittens.py\u001b[0m in \u001b[0;36m_get_gradients_and_error\u001b[0;34m(self, predictions, log_coincidence, weights)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmittens\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcurr_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mwgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmittens\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Mittens' object has no attribute 'has_embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzniUIiExhUt",
        "outputId": "6b109cd3-b119-4a64-c14c-3c4d5005cb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5dc4ff210770>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooccurrence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_embedding_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fuNa6-WuR4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}